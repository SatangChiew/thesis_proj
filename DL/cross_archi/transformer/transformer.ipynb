{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a2ed14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb3ca124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "CHUNK_SIZE = 31\n",
    "NUM_FEATURES = 8\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "K_FOLDS = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc5201bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPERS ===\n",
    "def collate_fn(batch):\n",
    "    streams, labels = zip(*batch)\n",
    "    streams = list(zip(*streams))\n",
    "    streams = [torch.stack(s) for s in streams]\n",
    "    labels = torch.tensor(labels)\n",
    "    return streams, labels\n",
    "\n",
    "def compute_class_weights(labels, device):\n",
    "    counter = Counter(labels)\n",
    "    total = sum(counter.values())\n",
    "    weights = [np.log(total / (counter[i] + 1)) for i in range(len(counter))]\n",
    "    return torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "def print_model_info(model):\n",
    "    print(\"Model Architecture:\")\n",
    "    print(model)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "def plot_loss_curve(train_losses, val_losses):\n",
    "    epochs = range(len(train_losses))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, label='Train Loss', color='blue')\n",
    "    plt.plot(epochs, val_losses, label='Val Loss', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_curve(train_acc, val_acc):\n",
    "    epochs = range(len(train_acc))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_acc, label='Train Accuracy', color='green')\n",
    "    plt.plot(epochs, val_acc, label='Val Accuracy', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cee78dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATASET CLASS ===\n",
    "class MultiStreamDataset(Dataset):\n",
    "    def __init__(self, data, labels, label_encoder, augment=False):\n",
    "        self.data = data\n",
    "        self.labels = label_encoder.transform(labels)\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def augment_stream(self, stream):\n",
    "        jitter = np.random.normal(0, 0.01, stream.shape)\n",
    "        scale = np.random.normal(1.0, 0.05, stream.shape)\n",
    "        return stream * scale + jitter\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]  # shape: (T, 8)\n",
    "        \n",
    "        if self.augment:\n",
    "            # Apply augmentation to each feature independently\n",
    "            jitter = np.random.normal(0, 0.01, sample.shape)\n",
    "            scale = np.random.normal(1.0, 0.05, sample.shape)\n",
    "            sample = sample * scale + jitter\n",
    "\n",
    "        sample_tensor = torch.tensor(sample, dtype=torch.float32)  # shape: (T, 8)\n",
    "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return sample_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f44ad405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RansomwareTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=8, seq_len=32, num_classes=12,\n",
    "                 d_model=32, nhead=2, num_layers=1, dim_feedforward=64, dropout=0.1):\n",
    "        super(RansomwareTransformer, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(input_dim, d_model)\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1, seq_len, d_model))  # (1, T, d_model)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward, dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)  # pool across time steps\n",
    "        self.proj = nn.Linear(d_model, 128)     # ⬅️ For feature distillation (match student)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_features=False):  # x: (B, T, 8)\n",
    "        x = self.embedding(x) + self.pos_encoding[:, :x.size(1)]\n",
    "        x = self.transformer(x)         # (B, T, d_model)\n",
    "        x = x.transpose(1, 2)           # (B, d_model, T)\n",
    "        x = self.pooling(x).squeeze(-1) # (B, d_model)\n",
    "\n",
    "        if return_features:\n",
    "            feat_proj = self.proj(x)    # (B, 128)\n",
    "            return self.fc(x), feat_proj\n",
    "\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43c4ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === COLLATE FUNCTION ===\n",
    "# def collate_fn(batch):\n",
    "#     streams, labels = zip(*batch)\n",
    "#     streams = list(zip(*streams))\n",
    "#     streams = [torch.stack(s) for s in streams]\n",
    "#     labels = torch.tensor(labels)\n",
    "#     return streams, labels\n",
    "\n",
    "# === LOAD SPLIT FUNCTION ===\n",
    "def load_split_from_folder(split_dir, expected_shape):\n",
    "    X, y = [], []\n",
    "    for class_name in sorted(os.listdir(split_dir)):\n",
    "        class_path = os.path.join(split_dir, class_name)\n",
    "        for fname in sorted(os.listdir(class_path)):\n",
    "            if fname.endswith(\".csv\"):\n",
    "                fpath = os.path.join(class_path, fname)\n",
    "                chunk = pd.read_csv(fpath, header=None).values\n",
    "                if chunk.shape == expected_shape:\n",
    "                    X.append(chunk)\n",
    "                    y.append(class_name)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe8144a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === APPLY SMOTE ===\n",
    "def apply_smote_on_training(X_chunks, y_labels, chunk_size, num_features):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y_labels)\n",
    "\n",
    "    smote_encoder = LabelEncoder()\n",
    "    y_encoded_for_smote = smote_encoder.fit_transform(y_labels)\n",
    "\n",
    "    X_flat = X_chunks.reshape(X_chunks.shape[0], -1)\n",
    "    X_resampled, y_resampled = SMOTE().fit_resample(X_flat, y_encoded_for_smote)\n",
    "\n",
    "    X_res = X_resampled.reshape(-1, chunk_size, num_features)\n",
    "    y_res_str = smote_encoder.inverse_transform(y_resampled)\n",
    "\n",
    "    return X_res, y_res_str, label_encoder\n",
    "\n",
    "# # === LOAD DATASETS ===\n",
    "# expected_shape = (CHUNK_SIZE, NUM_FEATURES)\n",
    "\n",
    "# X_train_raw, y_train_raw = load_split_from_folder(os.path.join(INPUT_DIR, \"train\"), expected_shape)\n",
    "# X_val_raw,   y_val_raw   = load_split_from_folder(os.path.join(INPUT_DIR, \"val\"), expected_shape)\n",
    "\n",
    "# # === SMOTE ONLY ON TRAIN ===\n",
    "# X_train_balanced, y_train_str, label_encoder = apply_smote_on_training(\n",
    "#     X_train_raw, y_train_raw, CHUNK_SIZE, NUM_FEATURES\n",
    "# )\n",
    "\n",
    "# # === CREATE DATASETS ===\n",
    "# train_dataset = MultiStreamDataset(X_train_balanced, y_train_str, label_encoder, augment=True)\n",
    "# val_dataset   = MultiStreamDataset(X_val_raw, y_val_raw, label_encoder, augment=False)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "# val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e9eb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === CLASS WEIGHTING ===\n",
    "def compute_class_weights(labels, device):\n",
    "    from collections import Counter\n",
    "    total = len(labels)\n",
    "    counts = Counter(labels)\n",
    "    weights = [np.log(total / (counts[i] + 1)) for i in range(len(counts))]\n",
    "    return torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "# class_weights_tensor = compute_class_weights(label_encoder.transform(y_train_str), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "882bd8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=50, lr=0.001,\n",
    "                class_weights=None, optimizer=None, scheduler=None, best_model_path=\"transformer_model.pth\"):\n",
    "\n",
    "    print(\"🔍 Class Weights Tensor:\")\n",
    "    print(class_weights)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if optimizer is None:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct = 0, 0\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(total_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {total_loss:.4f} - Val Loss: {val_loss:.4f} - Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # ✅ Save model ONLY if it's the best so far\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"💾 Best model saved to: {best_model_path}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    return train_accuracies, val_accuracies, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d938ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === UTILS ===\n",
    "def load_split_from_folder(split_dir, expected_shape):\n",
    "    X, y = [], []\n",
    "    for class_name in sorted(os.listdir(split_dir)):\n",
    "        class_path = os.path.join(split_dir, class_name)\n",
    "        for fname in sorted(os.listdir(class_path)):\n",
    "            if fname.endswith(\".csv\"):\n",
    "                fpath = os.path.join(class_path, fname)\n",
    "                chunk = pd.read_csv(fpath, header=None).values\n",
    "                if chunk.shape == expected_shape:\n",
    "                    X.append(chunk)\n",
    "                    y.append(class_name)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# # === LOAD DATA FROM FOLDER STRUCTURE ===\n",
    "# expected_shape = (CHUNK_SIZE, NUM_FEATURES)\n",
    "# X_train_raw, y_train_raw = load_split_from_folder(os.path.join(INPUT_DIR, \"train\"), expected_shape)\n",
    "# X_val_raw, y_val_raw     = load_split_from_folder(os.path.join(INPUT_DIR, \"val\"), expected_shape)\n",
    "\n",
    "# # === ENCODE LABELS & APPLY SMOTE ===\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train_encoded = label_encoder.fit_transform(y_train_raw)\n",
    "\n",
    "# X_train_flat = X_train_raw.reshape(X_train_raw.shape[0], -1)\n",
    "# X_resampled, y_resampled = SMOTE().fit_resample(X_train_flat, y_train_encoded)\n",
    "# X_train_bal = X_resampled.reshape(-1, CHUNK_SIZE, NUM_FEATURES)\n",
    "# y_train_str = label_encoder.inverse_transform(y_resampled)\n",
    "\n",
    "# # === BUILD DATASETS AND LOADERS ===\n",
    "# train_dataset = MultiStreamDataset(X_train_bal, y_train_str, label_encoder, augment=True)\n",
    "# val_dataset   = MultiStreamDataset(X_val_raw, y_val_raw, label_encoder, augment=False)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# # === CLASS WEIGHTS ===\n",
    "# class_weights_tensor = compute_class_weights(label_encoder.transform(y_train_str), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e25950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_lr_finder import LRFinder\n",
    "\n",
    "# NUM_EPOCHS = 70\n",
    "\n",
    "# print(\"\\n=== 🧠 Retraining Transformer Model ===\")\n",
    "# model_for_lr = RansomwareTransformer(\n",
    "#     input_dim=NUM_FEATURES,\n",
    "#     seq_len=CHUNK_SIZE,\n",
    "#     num_classes=len(label_encoder.classes_)\n",
    "# ).to(device)\n",
    "\n",
    "# # ✅ Use AdamW for LR Finder\n",
    "# optimizer = torch.optim.AdamW(model_for_lr.parameters(), lr=1e-7, weight_decay=1e-4)\n",
    "# criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# print(\"🔍 Finding optimal learning rate...\")\n",
    "# lr_finder = LRFinder(model_for_lr, optimizer, criterion, device=device)\n",
    "# lr_finder.range_test(train_loader, end_lr=1, num_iter=200)\n",
    "# lr_finder.plot()  # Manually inspect the curve\n",
    "# lr_finder.reset()\n",
    "\n",
    "# # After inspecting the LR plot, update this\n",
    "# BEST_LR = 0.01  # ✅ Replace this based on the plotted curve\n",
    "\n",
    "# # === Train Final Transformer ===\n",
    "# final_transformer = RansomwareTransformer(\n",
    "#     input_dim=NUM_FEATURES,\n",
    "#     seq_len=CHUNK_SIZE,\n",
    "#     num_classes=len(label_encoder.classes_)\n",
    "# ).to(device)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(final_transformer.parameters(), lr=BEST_LR, weight_decay=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# train_accs, val_accs, train_losses, val_losses = train_model(\n",
    "#     model=final_transformer,\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=val_loader,\n",
    "#     device=device,\n",
    "#     epochs=NUM_EPOCHS,\n",
    "#     class_weights=class_weights_tensor,\n",
    "#     lr=BEST_LR,\n",
    "#     optimizer=optimizer,\n",
    "#     scheduler=scheduler\n",
    "# )\n",
    "\n",
    "# # === Save Model ===\n",
    "# torch.save(final_transformer.state_dict(), \"transformer.pth\")\n",
    "# print(\"✅ Final transformer model saved as 'transformer.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3120acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === 🔍 Plot training curves\n",
    "# plot_loss_curve(train_losses, val_losses)\n",
    "# plot_accuracy_curve(train_accs, val_accs)\n",
    "\n",
    "# # === 📊 Evaluate on validation set (same used during training)\n",
    "# final_transformer.eval()\n",
    "# all_preds, all_labels = [], []\n",
    "# with torch.no_grad():\n",
    "#     for inputs, labels in val_loader:  # inputs: (B, T, 8)\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = final_transformer(inputs)\n",
    "#         preds = torch.argmax(outputs, dim=1)\n",
    "#         all_preds.extend(preds.cpu().numpy())\n",
    "#         all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# # === Confusion Matrix & Report\n",
    "# cm = confusion_matrix(all_labels, all_preds)\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#             xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "# plt.title('Teacher Model - Confusion Matrix (Validation Set)')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(\"\\nFinal Classification Report (Teacher):\\n\")\n",
    "# print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
    "\n",
    "# print(f\"\\nFinal Training Accuracy: {train_accs[-1]:.4f}\")\n",
    "# print(f\"Final Validation Accuracy: {val_accs[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6f4dec68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running for Td=30, Tw=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4843, 2.4843, 2.4843, 2.4843, 2.4843, 2.4843, 2.4843, 2.4843, 2.4843,\n",
      "        2.4843, 2.4843, 2.4843], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 624.6613 - Val Loss: 75.4990 - Train Acc: 0.5724 - Val Acc: 0.5245\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 2/50 - Train Loss: 474.3682 - Val Loss: 59.0594 - Train Acc: 0.6746 - Val Acc: 0.6232\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 3/50 - Train Loss: 413.8850 - Val Loss: 59.4414 - Train Acc: 0.7205 - Val Acc: 0.6263\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 4/50 - Train Loss: 387.8245 - Val Loss: 49.5105 - Train Acc: 0.7374 - Val Acc: 0.6738\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 5/50 - Train Loss: 373.1636 - Val Loss: 55.0459 - Train Acc: 0.7449 - Val Acc: 0.6438\n",
      "Epoch 6/50 - Train Loss: 348.6946 - Val Loss: 40.4809 - Train Acc: 0.7628 - Val Acc: 0.7380\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 7/50 - Train Loss: 339.0378 - Val Loss: 45.1886 - Train Acc: 0.7691 - Val Acc: 0.7034\n",
      "Epoch 8/50 - Train Loss: 331.2945 - Val Loss: 48.7687 - Train Acc: 0.7774 - Val Acc: 0.7069\n",
      "Epoch 9/50 - Train Loss: 326.4944 - Val Loss: 46.1459 - Train Acc: 0.7802 - Val Acc: 0.7214\n",
      "Epoch 10/50 - Train Loss: 321.2326 - Val Loss: 47.1398 - Train Acc: 0.7828 - Val Acc: 0.7124\n",
      "Epoch 11/50 - Train Loss: 303.9492 - Val Loss: 45.4845 - Train Acc: 0.7934 - Val Acc: 0.7114\n",
      "Epoch 12/50 - Train Loss: 296.0782 - Val Loss: 37.5868 - Train Acc: 0.7978 - Val Acc: 0.7690\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 13/50 - Train Loss: 290.8278 - Val Loss: 41.5357 - Train Acc: 0.8045 - Val Acc: 0.7375\n",
      "Epoch 14/50 - Train Loss: 278.4514 - Val Loss: 38.6160 - Train Acc: 0.8093 - Val Acc: 0.7575\n",
      "Epoch 15/50 - Train Loss: 274.4515 - Val Loss: 42.4913 - Train Acc: 0.8151 - Val Acc: 0.7340\n",
      "Epoch 16/50 - Train Loss: 269.2488 - Val Loss: 35.8885 - Train Acc: 0.8211 - Val Acc: 0.7866\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 17/50 - Train Loss: 272.6255 - Val Loss: 36.4569 - Train Acc: 0.8199 - Val Acc: 0.7745\n",
      "Epoch 18/50 - Train Loss: 268.5656 - Val Loss: 39.0376 - Train Acc: 0.8214 - Val Acc: 0.7490\n",
      "Epoch 19/50 - Train Loss: 265.9599 - Val Loss: 38.8204 - Train Acc: 0.8203 - Val Acc: 0.7565\n",
      "Epoch 20/50 - Train Loss: 248.4726 - Val Loss: 35.1974 - Train Acc: 0.8361 - Val Acc: 0.7655\n",
      "Epoch 21/50 - Train Loss: 239.3089 - Val Loss: 40.4089 - Train Acc: 0.8379 - Val Acc: 0.7771\n",
      "Epoch 22/50 - Train Loss: 237.9482 - Val Loss: 33.3293 - Train Acc: 0.8395 - Val Acc: 0.8001\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 23/50 - Train Loss: 229.5993 - Val Loss: 31.8042 - Train Acc: 0.8470 - Val Acc: 0.8221\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 24/50 - Train Loss: 225.8671 - Val Loss: 35.8943 - Train Acc: 0.8487 - Val Acc: 0.7851\n",
      "Epoch 25/50 - Train Loss: 221.9495 - Val Loss: 29.5817 - Train Acc: 0.8513 - Val Acc: 0.8236\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 26/50 - Train Loss: 206.7531 - Val Loss: 28.0536 - Train Acc: 0.8587 - Val Acc: 0.8322\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 27/50 - Train Loss: 206.6602 - Val Loss: 29.0645 - Train Acc: 0.8603 - Val Acc: 0.8297\n",
      "Epoch 28/50 - Train Loss: 202.9825 - Val Loss: 32.0695 - Train Acc: 0.8640 - Val Acc: 0.8151\n",
      "Epoch 29/50 - Train Loss: 199.8492 - Val Loss: 26.6215 - Train Acc: 0.8691 - Val Acc: 0.8417\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 30/50 - Train Loss: 192.8802 - Val Loss: 28.2129 - Train Acc: 0.8708 - Val Acc: 0.8236\n",
      "Epoch 31/50 - Train Loss: 185.8978 - Val Loss: 29.9010 - Train Acc: 0.8743 - Val Acc: 0.8307\n",
      "Epoch 32/50 - Train Loss: 180.3000 - Val Loss: 27.1407 - Train Acc: 0.8793 - Val Acc: 0.8312\n",
      "Epoch 33/50 - Train Loss: 178.9393 - Val Loss: 23.8548 - Train Acc: 0.8796 - Val Acc: 0.8687\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 34/50 - Train Loss: 175.7129 - Val Loss: 23.7991 - Train Acc: 0.8831 - Val Acc: 0.8652\n",
      "Epoch 35/50 - Train Loss: 168.7073 - Val Loss: 22.2635 - Train Acc: 0.8866 - Val Acc: 0.8667\n",
      "Epoch 36/50 - Train Loss: 164.6539 - Val Loss: 22.5643 - Train Acc: 0.8900 - Val Acc: 0.8712\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 37/50 - Train Loss: 164.3505 - Val Loss: 21.8932 - Train Acc: 0.8900 - Val Acc: 0.8682\n",
      "Epoch 38/50 - Train Loss: 159.5455 - Val Loss: 22.4895 - Train Acc: 0.8920 - Val Acc: 0.8677\n",
      "Epoch 39/50 - Train Loss: 154.5193 - Val Loss: 21.1910 - Train Acc: 0.8962 - Val Acc: 0.8793\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 40/50 - Train Loss: 150.4110 - Val Loss: 20.8287 - Train Acc: 0.8980 - Val Acc: 0.8818\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 41/50 - Train Loss: 150.8112 - Val Loss: 20.8616 - Train Acc: 0.8995 - Val Acc: 0.8833\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 42/50 - Train Loss: 145.3186 - Val Loss: 21.8641 - Train Acc: 0.9017 - Val Acc: 0.8742\n",
      "Epoch 43/50 - Train Loss: 145.1622 - Val Loss: 20.2501 - Train Acc: 0.9053 - Val Acc: 0.8863\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 44/50 - Train Loss: 144.0680 - Val Loss: 21.0390 - Train Acc: 0.9049 - Val Acc: 0.8803\n",
      "Epoch 45/50 - Train Loss: 143.0169 - Val Loss: 20.0481 - Train Acc: 0.9035 - Val Acc: 0.8893\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 46/50 - Train Loss: 140.8993 - Val Loss: 20.1818 - Train Acc: 0.9054 - Val Acc: 0.8888\n",
      "Epoch 47/50 - Train Loss: 137.1662 - Val Loss: 19.8625 - Train Acc: 0.9098 - Val Acc: 0.8903\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 48/50 - Train Loss: 139.7053 - Val Loss: 19.8781 - Train Acc: 0.9059 - Val Acc: 0.8918\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw10.pth\n",
      "Epoch 49/50 - Train Loss: 138.8202 - Val Loss: 19.8503 - Train Acc: 0.9078 - Val Acc: 0.8908\n",
      "Epoch 50/50 - Train Loss: 134.8531 - Val Loss: 19.8503 - Train Acc: 0.9101 - Val Acc: 0.8908\n",
      "\n",
      "🚀 Running for Td=30, Tw=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/213766697.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4844, 2.4844, 2.4844, 2.4844, 2.4844, 2.4844, 2.4844, 2.4844, 2.4844,\n",
      "        2.4844, 2.4844, 2.4844], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 702.7678 - Val Loss: 70.2160 - Train Acc: 0.6632 - Val Acc: 0.6800\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 2/50 - Train Loss: 475.8542 - Val Loss: 67.5550 - Train Acc: 0.7658 - Val Acc: 0.6644\n",
      "Epoch 3/50 - Train Loss: 440.9636 - Val Loss: 65.1731 - Train Acc: 0.7818 - Val Acc: 0.6997\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 4/50 - Train Loss: 411.5334 - Val Loss: 70.1555 - Train Acc: 0.7971 - Val Acc: 0.6629\n",
      "Epoch 5/50 - Train Loss: 376.9889 - Val Loss: 57.3830 - Train Acc: 0.8118 - Val Acc: 0.7213\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 6/50 - Train Loss: 363.1743 - Val Loss: 57.7546 - Train Acc: 0.8211 - Val Acc: 0.7248\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 7/50 - Train Loss: 341.6708 - Val Loss: 54.0524 - Train Acc: 0.8314 - Val Acc: 0.7566\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 8/50 - Train Loss: 326.2858 - Val Loss: 46.1297 - Train Acc: 0.8382 - Val Acc: 0.7927\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 9/50 - Train Loss: 306.5896 - Val Loss: 47.1703 - Train Acc: 0.8482 - Val Acc: 0.8052\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 10/50 - Train Loss: 291.5123 - Val Loss: 50.7027 - Train Acc: 0.8582 - Val Acc: 0.7654\n",
      "Epoch 11/50 - Train Loss: 297.6305 - Val Loss: 45.2372 - Train Acc: 0.8554 - Val Acc: 0.8117\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 12/50 - Train Loss: 275.0142 - Val Loss: 43.4709 - Train Acc: 0.8667 - Val Acc: 0.8178\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 13/50 - Train Loss: 258.8100 - Val Loss: 36.8192 - Train Acc: 0.8721 - Val Acc: 0.8322\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 14/50 - Train Loss: 254.8201 - Val Loss: 41.0351 - Train Acc: 0.8727 - Val Acc: 0.8231\n",
      "Epoch 15/50 - Train Loss: 244.5368 - Val Loss: 34.9006 - Train Acc: 0.8788 - Val Acc: 0.8489\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 16/50 - Train Loss: 242.2202 - Val Loss: 39.2466 - Train Acc: 0.8785 - Val Acc: 0.8292\n",
      "Epoch 17/50 - Train Loss: 231.0998 - Val Loss: 39.5332 - Train Acc: 0.8870 - Val Acc: 0.8231\n",
      "Epoch 18/50 - Train Loss: 221.9048 - Val Loss: 37.3749 - Train Acc: 0.8891 - Val Acc: 0.8470\n",
      "Epoch 19/50 - Train Loss: 223.1639 - Val Loss: 38.5330 - Train Acc: 0.8904 - Val Acc: 0.8326\n",
      "Epoch 20/50 - Train Loss: 218.8416 - Val Loss: 30.6119 - Train Acc: 0.8932 - Val Acc: 0.8702\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 21/50 - Train Loss: 204.7109 - Val Loss: 36.9212 - Train Acc: 0.8970 - Val Acc: 0.8462\n",
      "Epoch 22/50 - Train Loss: 200.0890 - Val Loss: 45.1560 - Train Acc: 0.9018 - Val Acc: 0.8204\n",
      "Epoch 23/50 - Train Loss: 193.3879 - Val Loss: 34.7797 - Train Acc: 0.9046 - Val Acc: 0.8535\n",
      "Epoch 24/50 - Train Loss: 188.9774 - Val Loss: 37.1397 - Train Acc: 0.9083 - Val Acc: 0.8424\n",
      "Epoch 25/50 - Train Loss: 185.1321 - Val Loss: 31.5364 - Train Acc: 0.9087 - Val Acc: 0.8736\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 26/50 - Train Loss: 176.0564 - Val Loss: 32.3055 - Train Acc: 0.9133 - Val Acc: 0.8675\n",
      "Epoch 27/50 - Train Loss: 174.1320 - Val Loss: 36.4220 - Train Acc: 0.9157 - Val Acc: 0.8584\n",
      "Epoch 28/50 - Train Loss: 165.4774 - Val Loss: 36.3031 - Train Acc: 0.9178 - Val Acc: 0.8603\n",
      "Epoch 29/50 - Train Loss: 166.1780 - Val Loss: 27.6573 - Train Acc: 0.9181 - Val Acc: 0.8857\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 30/50 - Train Loss: 156.9349 - Val Loss: 31.0750 - Train Acc: 0.9234 - Val Acc: 0.8781\n",
      "Epoch 31/50 - Train Loss: 151.2209 - Val Loss: 29.5656 - Train Acc: 0.9258 - Val Acc: 0.8804\n",
      "Epoch 32/50 - Train Loss: 149.1637 - Val Loss: 31.8589 - Train Acc: 0.9281 - Val Acc: 0.8823\n",
      "Epoch 33/50 - Train Loss: 141.8795 - Val Loss: 30.5214 - Train Acc: 0.9324 - Val Acc: 0.8876\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 34/50 - Train Loss: 138.2894 - Val Loss: 28.9809 - Train Acc: 0.9329 - Val Acc: 0.8857\n",
      "Epoch 35/50 - Train Loss: 134.8760 - Val Loss: 27.3889 - Train Acc: 0.9352 - Val Acc: 0.8910\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 36/50 - Train Loss: 127.9935 - Val Loss: 28.0296 - Train Acc: 0.9386 - Val Acc: 0.8914\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 37/50 - Train Loss: 128.6425 - Val Loss: 28.5524 - Train Acc: 0.9379 - Val Acc: 0.8880\n",
      "Epoch 38/50 - Train Loss: 123.7919 - Val Loss: 29.0586 - Train Acc: 0.9415 - Val Acc: 0.8903\n",
      "Epoch 39/50 - Train Loss: 121.3380 - Val Loss: 27.9510 - Train Acc: 0.9408 - Val Acc: 0.8933\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 40/50 - Train Loss: 115.8257 - Val Loss: 25.4659 - Train Acc: 0.9450 - Val Acc: 0.9002\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 41/50 - Train Loss: 117.2540 - Val Loss: 25.9235 - Train Acc: 0.9432 - Val Acc: 0.9021\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 42/50 - Train Loss: 115.1010 - Val Loss: 26.0711 - Train Acc: 0.9441 - Val Acc: 0.8964\n",
      "Epoch 43/50 - Train Loss: 114.2842 - Val Loss: 26.0831 - Train Acc: 0.9451 - Val Acc: 0.8986\n",
      "Epoch 44/50 - Train Loss: 108.6741 - Val Loss: 25.0451 - Train Acc: 0.9472 - Val Acc: 0.9039\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw15.pth\n",
      "Epoch 45/50 - Train Loss: 108.2613 - Val Loss: 26.4786 - Train Acc: 0.9468 - Val Acc: 0.8979\n",
      "Epoch 46/50 - Train Loss: 106.4651 - Val Loss: 25.6624 - Train Acc: 0.9487 - Val Acc: 0.9009\n",
      "Epoch 47/50 - Train Loss: 105.6368 - Val Loss: 25.8112 - Train Acc: 0.9491 - Val Acc: 0.9021\n",
      "Epoch 48/50 - Train Loss: 106.3808 - Val Loss: 25.5966 - Train Acc: 0.9482 - Val Acc: 0.9017\n",
      "Epoch 49/50 - Train Loss: 106.1012 - Val Loss: 25.5872 - Train Acc: 0.9493 - Val Acc: 0.9013\n",
      "Epoch 50/50 - Train Loss: 104.1696 - Val Loss: 25.5872 - Train Acc: 0.9485 - Val Acc: 0.9013\n",
      "\n",
      "🚀 Running for Td=30, Tw=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/213766697.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4847, 2.4847, 2.4847, 2.4847, 2.4847, 2.4847, 2.4847, 2.4847, 2.4847,\n",
      "        2.4847, 2.4847, 2.4847], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 1227.0316 - Val Loss: 129.1422 - Train Acc: 0.7030 - Val Acc: 0.6899\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 2/50 - Train Loss: 856.1394 - Val Loss: 106.6799 - Train Acc: 0.7887 - Val Acc: 0.7306\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 3/50 - Train Loss: 769.6849 - Val Loss: 103.5620 - Train Acc: 0.8103 - Val Acc: 0.7465\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 4/50 - Train Loss: 714.8654 - Val Loss: 125.1126 - Train Acc: 0.8242 - Val Acc: 0.7392\n",
      "Epoch 5/50 - Train Loss: 679.0222 - Val Loss: 95.8768 - Train Acc: 0.8344 - Val Acc: 0.7807\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 6/50 - Train Loss: 674.2667 - Val Loss: 102.1752 - Train Acc: 0.8355 - Val Acc: 0.7902\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 7/50 - Train Loss: 620.8925 - Val Loss: 92.5513 - Train Acc: 0.8486 - Val Acc: 0.8117\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 8/50 - Train Loss: 606.5156 - Val Loss: 87.1469 - Train Acc: 0.8525 - Val Acc: 0.8013\n",
      "Epoch 9/50 - Train Loss: 611.0236 - Val Loss: 102.7931 - Train Acc: 0.8521 - Val Acc: 0.7864\n",
      "Epoch 10/50 - Train Loss: 600.4246 - Val Loss: 86.3360 - Train Acc: 0.8552 - Val Acc: 0.8080\n",
      "Epoch 11/50 - Train Loss: 577.2791 - Val Loss: 87.7007 - Train Acc: 0.8587 - Val Acc: 0.8061\n",
      "Epoch 12/50 - Train Loss: 544.5530 - Val Loss: 89.8231 - Train Acc: 0.8678 - Val Acc: 0.8281\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 13/50 - Train Loss: 563.0009 - Val Loss: 96.2881 - Train Acc: 0.8612 - Val Acc: 0.7862\n",
      "Epoch 14/50 - Train Loss: 539.0024 - Val Loss: 82.3852 - Train Acc: 0.8690 - Val Acc: 0.8302\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 15/50 - Train Loss: 514.2524 - Val Loss: 91.6670 - Train Acc: 0.8748 - Val Acc: 0.8270\n",
      "Epoch 16/50 - Train Loss: 545.5732 - Val Loss: 92.9783 - Train Acc: 0.8676 - Val Acc: 0.8390\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 17/50 - Train Loss: 486.1002 - Val Loss: 90.0808 - Train Acc: 0.8807 - Val Acc: 0.8191\n",
      "Epoch 18/50 - Train Loss: 483.0281 - Val Loss: 75.4602 - Train Acc: 0.8822 - Val Acc: 0.8499\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 19/50 - Train Loss: 461.0377 - Val Loss: 83.8775 - Train Acc: 0.8864 - Val Acc: 0.8488\n",
      "Epoch 20/50 - Train Loss: 468.2586 - Val Loss: 75.7413 - Train Acc: 0.8868 - Val Acc: 0.8501\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 21/50 - Train Loss: 442.7389 - Val Loss: 95.4378 - Train Acc: 0.8915 - Val Acc: 0.8224\n",
      "Epoch 22/50 - Train Loss: 433.0317 - Val Loss: 74.9340 - Train Acc: 0.8942 - Val Acc: 0.8432\n",
      "Epoch 23/50 - Train Loss: 414.6925 - Val Loss: 71.7411 - Train Acc: 0.8972 - Val Acc: 0.8549\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 24/50 - Train Loss: 398.6528 - Val Loss: 77.4228 - Train Acc: 0.9025 - Val Acc: 0.8396\n",
      "Epoch 25/50 - Train Loss: 395.1772 - Val Loss: 67.6742 - Train Acc: 0.9039 - Val Acc: 0.8566\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 26/50 - Train Loss: 385.4234 - Val Loss: 92.3336 - Train Acc: 0.9057 - Val Acc: 0.8457\n",
      "Epoch 27/50 - Train Loss: 380.2129 - Val Loss: 68.2860 - Train Acc: 0.9061 - Val Acc: 0.8671\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 28/50 - Train Loss: 371.6352 - Val Loss: 70.9856 - Train Acc: 0.9082 - Val Acc: 0.8635\n",
      "Epoch 29/50 - Train Loss: 348.2867 - Val Loss: 75.0767 - Train Acc: 0.9140 - Val Acc: 0.8734\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 30/50 - Train Loss: 339.3705 - Val Loss: 65.1798 - Train Acc: 0.9167 - Val Acc: 0.8816\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 31/50 - Train Loss: 331.8968 - Val Loss: 64.3104 - Train Acc: 0.9170 - Val Acc: 0.8738\n",
      "Epoch 32/50 - Train Loss: 322.6228 - Val Loss: 63.8539 - Train Acc: 0.9190 - Val Acc: 0.8847\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 33/50 - Train Loss: 312.4233 - Val Loss: 64.5964 - Train Acc: 0.9226 - Val Acc: 0.8822\n",
      "Epoch 34/50 - Train Loss: 305.6439 - Val Loss: 64.7581 - Train Acc: 0.9229 - Val Acc: 0.8862\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 35/50 - Train Loss: 297.5754 - Val Loss: 59.3274 - Train Acc: 0.9257 - Val Acc: 0.8815\n",
      "Epoch 36/50 - Train Loss: 286.4328 - Val Loss: 67.2451 - Train Acc: 0.9285 - Val Acc: 0.8851\n",
      "Epoch 37/50 - Train Loss: 289.0144 - Val Loss: 59.0384 - Train Acc: 0.9284 - Val Acc: 0.8830\n",
      "Epoch 38/50 - Train Loss: 277.2381 - Val Loss: 63.9898 - Train Acc: 0.9311 - Val Acc: 0.8832\n",
      "Epoch 39/50 - Train Loss: 270.2175 - Val Loss: 59.2560 - Train Acc: 0.9329 - Val Acc: 0.8897\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 40/50 - Train Loss: 268.9062 - Val Loss: 61.0168 - Train Acc: 0.9327 - Val Acc: 0.8883\n",
      "Epoch 41/50 - Train Loss: 261.7140 - Val Loss: 65.9300 - Train Acc: 0.9339 - Val Acc: 0.8826\n",
      "Epoch 42/50 - Train Loss: 258.4515 - Val Loss: 57.7651 - Train Acc: 0.9344 - Val Acc: 0.8910\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 43/50 - Train Loss: 258.6249 - Val Loss: 58.2193 - Train Acc: 0.9350 - Val Acc: 0.8885\n",
      "Epoch 44/50 - Train Loss: 254.8610 - Val Loss: 60.4472 - Train Acc: 0.9365 - Val Acc: 0.8839\n",
      "Epoch 45/50 - Train Loss: 246.1499 - Val Loss: 57.2738 - Train Acc: 0.9386 - Val Acc: 0.8912\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 46/50 - Train Loss: 244.8868 - Val Loss: 58.1497 - Train Acc: 0.9382 - Val Acc: 0.8910\n",
      "Epoch 47/50 - Train Loss: 242.9878 - Val Loss: 58.0715 - Train Acc: 0.9394 - Val Acc: 0.8935\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td30_Tw20.pth\n",
      "Epoch 48/50 - Train Loss: 244.4600 - Val Loss: 57.9853 - Train Acc: 0.9394 - Val Acc: 0.8914\n",
      "Epoch 49/50 - Train Loss: 246.2083 - Val Loss: 58.1789 - Train Acc: 0.9386 - Val Acc: 0.8912\n",
      "Epoch 50/50 - Train Loss: 241.0785 - Val Loss: 58.1789 - Train Acc: 0.9389 - Val Acc: 0.8912\n",
      "\n",
      "🚀 Running for Td=45, Tw=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/213766697.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4837, 2.4837, 2.4837, 2.4837, 2.4837, 2.4837, 2.4837, 2.4837, 2.4837,\n",
      "        2.4837, 2.4837, 2.4837], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 311.9090 - Val Loss: 29.9400 - Train Acc: 0.6420 - Val Acc: 0.6124\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 2/50 - Train Loss: 194.2908 - Val Loss: 25.0553 - Train Acc: 0.7728 - Val Acc: 0.7510\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 3/50 - Train Loss: 163.4268 - Val Loss: 25.6195 - Train Acc: 0.8060 - Val Acc: 0.6986\n",
      "Epoch 4/50 - Train Loss: 140.8958 - Val Loss: 18.8329 - Train Acc: 0.8343 - Val Acc: 0.7994\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 5/50 - Train Loss: 128.6935 - Val Loss: 20.5885 - Train Acc: 0.8485 - Val Acc: 0.7791\n",
      "Epoch 6/50 - Train Loss: 121.0768 - Val Loss: 17.4014 - Train Acc: 0.8627 - Val Acc: 0.7955\n",
      "Epoch 7/50 - Train Loss: 114.8772 - Val Loss: 16.0257 - Train Acc: 0.8675 - Val Acc: 0.8382\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 8/50 - Train Loss: 109.7202 - Val Loss: 23.0282 - Train Acc: 0.8721 - Val Acc: 0.7297\n",
      "Epoch 9/50 - Train Loss: 104.6452 - Val Loss: 15.1271 - Train Acc: 0.8766 - Val Acc: 0.8372\n",
      "Epoch 10/50 - Train Loss: 101.2476 - Val Loss: 16.2283 - Train Acc: 0.8823 - Val Acc: 0.8391\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 11/50 - Train Loss: 95.5549 - Val Loss: 18.2981 - Train Acc: 0.8876 - Val Acc: 0.7946\n",
      "Epoch 12/50 - Train Loss: 90.3614 - Val Loss: 16.8810 - Train Acc: 0.8963 - Val Acc: 0.8266\n",
      "Epoch 13/50 - Train Loss: 88.4666 - Val Loss: 16.1166 - Train Acc: 0.8973 - Val Acc: 0.8295\n",
      "Epoch 14/50 - Train Loss: 90.3997 - Val Loss: 16.0007 - Train Acc: 0.8958 - Val Acc: 0.8207\n",
      "Epoch 15/50 - Train Loss: 76.1422 - Val Loss: 15.0470 - Train Acc: 0.9138 - Val Acc: 0.8517\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 16/50 - Train Loss: 83.1274 - Val Loss: 14.3456 - Train Acc: 0.9049 - Val Acc: 0.8585\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 17/50 - Train Loss: 74.8061 - Val Loss: 13.6203 - Train Acc: 0.9124 - Val Acc: 0.8556\n",
      "Epoch 18/50 - Train Loss: 72.3116 - Val Loss: 13.7683 - Train Acc: 0.9177 - Val Acc: 0.8517\n",
      "Epoch 19/50 - Train Loss: 68.3261 - Val Loss: 14.5760 - Train Acc: 0.9208 - Val Acc: 0.8372\n",
      "Epoch 20/50 - Train Loss: 65.9710 - Val Loss: 11.7371 - Train Acc: 0.9227 - Val Acc: 0.8779\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 21/50 - Train Loss: 61.9414 - Val Loss: 13.5348 - Train Acc: 0.9293 - Val Acc: 0.8672\n",
      "Epoch 22/50 - Train Loss: 64.8741 - Val Loss: 11.2781 - Train Acc: 0.9242 - Val Acc: 0.8576\n",
      "Epoch 23/50 - Train Loss: 58.8274 - Val Loss: 12.4072 - Train Acc: 0.9320 - Val Acc: 0.8798\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 24/50 - Train Loss: 55.6603 - Val Loss: 11.5448 - Train Acc: 0.9377 - Val Acc: 0.8721\n",
      "Epoch 25/50 - Train Loss: 51.0341 - Val Loss: 11.4639 - Train Acc: 0.9428 - Val Acc: 0.8876\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 26/50 - Train Loss: 51.1207 - Val Loss: 14.4246 - Train Acc: 0.9423 - Val Acc: 0.8595\n",
      "Epoch 27/50 - Train Loss: 48.3924 - Val Loss: 10.9034 - Train Acc: 0.9443 - Val Acc: 0.8963\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 28/50 - Train Loss: 46.6403 - Val Loss: 10.7136 - Train Acc: 0.9467 - Val Acc: 0.9002\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 29/50 - Train Loss: 42.1180 - Val Loss: 10.8689 - Train Acc: 0.9544 - Val Acc: 0.8992\n",
      "Epoch 30/50 - Train Loss: 39.3027 - Val Loss: 10.3096 - Train Acc: 0.9571 - Val Acc: 0.9079\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 31/50 - Train Loss: 37.7220 - Val Loss: 9.4204 - Train Acc: 0.9572 - Val Acc: 0.9089\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 32/50 - Train Loss: 34.1875 - Val Loss: 10.0334 - Train Acc: 0.9587 - Val Acc: 0.9099\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 33/50 - Train Loss: 32.0348 - Val Loss: 8.4818 - Train Acc: 0.9651 - Val Acc: 0.9186\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 34/50 - Train Loss: 31.4695 - Val Loss: 10.0031 - Train Acc: 0.9659 - Val Acc: 0.9060\n",
      "Epoch 35/50 - Train Loss: 27.8267 - Val Loss: 8.8250 - Train Acc: 0.9690 - Val Acc: 0.9157\n",
      "Epoch 36/50 - Train Loss: 28.9386 - Val Loss: 9.2710 - Train Acc: 0.9685 - Val Acc: 0.9186\n",
      "Epoch 37/50 - Train Loss: 25.8606 - Val Loss: 9.3219 - Train Acc: 0.9707 - Val Acc: 0.9109\n",
      "Epoch 38/50 - Train Loss: 24.4560 - Val Loss: 8.6323 - Train Acc: 0.9708 - Val Acc: 0.9312\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw10.pth\n",
      "Epoch 39/50 - Train Loss: 23.1724 - Val Loss: 8.7917 - Train Acc: 0.9726 - Val Acc: 0.9157\n",
      "Epoch 40/50 - Train Loss: 22.2423 - Val Loss: 9.9563 - Train Acc: 0.9747 - Val Acc: 0.9157\n",
      "Epoch 41/50 - Train Loss: 20.6161 - Val Loss: 9.5061 - Train Acc: 0.9758 - Val Acc: 0.9128\n",
      "Epoch 42/50 - Train Loss: 19.3024 - Val Loss: 9.3215 - Train Acc: 0.9781 - Val Acc: 0.9244\n",
      "Epoch 43/50 - Train Loss: 19.6881 - Val Loss: 8.6189 - Train Acc: 0.9771 - Val Acc: 0.9234\n",
      "Epoch 44/50 - Train Loss: 19.0455 - Val Loss: 8.6580 - Train Acc: 0.9789 - Val Acc: 0.9234\n",
      "Epoch 45/50 - Train Loss: 17.7853 - Val Loss: 8.5052 - Train Acc: 0.9790 - Val Acc: 0.9293\n",
      "Epoch 46/50 - Train Loss: 17.4639 - Val Loss: 8.4856 - Train Acc: 0.9805 - Val Acc: 0.9264\n",
      "Epoch 47/50 - Train Loss: 16.1156 - Val Loss: 8.6383 - Train Acc: 0.9816 - Val Acc: 0.9283\n",
      "Epoch 48/50 - Train Loss: 16.9562 - Val Loss: 8.5773 - Train Acc: 0.9817 - Val Acc: 0.9264\n",
      "Epoch 49/50 - Train Loss: 16.7075 - Val Loss: 8.5934 - Train Acc: 0.9811 - Val Acc: 0.9273\n",
      "Epoch 50/50 - Train Loss: 16.7369 - Val Loss: 8.5934 - Train Acc: 0.9811 - Val Acc: 0.9273\n",
      "\n",
      "🚀 Running for Td=45, Tw=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/213766697.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4840, 2.4840, 2.4840, 2.4840, 2.4840, 2.4840, 2.4840, 2.4840, 2.4840,\n",
      "        2.4840, 2.4840, 2.4840], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 395.9564 - Val Loss: 38.1755 - Train Acc: 0.6484 - Val Acc: 0.6852\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 2/50 - Train Loss: 238.3484 - Val Loss: 47.2442 - Train Acc: 0.7788 - Val Acc: 0.6121\n",
      "Epoch 3/50 - Train Loss: 209.9999 - Val Loss: 29.9208 - Train Acc: 0.8071 - Val Acc: 0.7283\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 4/50 - Train Loss: 184.2100 - Val Loss: 29.4032 - Train Acc: 0.8289 - Val Acc: 0.7268\n",
      "Epoch 5/50 - Train Loss: 175.9933 - Val Loss: 24.5001 - Train Acc: 0.8426 - Val Acc: 0.7874\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 6/50 - Train Loss: 163.0370 - Val Loss: 31.4497 - Train Acc: 0.8537 - Val Acc: 0.7334\n",
      "Epoch 7/50 - Train Loss: 157.3632 - Val Loss: 26.4075 - Train Acc: 0.8626 - Val Acc: 0.7838\n",
      "Epoch 8/50 - Train Loss: 139.2425 - Val Loss: 28.8927 - Train Acc: 0.8755 - Val Acc: 0.7655\n",
      "Epoch 9/50 - Train Loss: 136.9973 - Val Loss: 22.5481 - Train Acc: 0.8788 - Val Acc: 0.8013\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 10/50 - Train Loss: 142.4271 - Val Loss: 26.9834 - Train Acc: 0.8735 - Val Acc: 0.7823\n",
      "Epoch 11/50 - Train Loss: 137.5700 - Val Loss: 23.3631 - Train Acc: 0.8821 - Val Acc: 0.7977\n",
      "Epoch 12/50 - Train Loss: 119.5067 - Val Loss: 36.9769 - Train Acc: 0.8939 - Val Acc: 0.7159\n",
      "Epoch 13/50 - Train Loss: 127.6447 - Val Loss: 20.8849 - Train Acc: 0.8865 - Val Acc: 0.8430\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 14/50 - Train Loss: 127.8149 - Val Loss: 21.6604 - Train Acc: 0.8862 - Val Acc: 0.8028\n",
      "Epoch 15/50 - Train Loss: 121.8554 - Val Loss: 18.9861 - Train Acc: 0.8933 - Val Acc: 0.8393\n",
      "Epoch 16/50 - Train Loss: 100.5665 - Val Loss: 18.8676 - Train Acc: 0.9120 - Val Acc: 0.8524\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 17/50 - Train Loss: 109.3703 - Val Loss: 22.5499 - Train Acc: 0.9041 - Val Acc: 0.8371\n",
      "Epoch 18/50 - Train Loss: 105.4651 - Val Loss: 20.9980 - Train Acc: 0.9076 - Val Acc: 0.8305\n",
      "Epoch 19/50 - Train Loss: 101.2140 - Val Loss: 19.0864 - Train Acc: 0.9116 - Val Acc: 0.8466\n",
      "Epoch 20/50 - Train Loss: 97.4166 - Val Loss: 17.2029 - Train Acc: 0.9135 - Val Acc: 0.8576\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 21/50 - Train Loss: 85.5964 - Val Loss: 16.4667 - Train Acc: 0.9259 - Val Acc: 0.8860\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 22/50 - Train Loss: 86.6061 - Val Loss: 16.1807 - Train Acc: 0.9237 - Val Acc: 0.8758\n",
      "Epoch 23/50 - Train Loss: 80.9047 - Val Loss: 15.9512 - Train Acc: 0.9274 - Val Acc: 0.8897\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 24/50 - Train Loss: 79.6740 - Val Loss: 16.9150 - Train Acc: 0.9312 - Val Acc: 0.8744\n",
      "Epoch 25/50 - Train Loss: 71.8230 - Val Loss: 16.5168 - Train Acc: 0.9364 - Val Acc: 0.8853\n",
      "Epoch 26/50 - Train Loss: 67.1412 - Val Loss: 15.9709 - Train Acc: 0.9410 - Val Acc: 0.8817\n",
      "Epoch 27/50 - Train Loss: 67.0985 - Val Loss: 14.9706 - Train Acc: 0.9419 - Val Acc: 0.8919\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 28/50 - Train Loss: 67.0913 - Val Loss: 14.6142 - Train Acc: 0.9431 - Val Acc: 0.9014\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 29/50 - Train Loss: 61.6645 - Val Loss: 14.5636 - Train Acc: 0.9460 - Val Acc: 0.8955\n",
      "Epoch 30/50 - Train Loss: 59.5996 - Val Loss: 15.2099 - Train Acc: 0.9477 - Val Acc: 0.8955\n",
      "Epoch 31/50 - Train Loss: 58.0497 - Val Loss: 17.8409 - Train Acc: 0.9485 - Val Acc: 0.8904\n",
      "Epoch 32/50 - Train Loss: 57.2898 - Val Loss: 14.6189 - Train Acc: 0.9491 - Val Acc: 0.9087\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 33/50 - Train Loss: 52.4381 - Val Loss: 13.1761 - Train Acc: 0.9541 - Val Acc: 0.9021\n",
      "Epoch 34/50 - Train Loss: 52.1649 - Val Loss: 16.9935 - Train Acc: 0.9547 - Val Acc: 0.8999\n",
      "Epoch 35/50 - Train Loss: 50.1854 - Val Loss: 12.6661 - Train Acc: 0.9573 - Val Acc: 0.9262\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 36/50 - Train Loss: 46.1528 - Val Loss: 13.9997 - Train Acc: 0.9603 - Val Acc: 0.9116\n",
      "Epoch 37/50 - Train Loss: 45.6875 - Val Loss: 12.7353 - Train Acc: 0.9616 - Val Acc: 0.9196\n",
      "Epoch 38/50 - Train Loss: 39.7429 - Val Loss: 18.1860 - Train Acc: 0.9670 - Val Acc: 0.9080\n",
      "Epoch 39/50 - Train Loss: 41.2564 - Val Loss: 12.4582 - Train Acc: 0.9660 - Val Acc: 0.9284\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 40/50 - Train Loss: 38.7019 - Val Loss: 13.1988 - Train Acc: 0.9672 - Val Acc: 0.9167\n",
      "Epoch 41/50 - Train Loss: 36.8472 - Val Loss: 12.7066 - Train Acc: 0.9689 - Val Acc: 0.9284\n",
      "Epoch 42/50 - Train Loss: 36.0165 - Val Loss: 13.6200 - Train Acc: 0.9699 - Val Acc: 0.9196\n",
      "Epoch 43/50 - Train Loss: 35.6088 - Val Loss: 12.6797 - Train Acc: 0.9695 - Val Acc: 0.9255\n",
      "Epoch 44/50 - Train Loss: 32.8752 - Val Loss: 12.0852 - Train Acc: 0.9718 - Val Acc: 0.9328\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw15.pth\n",
      "Epoch 45/50 - Train Loss: 32.0140 - Val Loss: 12.0325 - Train Acc: 0.9734 - Val Acc: 0.9291\n",
      "Epoch 46/50 - Train Loss: 32.7991 - Val Loss: 12.4603 - Train Acc: 0.9725 - Val Acc: 0.9299\n",
      "Epoch 47/50 - Train Loss: 32.8513 - Val Loss: 12.4349 - Train Acc: 0.9718 - Val Acc: 0.9306\n",
      "Epoch 48/50 - Train Loss: 32.9296 - Val Loss: 12.6803 - Train Acc: 0.9724 - Val Acc: 0.9284\n",
      "Epoch 49/50 - Train Loss: 33.0302 - Val Loss: 12.6179 - Train Acc: 0.9712 - Val Acc: 0.9284\n",
      "Epoch 50/50 - Train Loss: 32.0372 - Val Loss: 12.6179 - Train Acc: 0.9724 - Val Acc: 0.9284\n",
      "\n",
      "🚀 Running for Td=45, Tw=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/213766697.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4841, 2.4841, 2.4841, 2.4841, 2.4841, 2.4841, 2.4841, 2.4841, 2.4841,\n",
      "        2.4841, 2.4841, 2.4841], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 456.5804 - Val Loss: 40.9561 - Train Acc: 0.6529 - Val Acc: 0.6852\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 2/50 - Train Loss: 273.0977 - Val Loss: 34.5022 - Train Acc: 0.7877 - Val Acc: 0.7180\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 3/50 - Train Loss: 236.8279 - Val Loss: 46.4135 - Train Acc: 0.8118 - Val Acc: 0.6625\n",
      "Epoch 4/50 - Train Loss: 212.2429 - Val Loss: 35.0282 - Train Acc: 0.8352 - Val Acc: 0.7401\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 5/50 - Train Loss: 202.2456 - Val Loss: 30.5795 - Train Acc: 0.8444 - Val Acc: 0.7678\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 6/50 - Train Loss: 195.5631 - Val Loss: 30.6188 - Train Acc: 0.8480 - Val Acc: 0.7596\n",
      "Epoch 7/50 - Train Loss: 180.2011 - Val Loss: 25.5107 - Train Acc: 0.8644 - Val Acc: 0.7968\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 8/50 - Train Loss: 168.3792 - Val Loss: 31.1856 - Train Acc: 0.8733 - Val Acc: 0.7836\n",
      "Epoch 9/50 - Train Loss: 161.4900 - Val Loss: 26.6889 - Train Acc: 0.8785 - Val Acc: 0.8019\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 10/50 - Train Loss: 168.5139 - Val Loss: 25.7437 - Train Acc: 0.8743 - Val Acc: 0.8006\n",
      "Epoch 11/50 - Train Loss: 149.9264 - Val Loss: 24.2714 - Train Acc: 0.8857 - Val Acc: 0.8397\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 12/50 - Train Loss: 148.3503 - Val Loss: 29.1485 - Train Acc: 0.8889 - Val Acc: 0.7842\n",
      "Epoch 13/50 - Train Loss: 143.4823 - Val Loss: 24.9596 - Train Acc: 0.8902 - Val Acc: 0.8347\n",
      "Epoch 14/50 - Train Loss: 142.4445 - Val Loss: 24.2563 - Train Acc: 0.8939 - Val Acc: 0.8429\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 15/50 - Train Loss: 134.7193 - Val Loss: 24.4553 - Train Acc: 0.8994 - Val Acc: 0.8297\n",
      "Epoch 16/50 - Train Loss: 129.5950 - Val Loss: 24.0586 - Train Acc: 0.9019 - Val Acc: 0.8467\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 17/50 - Train Loss: 130.3037 - Val Loss: 20.7352 - Train Acc: 0.9030 - Val Acc: 0.8498\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 18/50 - Train Loss: 126.6411 - Val Loss: 22.1647 - Train Acc: 0.9032 - Val Acc: 0.8498\n",
      "Epoch 19/50 - Train Loss: 116.5147 - Val Loss: 26.9853 - Train Acc: 0.9115 - Val Acc: 0.8101\n",
      "Epoch 20/50 - Train Loss: 115.9242 - Val Loss: 21.2580 - Train Acc: 0.9099 - Val Acc: 0.8681\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 21/50 - Train Loss: 106.7245 - Val Loss: 19.9282 - Train Acc: 0.9196 - Val Acc: 0.8625\n",
      "Epoch 22/50 - Train Loss: 103.9428 - Val Loss: 19.0584 - Train Acc: 0.9201 - Val Acc: 0.8744\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 23/50 - Train Loss: 97.0471 - Val Loss: 19.2423 - Train Acc: 0.9257 - Val Acc: 0.8612\n",
      "Epoch 24/50 - Train Loss: 96.0951 - Val Loss: 20.0308 - Train Acc: 0.9261 - Val Acc: 0.8644\n",
      "Epoch 25/50 - Train Loss: 93.1298 - Val Loss: 19.1219 - Train Acc: 0.9292 - Val Acc: 0.8719\n",
      "Epoch 26/50 - Train Loss: 87.4452 - Val Loss: 20.3312 - Train Acc: 0.9339 - Val Acc: 0.8612\n",
      "Epoch 27/50 - Train Loss: 93.4186 - Val Loss: 20.0633 - Train Acc: 0.9303 - Val Acc: 0.8517\n",
      "Epoch 28/50 - Train Loss: 79.0535 - Val Loss: 16.9140 - Train Acc: 0.9376 - Val Acc: 0.8921\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 29/50 - Train Loss: 78.5198 - Val Loss: 17.7301 - Train Acc: 0.9404 - Val Acc: 0.8940\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 30/50 - Train Loss: 75.3634 - Val Loss: 19.0061 - Train Acc: 0.9419 - Val Acc: 0.8751\n",
      "Epoch 31/50 - Train Loss: 69.0111 - Val Loss: 17.1017 - Train Acc: 0.9466 - Val Acc: 0.8864\n",
      "Epoch 32/50 - Train Loss: 66.1737 - Val Loss: 18.9906 - Train Acc: 0.9492 - Val Acc: 0.8940\n",
      "Epoch 33/50 - Train Loss: 64.8153 - Val Loss: 17.2403 - Train Acc: 0.9507 - Val Acc: 0.8801\n",
      "Epoch 34/50 - Train Loss: 62.4331 - Val Loss: 15.2325 - Train Acc: 0.9525 - Val Acc: 0.8978\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 35/50 - Train Loss: 62.6851 - Val Loss: 16.3062 - Train Acc: 0.9512 - Val Acc: 0.9054\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 36/50 - Train Loss: 57.0839 - Val Loss: 14.3587 - Train Acc: 0.9571 - Val Acc: 0.9104\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 37/50 - Train Loss: 54.6569 - Val Loss: 14.7284 - Train Acc: 0.9582 - Val Acc: 0.9091\n",
      "Epoch 38/50 - Train Loss: 53.2529 - Val Loss: 13.8919 - Train Acc: 0.9591 - Val Acc: 0.9091\n",
      "Epoch 39/50 - Train Loss: 50.2696 - Val Loss: 14.1512 - Train Acc: 0.9629 - Val Acc: 0.9110\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 40/50 - Train Loss: 46.9526 - Val Loss: 13.9769 - Train Acc: 0.9631 - Val Acc: 0.9104\n",
      "Epoch 41/50 - Train Loss: 46.6775 - Val Loss: 13.6437 - Train Acc: 0.9635 - Val Acc: 0.9167\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td45_Tw20.pth\n",
      "Epoch 42/50 - Train Loss: 45.6649 - Val Loss: 15.2741 - Train Acc: 0.9646 - Val Acc: 0.9136\n",
      "Epoch 43/50 - Train Loss: 43.9963 - Val Loss: 15.0844 - Train Acc: 0.9664 - Val Acc: 0.9117\n",
      "Epoch 44/50 - Train Loss: 44.2993 - Val Loss: 14.5629 - Train Acc: 0.9664 - Val Acc: 0.9117\n",
      "Epoch 45/50 - Train Loss: 40.8763 - Val Loss: 14.1119 - Train Acc: 0.9688 - Val Acc: 0.9142\n",
      "Epoch 46/50 - Train Loss: 40.7062 - Val Loss: 13.7697 - Train Acc: 0.9678 - Val Acc: 0.9142\n",
      "Epoch 47/50 - Train Loss: 40.9988 - Val Loss: 14.0855 - Train Acc: 0.9690 - Val Acc: 0.9142\n",
      "Epoch 48/50 - Train Loss: 39.6203 - Val Loss: 14.0423 - Train Acc: 0.9705 - Val Acc: 0.9136\n",
      "Epoch 49/50 - Train Loss: 40.2934 - Val Loss: 14.0389 - Train Acc: 0.9694 - Val Acc: 0.9142\n",
      "Epoch 50/50 - Train Loss: 38.4093 - Val Loss: 14.0389 - Train Acc: 0.9702 - Val Acc: 0.9142\n",
      "\n",
      "🚀 Running for Td=60, Tw=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/213766697.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4832, 2.4832, 2.4832, 2.4832, 2.4832, 2.4832, 2.4832, 2.4832, 2.4832,\n",
      "        2.4832, 2.4832, 2.4832], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 291.1608 - Val Loss: 25.7114 - Train Acc: 0.5266 - Val Acc: 0.5706\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 2/50 - Train Loss: 136.1160 - Val Loss: 15.5064 - Train Acc: 0.7757 - Val Acc: 0.7540\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 3/50 - Train Loss: 113.8349 - Val Loss: 14.1567 - Train Acc: 0.8134 - Val Acc: 0.7409\n",
      "Epoch 4/50 - Train Loss: 98.4747 - Val Loss: 13.6073 - Train Acc: 0.8370 - Val Acc: 0.7380\n",
      "Epoch 5/50 - Train Loss: 88.4874 - Val Loss: 15.8671 - Train Acc: 0.8559 - Val Acc: 0.6841\n",
      "Epoch 6/50 - Train Loss: 82.8551 - Val Loss: 11.3984 - Train Acc: 0.8596 - Val Acc: 0.8108\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 7/50 - Train Loss: 82.9998 - Val Loss: 15.3993 - Train Acc: 0.8627 - Val Acc: 0.7656\n",
      "Epoch 8/50 - Train Loss: 75.9105 - Val Loss: 12.1476 - Train Acc: 0.8767 - Val Acc: 0.7817\n",
      "Epoch 9/50 - Train Loss: 66.4335 - Val Loss: 11.6317 - Train Acc: 0.8879 - Val Acc: 0.7962\n",
      "Epoch 10/50 - Train Loss: 68.3190 - Val Loss: 11.1333 - Train Acc: 0.8875 - Val Acc: 0.8253\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 11/50 - Train Loss: 58.9569 - Val Loss: 12.9087 - Train Acc: 0.8973 - Val Acc: 0.7744\n",
      "Epoch 12/50 - Train Loss: 60.5082 - Val Loss: 10.6170 - Train Acc: 0.8947 - Val Acc: 0.8137\n",
      "Epoch 13/50 - Train Loss: 54.1750 - Val Loss: 10.6461 - Train Acc: 0.9068 - Val Acc: 0.8472\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 14/50 - Train Loss: 55.4398 - Val Loss: 15.2515 - Train Acc: 0.9075 - Val Acc: 0.7744\n",
      "Epoch 15/50 - Train Loss: 49.4104 - Val Loss: 12.2124 - Train Acc: 0.9181 - Val Acc: 0.8311\n",
      "Epoch 16/50 - Train Loss: 50.0370 - Val Loss: 20.0648 - Train Acc: 0.9197 - Val Acc: 0.7438\n",
      "Epoch 17/50 - Train Loss: 50.6178 - Val Loss: 9.6141 - Train Acc: 0.9149 - Val Acc: 0.8486\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 18/50 - Train Loss: 46.8987 - Val Loss: 10.3068 - Train Acc: 0.9222 - Val Acc: 0.8588\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 19/50 - Train Loss: 44.5150 - Val Loss: 10.0999 - Train Acc: 0.9239 - Val Acc: 0.8617\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 20/50 - Train Loss: 40.7749 - Val Loss: 10.4139 - Train Acc: 0.9281 - Val Acc: 0.8501\n",
      "Epoch 21/50 - Train Loss: 34.9127 - Val Loss: 8.5183 - Train Acc: 0.9375 - Val Acc: 0.8836\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 22/50 - Train Loss: 36.4141 - Val Loss: 7.8806 - Train Acc: 0.9402 - Val Acc: 0.8821\n",
      "Epoch 23/50 - Train Loss: 32.7715 - Val Loss: 10.0139 - Train Acc: 0.9414 - Val Acc: 0.8690\n",
      "Epoch 24/50 - Train Loss: 30.7093 - Val Loss: 8.7896 - Train Acc: 0.9485 - Val Acc: 0.8821\n",
      "Epoch 25/50 - Train Loss: 31.1720 - Val Loss: 9.5501 - Train Acc: 0.9466 - Val Acc: 0.8763\n",
      "Epoch 26/50 - Train Loss: 27.7333 - Val Loss: 10.4829 - Train Acc: 0.9531 - Val Acc: 0.8705\n",
      "Epoch 27/50 - Train Loss: 27.1818 - Val Loss: 10.5627 - Train Acc: 0.9558 - Val Acc: 0.8894\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 28/50 - Train Loss: 29.4086 - Val Loss: 9.7081 - Train Acc: 0.9533 - Val Acc: 0.8850\n",
      "Epoch 29/50 - Train Loss: 23.5431 - Val Loss: 8.6844 - Train Acc: 0.9622 - Val Acc: 0.8967\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 30/50 - Train Loss: 22.3001 - Val Loss: 9.4417 - Train Acc: 0.9638 - Val Acc: 0.9112\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 31/50 - Train Loss: 20.3985 - Val Loss: 10.1006 - Train Acc: 0.9654 - Val Acc: 0.9010\n",
      "Epoch 32/50 - Train Loss: 17.2203 - Val Loss: 8.7850 - Train Acc: 0.9715 - Val Acc: 0.8981\n",
      "Epoch 33/50 - Train Loss: 18.9764 - Val Loss: 11.1977 - Train Acc: 0.9683 - Val Acc: 0.8719\n",
      "Epoch 34/50 - Train Loss: 16.5077 - Val Loss: 7.8169 - Train Acc: 0.9733 - Val Acc: 0.9098\n",
      "Epoch 35/50 - Train Loss: 15.7602 - Val Loss: 10.2066 - Train Acc: 0.9740 - Val Acc: 0.9054\n",
      "Epoch 36/50 - Train Loss: 14.3638 - Val Loss: 8.4741 - Train Acc: 0.9770 - Val Acc: 0.9185\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 37/50 - Train Loss: 12.1782 - Val Loss: 10.1426 - Train Acc: 0.9795 - Val Acc: 0.9083\n",
      "Epoch 38/50 - Train Loss: 13.6624 - Val Loss: 9.0639 - Train Acc: 0.9770 - Val Acc: 0.9083\n",
      "Epoch 39/50 - Train Loss: 12.1504 - Val Loss: 8.0330 - Train Acc: 0.9798 - Val Acc: 0.9156\n",
      "Epoch 40/50 - Train Loss: 11.4901 - Val Loss: 9.0070 - Train Acc: 0.9827 - Val Acc: 0.9185\n",
      "Epoch 41/50 - Train Loss: 10.0231 - Val Loss: 8.3833 - Train Acc: 0.9827 - Val Acc: 0.9156\n",
      "Epoch 42/50 - Train Loss: 9.7125 - Val Loss: 9.0451 - Train Acc: 0.9853 - Val Acc: 0.9083\n",
      "Epoch 43/50 - Train Loss: 8.0817 - Val Loss: 8.8451 - Train Acc: 0.9869 - Val Acc: 0.9127\n",
      "Epoch 44/50 - Train Loss: 9.0696 - Val Loss: 8.7047 - Train Acc: 0.9855 - Val Acc: 0.9185\n",
      "Epoch 45/50 - Train Loss: 8.5208 - Val Loss: 8.6897 - Train Acc: 0.9871 - Val Acc: 0.9170\n",
      "Epoch 46/50 - Train Loss: 8.2815 - Val Loss: 8.5886 - Train Acc: 0.9862 - Val Acc: 0.9185\n",
      "Epoch 47/50 - Train Loss: 7.4087 - Val Loss: 8.6102 - Train Acc: 0.9885 - Val Acc: 0.9170\n",
      "Epoch 48/50 - Train Loss: 7.9431 - Val Loss: 8.5584 - Train Acc: 0.9861 - Val Acc: 0.9214\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 49/50 - Train Loss: 8.0824 - Val Loss: 8.5515 - Train Acc: 0.9868 - Val Acc: 0.9229\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw10.pth\n",
      "Epoch 50/50 - Train Loss: 7.1474 - Val Loss: 8.5515 - Train Acc: 0.9887 - Val Acc: 0.9229\n",
      "\n",
      "🚀 Running for Td=60, Tw=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/213766697.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4834, 2.4834, 2.4834, 2.4834, 2.4834, 2.4834, 2.4834, 2.4834, 2.4834,\n",
      "        2.4834, 2.4834, 2.4834], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 268.7120 - Val Loss: 23.8708 - Train Acc: 0.6108 - Val Acc: 0.6367\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 2/50 - Train Loss: 143.7432 - Val Loss: 21.4690 - Train Acc: 0.7871 - Val Acc: 0.6861\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 3/50 - Train Loss: 122.9996 - Val Loss: 18.8074 - Train Acc: 0.8133 - Val Acc: 0.7089\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 4/50 - Train Loss: 111.3475 - Val Loss: 15.7998 - Train Acc: 0.8318 - Val Acc: 0.7266\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 5/50 - Train Loss: 100.9744 - Val Loss: 15.6899 - Train Acc: 0.8505 - Val Acc: 0.7481\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 6/50 - Train Loss: 92.8111 - Val Loss: 16.5173 - Train Acc: 0.8576 - Val Acc: 0.7557\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 7/50 - Train Loss: 91.6626 - Val Loss: 18.4341 - Train Acc: 0.8618 - Val Acc: 0.7215\n",
      "Epoch 8/50 - Train Loss: 82.4814 - Val Loss: 11.5638 - Train Acc: 0.8742 - Val Acc: 0.8101\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 9/50 - Train Loss: 74.0530 - Val Loss: 16.5581 - Train Acc: 0.8886 - Val Acc: 0.7582\n",
      "Epoch 10/50 - Train Loss: 73.4745 - Val Loss: 11.5551 - Train Acc: 0.8929 - Val Acc: 0.8316\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 11/50 - Train Loss: 67.2165 - Val Loss: 10.8767 - Train Acc: 0.8982 - Val Acc: 0.8380\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 12/50 - Train Loss: 62.8660 - Val Loss: 10.5241 - Train Acc: 0.9034 - Val Acc: 0.8519\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 13/50 - Train Loss: 65.1180 - Val Loss: 9.7172 - Train Acc: 0.9029 - Val Acc: 0.8734\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 14/50 - Train Loss: 58.0382 - Val Loss: 11.4353 - Train Acc: 0.9095 - Val Acc: 0.8177\n",
      "Epoch 15/50 - Train Loss: 57.3036 - Val Loss: 9.9569 - Train Acc: 0.9133 - Val Acc: 0.8671\n",
      "Epoch 16/50 - Train Loss: 56.2109 - Val Loss: 10.4724 - Train Acc: 0.9197 - Val Acc: 0.8696\n",
      "Epoch 17/50 - Train Loss: 51.1672 - Val Loss: 8.3566 - Train Acc: 0.9259 - Val Acc: 0.8924\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 18/50 - Train Loss: 47.8798 - Val Loss: 9.2127 - Train Acc: 0.9257 - Val Acc: 0.8785\n",
      "Epoch 19/50 - Train Loss: 47.4840 - Val Loss: 11.7809 - Train Acc: 0.9312 - Val Acc: 0.8620\n",
      "Epoch 20/50 - Train Loss: 47.5122 - Val Loss: 7.0837 - Train Acc: 0.9312 - Val Acc: 0.9013\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 21/50 - Train Loss: 39.5059 - Val Loss: 13.4120 - Train Acc: 0.9405 - Val Acc: 0.8190\n",
      "Epoch 22/50 - Train Loss: 40.0385 - Val Loss: 8.9960 - Train Acc: 0.9421 - Val Acc: 0.9101\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 23/50 - Train Loss: 41.9948 - Val Loss: 10.2735 - Train Acc: 0.9386 - Val Acc: 0.8646\n",
      "Epoch 24/50 - Train Loss: 37.5501 - Val Loss: 8.3722 - Train Acc: 0.9457 - Val Acc: 0.9000\n",
      "Epoch 25/50 - Train Loss: 35.3042 - Val Loss: 9.6319 - Train Acc: 0.9489 - Val Acc: 0.8848\n",
      "Epoch 26/50 - Train Loss: 30.9263 - Val Loss: 8.8314 - Train Acc: 0.9566 - Val Acc: 0.8835\n",
      "Epoch 27/50 - Train Loss: 31.0976 - Val Loss: 8.8311 - Train Acc: 0.9553 - Val Acc: 0.9089\n",
      "Epoch 28/50 - Train Loss: 29.3868 - Val Loss: 8.7280 - Train Acc: 0.9590 - Val Acc: 0.9165\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 29/50 - Train Loss: 28.0303 - Val Loss: 7.6761 - Train Acc: 0.9588 - Val Acc: 0.9177\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 30/50 - Train Loss: 24.8948 - Val Loss: 8.5115 - Train Acc: 0.9640 - Val Acc: 0.9139\n",
      "Epoch 31/50 - Train Loss: 23.3203 - Val Loss: 7.9556 - Train Acc: 0.9640 - Val Acc: 0.9076\n",
      "Epoch 32/50 - Train Loss: 20.3593 - Val Loss: 6.2017 - Train Acc: 0.9697 - Val Acc: 0.9241\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 33/50 - Train Loss: 21.6141 - Val Loss: 8.0902 - Train Acc: 0.9688 - Val Acc: 0.9165\n",
      "Epoch 34/50 - Train Loss: 18.6680 - Val Loss: 7.1431 - Train Acc: 0.9737 - Val Acc: 0.9203\n",
      "Epoch 35/50 - Train Loss: 17.3571 - Val Loss: 6.3139 - Train Acc: 0.9759 - Val Acc: 0.9291\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 36/50 - Train Loss: 15.9567 - Val Loss: 5.5972 - Train Acc: 0.9768 - Val Acc: 0.9380\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 37/50 - Train Loss: 14.3592 - Val Loss: 5.4061 - Train Acc: 0.9794 - Val Acc: 0.9291\n",
      "Epoch 38/50 - Train Loss: 13.3465 - Val Loss: 7.0760 - Train Acc: 0.9812 - Val Acc: 0.9354\n",
      "Epoch 39/50 - Train Loss: 13.2815 - Val Loss: 6.0308 - Train Acc: 0.9816 - Val Acc: 0.9291\n",
      "Epoch 40/50 - Train Loss: 13.0304 - Val Loss: 6.8574 - Train Acc: 0.9816 - Val Acc: 0.9291\n",
      "Epoch 41/50 - Train Loss: 12.4190 - Val Loss: 6.4490 - Train Acc: 0.9808 - Val Acc: 0.9329\n",
      "Epoch 42/50 - Train Loss: 9.4824 - Val Loss: 5.8299 - Train Acc: 0.9876 - Val Acc: 0.9367\n",
      "Epoch 43/50 - Train Loss: 10.9320 - Val Loss: 6.0527 - Train Acc: 0.9856 - Val Acc: 0.9367\n",
      "Epoch 44/50 - Train Loss: 9.6543 - Val Loss: 6.2569 - Train Acc: 0.9865 - Val Acc: 0.9367\n",
      "Epoch 45/50 - Train Loss: 9.1776 - Val Loss: 6.1881 - Train Acc: 0.9863 - Val Acc: 0.9380\n",
      "Epoch 46/50 - Train Loss: 9.0158 - Val Loss: 6.2289 - Train Acc: 0.9881 - Val Acc: 0.9380\n",
      "Epoch 47/50 - Train Loss: 8.9252 - Val Loss: 6.2336 - Train Acc: 0.9877 - Val Acc: 0.9392\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw15.pth\n",
      "Epoch 48/50 - Train Loss: 8.9211 - Val Loss: 6.1545 - Train Acc: 0.9873 - Val Acc: 0.9392\n",
      "Epoch 49/50 - Train Loss: 8.6603 - Val Loss: 6.1421 - Train Acc: 0.9872 - Val Acc: 0.9392\n",
      "Epoch 50/50 - Train Loss: 8.6566 - Val Loss: 6.1421 - Train Acc: 0.9871 - Val Acc: 0.9392\n",
      "\n",
      "🚀 Running for Td=60, Tw=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/213766697.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4835, 2.4835, 2.4835, 2.4835, 2.4835, 2.4835, 2.4835, 2.4835, 2.4835,\n",
      "        2.4835, 2.4835, 2.4835], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 300.8287 - Val Loss: 25.6997 - Train Acc: 0.5956 - Val Acc: 0.6218\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 2/50 - Train Loss: 160.4579 - Val Loss: 22.8530 - Train Acc: 0.7868 - Val Acc: 0.6616\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 3/50 - Train Loss: 134.4231 - Val Loss: 16.3399 - Train Acc: 0.8100 - Val Acc: 0.7717\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 4/50 - Train Loss: 117.9616 - Val Loss: 14.8309 - Train Acc: 0.8365 - Val Acc: 0.7822\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 5/50 - Train Loss: 104.6295 - Val Loss: 23.4134 - Train Acc: 0.8569 - Val Acc: 0.6710\n",
      "Epoch 6/50 - Train Loss: 99.2899 - Val Loss: 16.0779 - Train Acc: 0.8641 - Val Acc: 0.7728\n",
      "Epoch 7/50 - Train Loss: 89.9430 - Val Loss: 13.2886 - Train Acc: 0.8760 - Val Acc: 0.8244\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 8/50 - Train Loss: 84.8369 - Val Loss: 15.1006 - Train Acc: 0.8830 - Val Acc: 0.7904\n",
      "Epoch 9/50 - Train Loss: 78.8687 - Val Loss: 13.9177 - Train Acc: 0.8900 - Val Acc: 0.8290\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 10/50 - Train Loss: 71.8009 - Val Loss: 16.0095 - Train Acc: 0.8992 - Val Acc: 0.7963\n",
      "Epoch 11/50 - Train Loss: 83.4490 - Val Loss: 14.0860 - Train Acc: 0.8888 - Val Acc: 0.8091\n",
      "Epoch 12/50 - Train Loss: 77.2887 - Val Loss: 13.4977 - Train Acc: 0.8989 - Val Acc: 0.8443\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 13/50 - Train Loss: 70.1468 - Val Loss: 15.9885 - Train Acc: 0.9037 - Val Acc: 0.8044\n",
      "Epoch 14/50 - Train Loss: 64.1854 - Val Loss: 11.5033 - Train Acc: 0.9118 - Val Acc: 0.8759\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 15/50 - Train Loss: 66.5786 - Val Loss: 10.9637 - Train Acc: 0.9103 - Val Acc: 0.8712\n",
      "Epoch 16/50 - Train Loss: 63.6232 - Val Loss: 13.9970 - Train Acc: 0.9120 - Val Acc: 0.8454\n",
      "Epoch 17/50 - Train Loss: 59.0041 - Val Loss: 11.0218 - Train Acc: 0.9225 - Val Acc: 0.8536\n",
      "Epoch 18/50 - Train Loss: 56.2750 - Val Loss: 12.0593 - Train Acc: 0.9214 - Val Acc: 0.8454\n",
      "Epoch 19/50 - Train Loss: 57.3016 - Val Loss: 16.0546 - Train Acc: 0.9266 - Val Acc: 0.8513\n",
      "Epoch 20/50 - Train Loss: 52.8155 - Val Loss: 11.3789 - Train Acc: 0.9319 - Val Acc: 0.8595\n",
      "Epoch 21/50 - Train Loss: 52.3559 - Val Loss: 11.2884 - Train Acc: 0.9318 - Val Acc: 0.8630\n",
      "Epoch 22/50 - Train Loss: 48.0219 - Val Loss: 10.0063 - Train Acc: 0.9391 - Val Acc: 0.8911\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 23/50 - Train Loss: 47.3746 - Val Loss: 13.0920 - Train Acc: 0.9390 - Val Acc: 0.8829\n",
      "Epoch 24/50 - Train Loss: 42.1929 - Val Loss: 10.7723 - Train Acc: 0.9448 - Val Acc: 0.8864\n",
      "Epoch 25/50 - Train Loss: 42.0793 - Val Loss: 11.4951 - Train Acc: 0.9441 - Val Acc: 0.8970\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 26/50 - Train Loss: 43.8134 - Val Loss: 10.1713 - Train Acc: 0.9422 - Val Acc: 0.8841\n",
      "Epoch 27/50 - Train Loss: 36.8620 - Val Loss: 11.1461 - Train Acc: 0.9518 - Val Acc: 0.8970\n",
      "Epoch 28/50 - Train Loss: 32.1918 - Val Loss: 12.1518 - Train Acc: 0.9578 - Val Acc: 0.8993\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 29/50 - Train Loss: 35.6060 - Val Loss: 10.7066 - Train Acc: 0.9538 - Val Acc: 0.9063\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 30/50 - Train Loss: 27.9219 - Val Loss: 9.7710 - Train Acc: 0.9628 - Val Acc: 0.9180\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 31/50 - Train Loss: 28.6489 - Val Loss: 11.1825 - Train Acc: 0.9644 - Val Acc: 0.8888\n",
      "Epoch 32/50 - Train Loss: 25.8989 - Val Loss: 8.5657 - Train Acc: 0.9649 - Val Acc: 0.9180\n",
      "Epoch 33/50 - Train Loss: 25.8726 - Val Loss: 10.2958 - Train Acc: 0.9653 - Val Acc: 0.8946\n",
      "Epoch 34/50 - Train Loss: 22.9129 - Val Loss: 10.0077 - Train Acc: 0.9713 - Val Acc: 0.9157\n",
      "Epoch 35/50 - Train Loss: 23.3298 - Val Loss: 10.3547 - Train Acc: 0.9681 - Val Acc: 0.9005\n",
      "Epoch 36/50 - Train Loss: 22.2870 - Val Loss: 10.0421 - Train Acc: 0.9701 - Val Acc: 0.9133\n",
      "Epoch 37/50 - Train Loss: 21.4625 - Val Loss: 9.8990 - Train Acc: 0.9736 - Val Acc: 0.9122\n",
      "Epoch 38/50 - Train Loss: 19.8813 - Val Loss: 8.9585 - Train Acc: 0.9729 - Val Acc: 0.9251\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 39/50 - Train Loss: 17.1191 - Val Loss: 8.9606 - Train Acc: 0.9772 - Val Acc: 0.9333\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/teacher/transformer_Td60_Tw20.pth\n",
      "Epoch 40/50 - Train Loss: 17.2265 - Val Loss: 9.1593 - Train Acc: 0.9772 - Val Acc: 0.9262\n",
      "Epoch 41/50 - Train Loss: 15.9306 - Val Loss: 8.4507 - Train Acc: 0.9784 - Val Acc: 0.9262\n",
      "Epoch 42/50 - Train Loss: 16.1677 - Val Loss: 9.5665 - Train Acc: 0.9804 - Val Acc: 0.9274\n",
      "Epoch 43/50 - Train Loss: 15.6437 - Val Loss: 9.8145 - Train Acc: 0.9795 - Val Acc: 0.9309\n",
      "Epoch 44/50 - Train Loss: 16.0158 - Val Loss: 10.1383 - Train Acc: 0.9772 - Val Acc: 0.9262\n",
      "Epoch 45/50 - Train Loss: 14.5546 - Val Loss: 9.7850 - Train Acc: 0.9806 - Val Acc: 0.9274\n",
      "Epoch 46/50 - Train Loss: 14.3815 - Val Loss: 9.0938 - Train Acc: 0.9810 - Val Acc: 0.9297\n",
      "Epoch 47/50 - Train Loss: 13.1082 - Val Loss: 9.6672 - Train Acc: 0.9845 - Val Acc: 0.9309\n",
      "Epoch 48/50 - Train Loss: 12.4208 - Val Loss: 9.6159 - Train Acc: 0.9841 - Val Acc: 0.9309\n",
      "Epoch 49/50 - Train Loss: 13.1949 - Val Loss: 9.6251 - Train Acc: 0.9825 - Val Acc: 0.9309\n",
      "Epoch 50/50 - Train Loss: 13.2254 - Val Loss: 9.6251 - Train Acc: 0.9834 - Val Acc: 0.9309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/213766697.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"/home/HardDisk/Satang/thesis_proj\"\n",
    "detection_times = [30, 45, 60]\n",
    "window_sizes = [10, 15, 20]\n",
    "save_root = \"/home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer\"\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "for T_d in detection_times:\n",
    "    for T_w in window_sizes:\n",
    "        print(f\"\\n🚀 Running for Td={T_d}, Tw={T_w}\")\n",
    "        model_name = os.path.join(save_root, f\"teacher/transformer_Td{T_d}_Tw{T_w}.pth\")\n",
    "        T_len = T_d - T_w + 1  # This determines expected shape and directory name\n",
    "        folder_name = f\"X_csv_split_{T_len}\"\n",
    "\n",
    "        input_dir = os.path.join(base_dir, f\"New_{T_d}\", f\"{T_w}\", \"split_tws\", folder_name)\n",
    "        train_path = os.path.join(input_dir, \"train\")\n",
    "        val_path   = os.path.join(input_dir, \"val\")\n",
    "\n",
    "        # === 1. Load Data ===\n",
    "        expected_shape = (T_len, NUM_FEATURES)\n",
    "        X_train_raw, y_train_raw = load_split_from_folder(train_path, expected_shape)\n",
    "        X_val_raw, y_val_raw     = load_split_from_folder(val_path, expected_shape)\n",
    "\n",
    "        # === 2. SMOTE + Encode ===\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_encoded = label_encoder.fit_transform(y_train_raw)\n",
    "        X_train_flat = X_train_raw.reshape(X_train_raw.shape[0], -1)\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X_train_flat, y_train_encoded)\n",
    "        X_train_bal = X_resampled.reshape(-1, expected_shape[0], NUM_FEATURES)\n",
    "        y_train_str = label_encoder.inverse_transform(y_resampled)\n",
    "\n",
    "        # === 3. Datasets + Loaders ===\n",
    "        train_dataset = MultiStreamDataset(X_train_bal, y_train_str, label_encoder, augment=True)\n",
    "        val_dataset   = MultiStreamDataset(X_val_raw, y_val_raw, label_encoder, augment=False)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # === 4. Transformer Model ===\n",
    "        model = RansomwareTransformer(\n",
    "            input_dim=NUM_FEATURES,\n",
    "            seq_len=expected_shape[0],\n",
    "            num_classes=len(label_encoder.classes_)\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "        class_weights_tensor = compute_class_weights(label_encoder.transform(y_train_str), device)\n",
    "\n",
    "        train_accs, val_accs, train_losses, val_losses = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            device=device,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            class_weights=class_weights_tensor,\n",
    "            lr=0.01,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            best_model_path=model_name\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "878a2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class StudentCNN(nn.Module):\n",
    "    def __init__(self, input_length, num_classes=12):\n",
    "        super().__init__()\n",
    "        self.streams = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(1, 4, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(4, 8, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool1d(1),\n",
    "                nn.Flatten()\n",
    "            ) for _ in range(8)\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8 * 8, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        # 🔄 Smaller projection for feature distillation\n",
    "        self.proj = nn.Linear(8 * 8, 128)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        # ✅ x is shape (B, T, 8) — same as Transformer input\n",
    "        B, T, C = x.shape\n",
    "        assert C == 8, f\"Expected 8 feature streams, got {C}\"\n",
    "\n",
    "        # Split into 8 (B, 1, T) tensors for each stream\n",
    "        streams = [x[:, :, i].unsqueeze(1) for i in range(C)]  # (B, 1, T)\n",
    "\n",
    "        # Apply each stream's CNN\n",
    "        features = [self.streams[i](streams[i]) for i in range(8)]  # 8 × (B, 8)\n",
    "        x = torch.cat(features, dim=1)  # (B, 64)\n",
    "\n",
    "        if return_features:\n",
    "            feat_proj = self.proj(x)  # (B, 128)\n",
    "            return self.fc(x), feat_proj\n",
    "\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ca8520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def distillation_loss(student_logits, teacher_logits, student_feat, teacher_feat, true_labels, T=3.0, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "    \"\"\"\n",
    "    alpha: weight for hard loss (CE)\n",
    "    beta: weight for soft loss (KL)\n",
    "    gamma: weight for feature-based distillation (MSE)\n",
    "    T: temperature for soft distillation\n",
    "    \"\"\"\n",
    "    # Hard loss\n",
    "    ce_loss = F.cross_entropy(student_logits, true_labels)\n",
    "\n",
    "    # Soft loss (logits)\n",
    "    soft_teacher = F.softmax(teacher_logits / T, dim=1)\n",
    "    soft_student = F.log_softmax(student_logits / T, dim=1)\n",
    "    kl_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (T * T)\n",
    "\n",
    "    # Feature loss (projection-matched MSE)\n",
    "    feat_loss = F.mse_loss(student_feat, teacher_feat)\n",
    "\n",
    "    return alpha * ce_loss + beta * kl_loss + gamma * feat_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a339fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_distilled(student, teacher, train_loader, val_loader, device,\n",
    "                    epochs=50, lr=0.0005, class_weights=None,\n",
    "                    T=2.0, alpha=0.2, beta=0.2, gamma=0.2,\n",
    "                    save_path=\"best_student.pth\"):\n",
    "\n",
    "    teacher.eval()\n",
    "    student.to(device)\n",
    "    teacher.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(student.parameters(), lr=lr)\n",
    "    ce_criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    train_losses, train_accuracies, val_accuracies, val_losses = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss, correct = 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:  # ✅ inputs: (B, T, 8)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            student_logits, student_feat = student(inputs, return_features=True)\n",
    "            with torch.no_grad():\n",
    "                teacher_logits, teacher_feat = teacher(inputs, return_features=True)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = distillation_loss(\n",
    "                student_logits, teacher_logits,\n",
    "                student_feat, teacher_feat,\n",
    "                labels,\n",
    "                T=T, alpha=alpha, beta=beta, gamma=gamma\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (student_logits.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(total_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # === Validation ===\n",
    "        student.eval()\n",
    "        val_correct = 0\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = student(inputs)\n",
    "                loss = ce_criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / len(val_loader.dataset)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"[Distill] Epoch {epoch+1:02d}/{epochs} - Loss: {total_loss:.4f} \"\n",
    "              f\"- Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Save best student model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(student.state_dict(), save_path)\n",
    "            print(f\"💾 Best student model saved to: {save_path}\")\n",
    "\n",
    "    student.load_state_dict(torch.load(save_path))\n",
    "    return train_accuracies, val_accuracies, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd2a7c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training Student for Td=30, Tw=10 (T_len=21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/4080983537.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 2187.9115 - Train Acc: 0.3338 - Val Acc: 0.4674\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1409.1232 - Train Acc: 0.6088 - Val Acc: 0.5566\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 03/50 - Loss: 1117.8612 - Train Acc: 0.6663 - Val Acc: 0.5932\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 04/50 - Loss: 959.4028 - Train Acc: 0.6926 - Val Acc: 0.6037\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 05/50 - Loss: 857.2742 - Train Acc: 0.7111 - Val Acc: 0.6202\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 06/50 - Loss: 788.4704 - Train Acc: 0.7173 - Val Acc: 0.6122\n",
      "[Distill] Epoch 07/50 - Loss: 732.9306 - Train Acc: 0.7295 - Val Acc: 0.6388\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 08/50 - Loss: 689.5982 - Train Acc: 0.7384 - Val Acc: 0.6403\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 09/50 - Loss: 653.0552 - Train Acc: 0.7487 - Val Acc: 0.6558\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 10/50 - Loss: 619.5974 - Train Acc: 0.7542 - Val Acc: 0.6558\n",
      "[Distill] Epoch 11/50 - Loss: 588.4233 - Train Acc: 0.7618 - Val Acc: 0.6748\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 12/50 - Loss: 560.6300 - Train Acc: 0.7672 - Val Acc: 0.6949\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 13/50 - Loss: 535.7252 - Train Acc: 0.7761 - Val Acc: 0.7034\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 14/50 - Loss: 514.9076 - Train Acc: 0.7809 - Val Acc: 0.6929\n",
      "[Distill] Epoch 15/50 - Loss: 491.5030 - Train Acc: 0.7880 - Val Acc: 0.7360\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 16/50 - Loss: 473.1347 - Train Acc: 0.7940 - Val Acc: 0.7214\n",
      "[Distill] Epoch 17/50 - Loss: 453.6995 - Train Acc: 0.8021 - Val Acc: 0.7219\n",
      "[Distill] Epoch 18/50 - Loss: 439.0046 - Train Acc: 0.8085 - Val Acc: 0.7325\n",
      "[Distill] Epoch 19/50 - Loss: 424.2030 - Train Acc: 0.8146 - Val Acc: 0.7580\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 20/50 - Loss: 411.8649 - Train Acc: 0.8146 - Val Acc: 0.7640\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 21/50 - Loss: 400.5056 - Train Acc: 0.8228 - Val Acc: 0.7655\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 22/50 - Loss: 387.5943 - Train Acc: 0.8259 - Val Acc: 0.7725\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 23/50 - Loss: 382.9984 - Train Acc: 0.8315 - Val Acc: 0.7786\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 24/50 - Loss: 373.4536 - Train Acc: 0.8301 - Val Acc: 0.7725\n",
      "[Distill] Epoch 25/50 - Loss: 363.2450 - Train Acc: 0.8394 - Val Acc: 0.7986\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 26/50 - Loss: 356.1053 - Train Acc: 0.8409 - Val Acc: 0.8051\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 27/50 - Loss: 349.2415 - Train Acc: 0.8416 - Val Acc: 0.8071\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 28/50 - Loss: 343.0353 - Train Acc: 0.8439 - Val Acc: 0.8146\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 29/50 - Loss: 338.3677 - Train Acc: 0.8466 - Val Acc: 0.7625\n",
      "[Distill] Epoch 30/50 - Loss: 331.4055 - Train Acc: 0.8516 - Val Acc: 0.7806\n",
      "[Distill] Epoch 31/50 - Loss: 327.4145 - Train Acc: 0.8507 - Val Acc: 0.8046\n",
      "[Distill] Epoch 32/50 - Loss: 322.2481 - Train Acc: 0.8532 - Val Acc: 0.8011\n",
      "[Distill] Epoch 33/50 - Loss: 314.6348 - Train Acc: 0.8575 - Val Acc: 0.8046\n",
      "[Distill] Epoch 34/50 - Loss: 314.9517 - Train Acc: 0.8532 - Val Acc: 0.8337\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 35/50 - Loss: 309.0638 - Train Acc: 0.8599 - Val Acc: 0.8407\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 36/50 - Loss: 303.9202 - Train Acc: 0.8624 - Val Acc: 0.8512\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 37/50 - Loss: 301.2763 - Train Acc: 0.8630 - Val Acc: 0.8437\n",
      "[Distill] Epoch 38/50 - Loss: 296.3850 - Train Acc: 0.8631 - Val Acc: 0.8372\n",
      "[Distill] Epoch 39/50 - Loss: 294.2051 - Train Acc: 0.8651 - Val Acc: 0.8377\n",
      "[Distill] Epoch 40/50 - Loss: 288.8446 - Train Acc: 0.8673 - Val Acc: 0.8332\n",
      "[Distill] Epoch 41/50 - Loss: 285.4680 - Train Acc: 0.8687 - Val Acc: 0.8367\n",
      "[Distill] Epoch 42/50 - Loss: 281.5591 - Train Acc: 0.8714 - Val Acc: 0.8191\n",
      "[Distill] Epoch 43/50 - Loss: 282.3243 - Train Acc: 0.8696 - Val Acc: 0.8532\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 44/50 - Loss: 276.4040 - Train Acc: 0.8742 - Val Acc: 0.8577\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 45/50 - Loss: 272.7548 - Train Acc: 0.8739 - Val Acc: 0.8417\n",
      "[Distill] Epoch 46/50 - Loss: 274.7256 - Train Acc: 0.8743 - Val Acc: 0.8542\n",
      "[Distill] Epoch 47/50 - Loss: 268.9949 - Train Acc: 0.8744 - Val Acc: 0.8482\n",
      "[Distill] Epoch 48/50 - Loss: 267.1480 - Train Acc: 0.8735 - Val Acc: 0.8547\n",
      "[Distill] Epoch 49/50 - Loss: 264.6922 - Train Acc: 0.8772 - Val Acc: 0.8642\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "[Distill] Epoch 50/50 - Loss: 261.4810 - Train Acc: 0.8777 - Val Acc: 0.8567\n",
      "\n",
      "📊 Final Classification Report (Student):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      1.00      1.00        85\n",
      "      Cerber       0.77      0.79      0.78       189\n",
      "    Darkside       0.96      0.80      0.88       323\n",
      "       Excel       0.99      1.00      1.00       147\n",
      "     Firefox       0.99      1.00      0.99       204\n",
      "   GandCrab4       0.71      0.81      0.76       319\n",
      "        Ryuk       0.77      0.80      0.78       196\n",
      "     SDelete       1.00      1.00      1.00        79\n",
      "  Sodinokibi       0.83      0.67      0.74       205\n",
      "  TeslaCrypt       0.75      1.00      0.86        85\n",
      "    WannaCry       1.00      1.00      1.00        79\n",
      "         Zip       1.00      1.00      1.00        85\n",
      "\n",
      "    accuracy                           0.86      1996\n",
      "   macro avg       0.90      0.91      0.90      1996\n",
      "weighted avg       0.87      0.86      0.86      1996\n",
      "\n",
      "✅ Model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw10.pth\n",
      "\n",
      "🚀 Training Student for Td=30, Tw=15 (T_len=16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/1996663968.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2403693/4080983537.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 3094.0534 - Train Acc: 0.3354 - Val Acc: 0.4472\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 02/50 - Loss: 2161.1076 - Train Acc: 0.5753 - Val Acc: 0.5315\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 03/50 - Loss: 1761.1518 - Train Acc: 0.6456 - Val Acc: 0.5881\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 04/50 - Loss: 1450.7412 - Train Acc: 0.7032 - Val Acc: 0.6333\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 05/50 - Loss: 1233.0324 - Train Acc: 0.7429 - Val Acc: 0.6522\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 06/50 - Loss: 1084.3224 - Train Acc: 0.7652 - Val Acc: 0.6655\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 07/50 - Loss: 985.2252 - Train Acc: 0.7790 - Val Acc: 0.6781\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 08/50 - Loss: 917.2693 - Train Acc: 0.7889 - Val Acc: 0.6940\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 09/50 - Loss: 855.5316 - Train Acc: 0.8010 - Val Acc: 0.7027\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 10/50 - Loss: 805.0481 - Train Acc: 0.8090 - Val Acc: 0.7145\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 11/50 - Loss: 768.0983 - Train Acc: 0.8164 - Val Acc: 0.7331\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 12/50 - Loss: 734.4805 - Train Acc: 0.8202 - Val Acc: 0.7361\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 13/50 - Loss: 702.1700 - Train Acc: 0.8243 - Val Acc: 0.7453\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 14/50 - Loss: 673.4286 - Train Acc: 0.8355 - Val Acc: 0.7479\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 15/50 - Loss: 650.2564 - Train Acc: 0.8351 - Val Acc: 0.7566\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 16/50 - Loss: 626.7288 - Train Acc: 0.8392 - Val Acc: 0.7559\n",
      "[Distill] Epoch 17/50 - Loss: 608.2067 - Train Acc: 0.8415 - Val Acc: 0.7688\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 18/50 - Loss: 584.9881 - Train Acc: 0.8480 - Val Acc: 0.7696\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 19/50 - Loss: 570.9654 - Train Acc: 0.8537 - Val Acc: 0.7885\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 20/50 - Loss: 556.6318 - Train Acc: 0.8530 - Val Acc: 0.7942\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 21/50 - Loss: 539.8688 - Train Acc: 0.8566 - Val Acc: 0.7771\n",
      "[Distill] Epoch 22/50 - Loss: 526.7695 - Train Acc: 0.8596 - Val Acc: 0.7912\n",
      "[Distill] Epoch 23/50 - Loss: 515.7079 - Train Acc: 0.8628 - Val Acc: 0.7722\n",
      "[Distill] Epoch 24/50 - Loss: 503.8756 - Train Acc: 0.8630 - Val Acc: 0.7976\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 25/50 - Loss: 491.3463 - Train Acc: 0.8669 - Val Acc: 0.7920\n",
      "[Distill] Epoch 26/50 - Loss: 483.4986 - Train Acc: 0.8684 - Val Acc: 0.8090\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 27/50 - Loss: 472.1653 - Train Acc: 0.8679 - Val Acc: 0.7980\n",
      "[Distill] Epoch 28/50 - Loss: 465.6923 - Train Acc: 0.8708 - Val Acc: 0.8075\n",
      "[Distill] Epoch 29/50 - Loss: 456.9502 - Train Acc: 0.8743 - Val Acc: 0.8132\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 30/50 - Loss: 448.1925 - Train Acc: 0.8748 - Val Acc: 0.8181\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 31/50 - Loss: 443.6559 - Train Acc: 0.8732 - Val Acc: 0.8113\n",
      "[Distill] Epoch 32/50 - Loss: 430.1331 - Train Acc: 0.8793 - Val Acc: 0.8155\n",
      "[Distill] Epoch 33/50 - Loss: 427.1409 - Train Acc: 0.8807 - Val Acc: 0.8098\n",
      "[Distill] Epoch 34/50 - Loss: 419.8097 - Train Acc: 0.8821 - Val Acc: 0.8311\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 35/50 - Loss: 413.7889 - Train Acc: 0.8823 - Val Acc: 0.8238\n",
      "[Distill] Epoch 36/50 - Loss: 411.6487 - Train Acc: 0.8842 - Val Acc: 0.8140\n",
      "[Distill] Epoch 37/50 - Loss: 401.1309 - Train Acc: 0.8873 - Val Acc: 0.8337\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 38/50 - Loss: 400.6982 - Train Acc: 0.8856 - Val Acc: 0.8238\n",
      "[Distill] Epoch 39/50 - Loss: 392.0301 - Train Acc: 0.8886 - Val Acc: 0.8250\n",
      "[Distill] Epoch 40/50 - Loss: 389.0343 - Train Acc: 0.8883 - Val Acc: 0.8265\n",
      "[Distill] Epoch 41/50 - Loss: 380.3887 - Train Acc: 0.8914 - Val Acc: 0.8432\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 42/50 - Loss: 378.1230 - Train Acc: 0.8905 - Val Acc: 0.8394\n",
      "[Distill] Epoch 43/50 - Loss: 377.0566 - Train Acc: 0.8899 - Val Acc: 0.8333\n",
      "[Distill] Epoch 44/50 - Loss: 372.1222 - Train Acc: 0.8924 - Val Acc: 0.8413\n",
      "[Distill] Epoch 45/50 - Loss: 365.2113 - Train Acc: 0.8950 - Val Acc: 0.8337\n",
      "[Distill] Epoch 46/50 - Loss: 361.1557 - Train Acc: 0.8951 - Val Acc: 0.8497\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 47/50 - Loss: 359.3968 - Train Acc: 0.8948 - Val Acc: 0.8299\n",
      "[Distill] Epoch 48/50 - Loss: 354.2585 - Train Acc: 0.8960 - Val Acc: 0.8500\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "[Distill] Epoch 49/50 - Loss: 350.8664 - Train Acc: 0.8971 - Val Acc: 0.8394\n",
      "[Distill] Epoch 50/50 - Loss: 349.7461 - Train Acc: 0.8977 - Val Acc: 0.8576\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/1996663968.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Classification Report (Student):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       0.97      1.00      0.98       112\n",
      "      Cerber       0.85      0.80      0.82       249\n",
      "    Darkside       0.98      0.81      0.89       427\n",
      "       Excel       1.00      0.99      0.99       194\n",
      "     Firefox       0.97      0.94      0.95       271\n",
      "   GandCrab4       0.67      0.77      0.72       420\n",
      "        Ryuk       0.76      0.73      0.74       258\n",
      "     SDelete       1.00      1.00      1.00       103\n",
      "  Sodinokibi       0.84      0.83      0.83       271\n",
      "  TeslaCrypt       0.66      0.93      0.77       114\n",
      "    WannaCry       1.00      1.00      1.00       103\n",
      "         Zip       1.00      0.96      0.98       112\n",
      "\n",
      "    accuracy                           0.86      2634\n",
      "   macro avg       0.89      0.90      0.89      2634\n",
      "weighted avg       0.87      0.86      0.86      2634\n",
      "\n",
      "✅ Model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw15.pth\n",
      "\n",
      "🚀 Training Student for Td=30, Tw=20 (T_len=11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/4080983537.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 5329.7681 - Train Acc: 0.4408 - Val Acc: 0.5472\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 02/50 - Loss: 3268.5926 - Train Acc: 0.6654 - Val Acc: 0.5952\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 03/50 - Loss: 2575.1115 - Train Acc: 0.7172 - Val Acc: 0.6380\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 04/50 - Loss: 2179.6683 - Train Acc: 0.7522 - Val Acc: 0.6790\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 05/50 - Loss: 1912.3550 - Train Acc: 0.7779 - Val Acc: 0.6920\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 06/50 - Loss: 1705.5618 - Train Acc: 0.7966 - Val Acc: 0.7124\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 07/50 - Loss: 1545.9124 - Train Acc: 0.8127 - Val Acc: 0.7382\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 08/50 - Loss: 1418.1179 - Train Acc: 0.8257 - Val Acc: 0.7489\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 09/50 - Loss: 1321.3626 - Train Acc: 0.8358 - Val Acc: 0.7646\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 10/50 - Loss: 1234.9222 - Train Acc: 0.8431 - Val Acc: 0.7730\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 11/50 - Loss: 1167.6884 - Train Acc: 0.8513 - Val Acc: 0.7887\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 12/50 - Loss: 1110.8346 - Train Acc: 0.8546 - Val Acc: 0.7897\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 13/50 - Loss: 1062.9884 - Train Acc: 0.8612 - Val Acc: 0.7908\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 14/50 - Loss: 1018.0550 - Train Acc: 0.8656 - Val Acc: 0.7744\n",
      "[Distill] Epoch 15/50 - Loss: 981.1287 - Train Acc: 0.8680 - Val Acc: 0.8172\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 16/50 - Loss: 954.1923 - Train Acc: 0.8706 - Val Acc: 0.7853\n",
      "[Distill] Epoch 17/50 - Loss: 916.5462 - Train Acc: 0.8741 - Val Acc: 0.7950\n",
      "[Distill] Epoch 18/50 - Loss: 898.1256 - Train Acc: 0.8784 - Val Acc: 0.8325\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 19/50 - Loss: 881.2095 - Train Acc: 0.8779 - Val Acc: 0.8310\n",
      "[Distill] Epoch 20/50 - Loss: 854.9756 - Train Acc: 0.8812 - Val Acc: 0.8285\n",
      "[Distill] Epoch 21/50 - Loss: 837.1352 - Train Acc: 0.8825 - Val Acc: 0.8185\n",
      "[Distill] Epoch 22/50 - Loss: 814.7050 - Train Acc: 0.8859 - Val Acc: 0.8327\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 23/50 - Loss: 799.4593 - Train Acc: 0.8878 - Val Acc: 0.8264\n",
      "[Distill] Epoch 24/50 - Loss: 782.7269 - Train Acc: 0.8896 - Val Acc: 0.8396\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 25/50 - Loss: 772.3054 - Train Acc: 0.8925 - Val Acc: 0.8402\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 26/50 - Loss: 762.7987 - Train Acc: 0.8914 - Val Acc: 0.8415\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 27/50 - Loss: 750.0871 - Train Acc: 0.8925 - Val Acc: 0.8325\n",
      "[Distill] Epoch 28/50 - Loss: 735.4584 - Train Acc: 0.8939 - Val Acc: 0.8447\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 29/50 - Loss: 724.2161 - Train Acc: 0.8965 - Val Acc: 0.8390\n",
      "[Distill] Epoch 30/50 - Loss: 721.4929 - Train Acc: 0.8961 - Val Acc: 0.8446\n",
      "[Distill] Epoch 31/50 - Loss: 707.0145 - Train Acc: 0.8982 - Val Acc: 0.8465\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 32/50 - Loss: 698.2638 - Train Acc: 0.8985 - Val Acc: 0.8480\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 33/50 - Loss: 685.5133 - Train Acc: 0.9017 - Val Acc: 0.8520\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 34/50 - Loss: 681.8510 - Train Acc: 0.9023 - Val Acc: 0.8444\n",
      "[Distill] Epoch 35/50 - Loss: 673.4795 - Train Acc: 0.9027 - Val Acc: 0.8407\n",
      "[Distill] Epoch 36/50 - Loss: 659.0162 - Train Acc: 0.9042 - Val Acc: 0.8535\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 37/50 - Loss: 661.6609 - Train Acc: 0.9038 - Val Acc: 0.8532\n",
      "[Distill] Epoch 38/50 - Loss: 651.2881 - Train Acc: 0.9041 - Val Acc: 0.8551\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 39/50 - Loss: 645.8870 - Train Acc: 0.9052 - Val Acc: 0.8537\n",
      "[Distill] Epoch 40/50 - Loss: 639.3611 - Train Acc: 0.9056 - Val Acc: 0.8520\n",
      "[Distill] Epoch 41/50 - Loss: 637.5287 - Train Acc: 0.9063 - Val Acc: 0.8577\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 42/50 - Loss: 629.0549 - Train Acc: 0.9072 - Val Acc: 0.8495\n",
      "[Distill] Epoch 43/50 - Loss: 620.8631 - Train Acc: 0.9079 - Val Acc: 0.8660\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 44/50 - Loss: 615.8682 - Train Acc: 0.9081 - Val Acc: 0.8681\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 45/50 - Loss: 611.9489 - Train Acc: 0.9097 - Val Acc: 0.8633\n",
      "[Distill] Epoch 46/50 - Loss: 605.7342 - Train Acc: 0.9109 - Val Acc: 0.8623\n",
      "[Distill] Epoch 47/50 - Loss: 597.3307 - Train Acc: 0.9116 - Val Acc: 0.8482\n",
      "[Distill] Epoch 48/50 - Loss: 594.5430 - Train Acc: 0.9118 - Val Acc: 0.8662\n",
      "[Distill] Epoch 49/50 - Loss: 589.0678 - Train Acc: 0.9127 - Val Acc: 0.8713\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "[Distill] Epoch 50/50 - Loss: 586.4076 - Train Acc: 0.9121 - Val Acc: 0.8595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/1996663968.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Classification Report (Student):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       0.95      0.91      0.93       221\n",
      "      Cerber       0.89      0.81      0.85       496\n",
      "    Darkside       0.99      0.82      0.90       850\n",
      "       Excel       1.00      0.99      0.99       386\n",
      "     Firefox       0.99      0.96      0.97       539\n",
      "   GandCrab4       0.75      0.81      0.78       836\n",
      "        Ryuk       0.73      0.77      0.75       514\n",
      "     SDelete       0.93      1.00      0.96       204\n",
      "  Sodinokibi       0.80      0.86      0.83       537\n",
      "  TeslaCrypt       0.68      0.95      0.80       224\n",
      "    WannaCry       1.00      0.99      1.00       203\n",
      "         Zip       1.00      0.95      0.97       220\n",
      "\n",
      "    accuracy                           0.87      5230\n",
      "   macro avg       0.89      0.90      0.89      5230\n",
      "weighted avg       0.88      0.87      0.87      5230\n",
      "\n",
      "✅ Model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td30_Tw20.pth\n",
      "\n",
      "🚀 Training Student for Td=45, Tw=10 (T_len=36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/4080983537.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 1506.5904 - Train Acc: 0.1672 - Val Acc: 0.2820\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1207.0527 - Train Acc: 0.4259 - Val Acc: 0.5203\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 03/50 - Loss: 931.3287 - Train Acc: 0.6366 - Val Acc: 0.6037\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 04/50 - Loss: 778.4278 - Train Acc: 0.6938 - Val Acc: 0.6172\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 05/50 - Loss: 675.6561 - Train Acc: 0.7267 - Val Acc: 0.6328\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 06/50 - Loss: 602.3246 - Train Acc: 0.7445 - Val Acc: 0.6502\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 07/50 - Loss: 544.1801 - Train Acc: 0.7650 - Val Acc: 0.6638\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 08/50 - Loss: 498.2059 - Train Acc: 0.7757 - Val Acc: 0.6822\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 09/50 - Loss: 461.9955 - Train Acc: 0.7926 - Val Acc: 0.6773\n",
      "[Distill] Epoch 10/50 - Loss: 426.8227 - Train Acc: 0.7987 - Val Acc: 0.6928\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 11/50 - Loss: 398.4626 - Train Acc: 0.8081 - Val Acc: 0.6928\n",
      "[Distill] Epoch 12/50 - Loss: 373.4928 - Train Acc: 0.8150 - Val Acc: 0.7161\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 13/50 - Loss: 351.6034 - Train Acc: 0.8252 - Val Acc: 0.7180\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 14/50 - Loss: 333.4959 - Train Acc: 0.8306 - Val Acc: 0.7229\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 15/50 - Loss: 313.7251 - Train Acc: 0.8391 - Val Acc: 0.7471\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 16/50 - Loss: 300.0592 - Train Acc: 0.8434 - Val Acc: 0.7548\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 17/50 - Loss: 287.4449 - Train Acc: 0.8527 - Val Acc: 0.7471\n",
      "[Distill] Epoch 18/50 - Loss: 272.5658 - Train Acc: 0.8543 - Val Acc: 0.7578\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 19/50 - Loss: 261.1528 - Train Acc: 0.8593 - Val Acc: 0.7752\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 20/50 - Loss: 250.1172 - Train Acc: 0.8657 - Val Acc: 0.7742\n",
      "[Distill] Epoch 21/50 - Loss: 239.4046 - Train Acc: 0.8682 - Val Acc: 0.7907\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 22/50 - Loss: 234.8387 - Train Acc: 0.8684 - Val Acc: 0.7946\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 23/50 - Loss: 228.4385 - Train Acc: 0.8743 - Val Acc: 0.7839\n",
      "[Distill] Epoch 24/50 - Loss: 220.4168 - Train Acc: 0.8776 - Val Acc: 0.7907\n",
      "[Distill] Epoch 25/50 - Loss: 213.3404 - Train Acc: 0.8818 - Val Acc: 0.8207\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 26/50 - Loss: 207.6182 - Train Acc: 0.8834 - Val Acc: 0.8023\n",
      "[Distill] Epoch 27/50 - Loss: 203.3636 - Train Acc: 0.8848 - Val Acc: 0.8140\n",
      "[Distill] Epoch 28/50 - Loss: 195.1035 - Train Acc: 0.8897 - Val Acc: 0.8227\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 29/50 - Loss: 192.5587 - Train Acc: 0.8921 - Val Acc: 0.8072\n",
      "[Distill] Epoch 30/50 - Loss: 187.8899 - Train Acc: 0.8938 - Val Acc: 0.8266\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 31/50 - Loss: 183.6239 - Train Acc: 0.8947 - Val Acc: 0.8198\n",
      "[Distill] Epoch 32/50 - Loss: 183.1451 - Train Acc: 0.8953 - Val Acc: 0.8130\n",
      "[Distill] Epoch 33/50 - Loss: 175.7593 - Train Acc: 0.9026 - Val Acc: 0.8188\n",
      "[Distill] Epoch 34/50 - Loss: 172.7292 - Train Acc: 0.9029 - Val Acc: 0.8217\n",
      "[Distill] Epoch 35/50 - Loss: 168.7981 - Train Acc: 0.9008 - Val Acc: 0.8411\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 36/50 - Loss: 164.7227 - Train Acc: 0.9071 - Val Acc: 0.8430\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 37/50 - Loss: 164.2879 - Train Acc: 0.9041 - Val Acc: 0.8372\n",
      "[Distill] Epoch 38/50 - Loss: 160.3598 - Train Acc: 0.9043 - Val Acc: 0.8382\n",
      "[Distill] Epoch 39/50 - Loss: 157.4021 - Train Acc: 0.9081 - Val Acc: 0.8527\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 40/50 - Loss: 155.7555 - Train Acc: 0.9075 - Val Acc: 0.8440\n",
      "[Distill] Epoch 41/50 - Loss: 152.9659 - Train Acc: 0.9110 - Val Acc: 0.8488\n",
      "[Distill] Epoch 42/50 - Loss: 150.1531 - Train Acc: 0.9081 - Val Acc: 0.8527\n",
      "[Distill] Epoch 43/50 - Loss: 151.2325 - Train Acc: 0.9108 - Val Acc: 0.8488\n",
      "[Distill] Epoch 44/50 - Loss: 147.2097 - Train Acc: 0.9120 - Val Acc: 0.8498\n",
      "[Distill] Epoch 45/50 - Loss: 144.8936 - Train Acc: 0.9127 - Val Acc: 0.8682\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "[Distill] Epoch 46/50 - Loss: 142.9118 - Train Acc: 0.9166 - Val Acc: 0.8459\n",
      "[Distill] Epoch 47/50 - Loss: 142.4821 - Train Acc: 0.9146 - Val Acc: 0.8479\n",
      "[Distill] Epoch 48/50 - Loss: 140.3078 - Train Acc: 0.9133 - Val Acc: 0.8595\n",
      "[Distill] Epoch 49/50 - Loss: 137.0521 - Train Acc: 0.9167 - Val Acc: 0.8537\n",
      "[Distill] Epoch 50/50 - Loss: 136.1593 - Train Acc: 0.9174 - Val Acc: 0.8605\n",
      "\n",
      "📊 Final Classification Report (Student):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      1.00      1.00        39\n",
      "      Cerber       0.89      0.81      0.85       100\n",
      "    Darkside       0.97      0.83      0.90       178\n",
      "       Excel       1.00      1.00      1.00        74\n",
      "     Firefox       0.94      0.94      0.94       108\n",
      "   GandCrab4       0.72      0.81      0.76       175\n",
      "        Ryuk       0.68      0.74      0.71       103\n",
      "     SDelete       1.00      1.00      1.00        36\n",
      "  Sodinokibi       0.86      0.82      0.84       109\n",
      "  TeslaCrypt       0.78      1.00      0.88        40\n",
      "    WannaCry       1.00      1.00      1.00        33\n",
      "         Zip       1.00      1.00      1.00        37\n",
      "\n",
      "    accuracy                           0.87      1032\n",
      "   macro avg       0.90      0.91      0.91      1032\n",
      "weighted avg       0.88      0.87      0.87      1032\n",
      "\n",
      "✅ Model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw10.pth\n",
      "\n",
      "🚀 Training Student for Td=45, Tw=15 (T_len=31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/1996663968.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2403693/4080983537.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 1915.7062 - Train Acc: 0.1948 - Val Acc: 0.3747\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1356.5061 - Train Acc: 0.5360 - Val Acc: 0.5427\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 03/50 - Loss: 1026.9329 - Train Acc: 0.6523 - Val Acc: 0.5661\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 04/50 - Loss: 875.0133 - Train Acc: 0.6916 - Val Acc: 0.5858\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 05/50 - Loss: 781.6161 - Train Acc: 0.7152 - Val Acc: 0.6172\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 06/50 - Loss: 714.4495 - Train Acc: 0.7355 - Val Acc: 0.6348\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 07/50 - Loss: 665.1575 - Train Acc: 0.7481 - Val Acc: 0.6362\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 08/50 - Loss: 620.7260 - Train Acc: 0.7602 - Val Acc: 0.6465\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 09/50 - Loss: 582.3101 - Train Acc: 0.7744 - Val Acc: 0.6640\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 10/50 - Loss: 550.1356 - Train Acc: 0.7893 - Val Acc: 0.6801\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 11/50 - Loss: 521.5230 - Train Acc: 0.7990 - Val Acc: 0.6742\n",
      "[Distill] Epoch 12/50 - Loss: 492.8530 - Train Acc: 0.8026 - Val Acc: 0.6932\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 13/50 - Loss: 470.0909 - Train Acc: 0.8156 - Val Acc: 0.6976\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 14/50 - Loss: 451.3978 - Train Acc: 0.8201 - Val Acc: 0.7239\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 15/50 - Loss: 429.1379 - Train Acc: 0.8289 - Val Acc: 0.7253\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 16/50 - Loss: 409.6832 - Train Acc: 0.8363 - Val Acc: 0.7414\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 17/50 - Loss: 393.8718 - Train Acc: 0.8445 - Val Acc: 0.7443\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 18/50 - Loss: 374.8712 - Train Acc: 0.8516 - Val Acc: 0.7524\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 19/50 - Loss: 360.9911 - Train Acc: 0.8555 - Val Acc: 0.7597\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 20/50 - Loss: 351.8858 - Train Acc: 0.8574 - Val Acc: 0.7677\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 21/50 - Loss: 340.3275 - Train Acc: 0.8644 - Val Acc: 0.7670\n",
      "[Distill] Epoch 22/50 - Loss: 328.8576 - Train Acc: 0.8667 - Val Acc: 0.7772\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 23/50 - Loss: 319.7797 - Train Acc: 0.8711 - Val Acc: 0.7882\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 24/50 - Loss: 308.3287 - Train Acc: 0.8759 - Val Acc: 0.7816\n",
      "[Distill] Epoch 25/50 - Loss: 301.1692 - Train Acc: 0.8768 - Val Acc: 0.7984\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 26/50 - Loss: 295.9848 - Train Acc: 0.8777 - Val Acc: 0.7860\n",
      "[Distill] Epoch 27/50 - Loss: 285.7437 - Train Acc: 0.8813 - Val Acc: 0.8057\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 28/50 - Loss: 281.1680 - Train Acc: 0.8868 - Val Acc: 0.8225\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 29/50 - Loss: 271.8503 - Train Acc: 0.8893 - Val Acc: 0.8115\n",
      "[Distill] Epoch 30/50 - Loss: 266.7095 - Train Acc: 0.8896 - Val Acc: 0.8203\n",
      "[Distill] Epoch 31/50 - Loss: 261.5674 - Train Acc: 0.8887 - Val Acc: 0.8152\n",
      "[Distill] Epoch 32/50 - Loss: 257.2718 - Train Acc: 0.8915 - Val Acc: 0.8137\n",
      "[Distill] Epoch 33/50 - Loss: 250.0149 - Train Acc: 0.8957 - Val Acc: 0.8130\n",
      "[Distill] Epoch 34/50 - Loss: 246.9037 - Train Acc: 0.8944 - Val Acc: 0.8291\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 35/50 - Loss: 242.0095 - Train Acc: 0.8981 - Val Acc: 0.8218\n",
      "[Distill] Epoch 36/50 - Loss: 241.1486 - Train Acc: 0.8961 - Val Acc: 0.8386\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 37/50 - Loss: 234.7736 - Train Acc: 0.8991 - Val Acc: 0.8327\n",
      "[Distill] Epoch 38/50 - Loss: 227.1547 - Train Acc: 0.9035 - Val Acc: 0.8415\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 39/50 - Loss: 225.1720 - Train Acc: 0.9054 - Val Acc: 0.8459\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 40/50 - Loss: 223.4501 - Train Acc: 0.9025 - Val Acc: 0.8546\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 41/50 - Loss: 217.1745 - Train Acc: 0.9065 - Val Acc: 0.8298\n",
      "[Distill] Epoch 42/50 - Loss: 215.0817 - Train Acc: 0.9063 - Val Acc: 0.8437\n",
      "[Distill] Epoch 43/50 - Loss: 213.2210 - Train Acc: 0.9061 - Val Acc: 0.8510\n",
      "[Distill] Epoch 44/50 - Loss: 207.9634 - Train Acc: 0.9107 - Val Acc: 0.8437\n",
      "[Distill] Epoch 45/50 - Loss: 206.2408 - Train Acc: 0.9108 - Val Acc: 0.8517\n",
      "[Distill] Epoch 46/50 - Loss: 200.4352 - Train Acc: 0.9152 - Val Acc: 0.8532\n",
      "[Distill] Epoch 47/50 - Loss: 200.3832 - Train Acc: 0.9132 - Val Acc: 0.8619\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 48/50 - Loss: 197.5808 - Train Acc: 0.9145 - Val Acc: 0.8583\n",
      "[Distill] Epoch 49/50 - Loss: 194.1067 - Train Acc: 0.9147 - Val Acc: 0.8649\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "[Distill] Epoch 50/50 - Loss: 190.2100 - Train Acc: 0.9157 - Val Acc: 0.8656\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "\n",
      "📊 Final Classification Report (Student):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      0.92      0.96        53\n",
      "      Cerber       0.93      0.78      0.85       132\n",
      "    Darkside       0.93      0.84      0.89       232\n",
      "       Excel       1.00      0.99      0.99       100\n",
      "     Firefox       0.97      0.93      0.95       143\n",
      "   GandCrab4       0.71      0.82      0.76       228\n",
      "        Ryuk       0.81      0.69      0.75       137\n",
      "     SDelete       0.87      1.00      0.93        48\n",
      "  Sodinokibi       0.81      0.87      0.84       143\n",
      "  TeslaCrypt       0.69      0.94      0.80        53\n",
      "    WannaCry       0.94      1.00      0.97        48\n",
      "         Zip       1.00      1.00      1.00        52\n",
      "\n",
      "    accuracy                           0.87      1369\n",
      "   macro avg       0.89      0.90      0.89      1369\n",
      "weighted avg       0.87      0.87      0.87      1369\n",
      "\n",
      "✅ Model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw15.pth\n",
      "\n",
      "🚀 Training Student for Td=45, Tw=20 (T_len=26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/1996663968.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2403693/4080983537.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 2198.2554 - Train Acc: 0.2108 - Val Acc: 0.3842\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1566.6506 - Train Acc: 0.5151 - Val Acc: 0.4789\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 03/50 - Loss: 1246.3492 - Train Acc: 0.6147 - Val Acc: 0.5287\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 04/50 - Loss: 1053.6591 - Train Acc: 0.6662 - Val Acc: 0.5609\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 05/50 - Loss: 929.8140 - Train Acc: 0.6953 - Val Acc: 0.5830\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 06/50 - Loss: 840.3231 - Train Acc: 0.7138 - Val Acc: 0.6145\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 07/50 - Loss: 768.4962 - Train Acc: 0.7306 - Val Acc: 0.6189\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 08/50 - Loss: 716.4396 - Train Acc: 0.7469 - Val Acc: 0.6416\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 09/50 - Loss: 673.8165 - Train Acc: 0.7568 - Val Acc: 0.6517\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 10/50 - Loss: 637.8430 - Train Acc: 0.7653 - Val Acc: 0.6726\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 11/50 - Loss: 607.4051 - Train Acc: 0.7768 - Val Acc: 0.6669\n",
      "[Distill] Epoch 12/50 - Loss: 580.1504 - Train Acc: 0.7861 - Val Acc: 0.6858\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 13/50 - Loss: 556.8609 - Train Acc: 0.7934 - Val Acc: 0.6940\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 14/50 - Loss: 533.8735 - Train Acc: 0.7965 - Val Acc: 0.7022\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 15/50 - Loss: 511.5516 - Train Acc: 0.8099 - Val Acc: 0.7079\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 16/50 - Loss: 495.6955 - Train Acc: 0.8129 - Val Acc: 0.7066\n",
      "[Distill] Epoch 17/50 - Loss: 477.7994 - Train Acc: 0.8187 - Val Acc: 0.7300\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 18/50 - Loss: 464.2877 - Train Acc: 0.8250 - Val Acc: 0.7438\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 19/50 - Loss: 450.3477 - Train Acc: 0.8276 - Val Acc: 0.7274\n",
      "[Distill] Epoch 20/50 - Loss: 438.4222 - Train Acc: 0.8356 - Val Acc: 0.7407\n",
      "[Distill] Epoch 21/50 - Loss: 424.4932 - Train Acc: 0.8371 - Val Acc: 0.7401\n",
      "[Distill] Epoch 22/50 - Loss: 411.7044 - Train Acc: 0.8402 - Val Acc: 0.7508\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 23/50 - Loss: 403.4328 - Train Acc: 0.8441 - Val Acc: 0.7546\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 24/50 - Loss: 397.7193 - Train Acc: 0.8464 - Val Acc: 0.7672\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 25/50 - Loss: 384.0596 - Train Acc: 0.8517 - Val Acc: 0.7539\n",
      "[Distill] Epoch 26/50 - Loss: 376.0827 - Train Acc: 0.8493 - Val Acc: 0.7754\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 27/50 - Loss: 370.5697 - Train Acc: 0.8568 - Val Acc: 0.7804\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 28/50 - Loss: 360.7855 - Train Acc: 0.8604 - Val Acc: 0.7628\n",
      "[Distill] Epoch 29/50 - Loss: 349.9620 - Train Acc: 0.8653 - Val Acc: 0.7842\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 30/50 - Loss: 351.1955 - Train Acc: 0.8606 - Val Acc: 0.7773\n",
      "[Distill] Epoch 31/50 - Loss: 339.2546 - Train Acc: 0.8653 - Val Acc: 0.7741\n",
      "[Distill] Epoch 32/50 - Loss: 336.8324 - Train Acc: 0.8683 - Val Acc: 0.7912\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 33/50 - Loss: 330.0018 - Train Acc: 0.8692 - Val Acc: 0.7874\n",
      "[Distill] Epoch 34/50 - Loss: 322.9367 - Train Acc: 0.8731 - Val Acc: 0.7905\n",
      "[Distill] Epoch 35/50 - Loss: 321.8654 - Train Acc: 0.8705 - Val Acc: 0.8101\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 36/50 - Loss: 314.5052 - Train Acc: 0.8766 - Val Acc: 0.8057\n",
      "[Distill] Epoch 37/50 - Loss: 310.8700 - Train Acc: 0.8752 - Val Acc: 0.8032\n",
      "[Distill] Epoch 38/50 - Loss: 303.3826 - Train Acc: 0.8802 - Val Acc: 0.8095\n",
      "[Distill] Epoch 39/50 - Loss: 291.1579 - Train Acc: 0.8845 - Val Acc: 0.7987\n",
      "[Distill] Epoch 40/50 - Loss: 285.1594 - Train Acc: 0.8866 - Val Acc: 0.8057\n",
      "[Distill] Epoch 41/50 - Loss: 278.3141 - Train Acc: 0.8898 - Val Acc: 0.8013\n",
      "[Distill] Epoch 42/50 - Loss: 274.4373 - Train Acc: 0.8896 - Val Acc: 0.8177\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 43/50 - Loss: 267.8052 - Train Acc: 0.8942 - Val Acc: 0.8120\n",
      "[Distill] Epoch 44/50 - Loss: 262.2206 - Train Acc: 0.8935 - Val Acc: 0.8063\n",
      "[Distill] Epoch 45/50 - Loss: 259.0516 - Train Acc: 0.8958 - Val Acc: 0.8240\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "[Distill] Epoch 46/50 - Loss: 254.5046 - Train Acc: 0.8984 - Val Acc: 0.8215\n",
      "[Distill] Epoch 47/50 - Loss: 250.7219 - Train Acc: 0.8967 - Val Acc: 0.8183\n",
      "[Distill] Epoch 48/50 - Loss: 248.5284 - Train Acc: 0.8985 - Val Acc: 0.8202\n",
      "[Distill] Epoch 49/50 - Loss: 245.6471 - Train Acc: 0.8989 - Val Acc: 0.8177\n",
      "[Distill] Epoch 50/50 - Loss: 240.7151 - Train Acc: 0.9023 - Val Acc: 0.8202\n",
      "\n",
      "📊 Final Classification Report (Student):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      0.98      0.99        60\n",
      "      Cerber       0.85      0.83      0.84       152\n",
      "    Darkside       0.98      0.83      0.90       270\n",
      "       Excel       1.00      1.00      1.00       115\n",
      "     Firefox       0.93      0.97      0.95       166\n",
      "   GandCrab4       0.67      0.60      0.63       265\n",
      "        Ryuk       0.56      0.61      0.59       158\n",
      "     SDelete       1.00      1.00      1.00        55\n",
      "  Sodinokibi       0.79      0.81      0.80       167\n",
      "  TeslaCrypt       0.54      0.97      0.69        62\n",
      "    WannaCry       0.98      1.00      0.99        55\n",
      "         Zip       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           0.82      1585\n",
      "   macro avg       0.86      0.88      0.87      1585\n",
      "weighted avg       0.84      0.82      0.83      1585\n",
      "\n",
      "✅ Model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td45_Tw20.pth\n",
      "\n",
      "🚀 Training Student for Td=60, Tw=10 (T_len=51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/1996663968.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2403693/4080983537.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 1108.8767 - Train Acc: 0.1105 - Val Acc: 0.2256\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1014.8261 - Train Acc: 0.2955 - Val Acc: 0.4192\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 03/50 - Loss: 746.1667 - Train Acc: 0.5683 - Val Acc: 0.5997\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 04/50 - Loss: 605.7265 - Train Acc: 0.7035 - Val Acc: 0.6434\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 05/50 - Loss: 523.0205 - Train Acc: 0.7375 - Val Acc: 0.6769\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 06/50 - Loss: 462.2089 - Train Acc: 0.7709 - Val Acc: 0.6769\n",
      "[Distill] Epoch 07/50 - Loss: 414.4801 - Train Acc: 0.7928 - Val Acc: 0.6856\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 08/50 - Loss: 378.8590 - Train Acc: 0.8031 - Val Acc: 0.7060\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 09/50 - Loss: 347.1210 - Train Acc: 0.8187 - Val Acc: 0.7103\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 10/50 - Loss: 321.2366 - Train Acc: 0.8204 - Val Acc: 0.7074\n",
      "[Distill] Epoch 11/50 - Loss: 298.4122 - Train Acc: 0.8325 - Val Acc: 0.7045\n",
      "[Distill] Epoch 12/50 - Loss: 277.4912 - Train Acc: 0.8404 - Val Acc: 0.7147\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 13/50 - Loss: 259.6866 - Train Acc: 0.8421 - Val Acc: 0.7103\n",
      "[Distill] Epoch 14/50 - Loss: 243.9656 - Train Acc: 0.8511 - Val Acc: 0.7293\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 15/50 - Loss: 228.3179 - Train Acc: 0.8531 - Val Acc: 0.7278\n",
      "[Distill] Epoch 16/50 - Loss: 216.1721 - Train Acc: 0.8589 - Val Acc: 0.7394\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 17/50 - Loss: 203.8192 - Train Acc: 0.8660 - Val Acc: 0.7467\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 18/50 - Loss: 194.3467 - Train Acc: 0.8737 - Val Acc: 0.7642\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 19/50 - Loss: 183.3855 - Train Acc: 0.8753 - Val Acc: 0.7482\n",
      "[Distill] Epoch 20/50 - Loss: 175.6014 - Train Acc: 0.8777 - Val Acc: 0.7686\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 21/50 - Loss: 166.0819 - Train Acc: 0.8847 - Val Acc: 0.7889\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 22/50 - Loss: 160.2974 - Train Acc: 0.8869 - Val Acc: 0.7787\n",
      "[Distill] Epoch 23/50 - Loss: 154.0665 - Train Acc: 0.8904 - Val Acc: 0.7758\n",
      "[Distill] Epoch 24/50 - Loss: 147.3564 - Train Acc: 0.8937 - Val Acc: 0.7889\n",
      "[Distill] Epoch 25/50 - Loss: 141.5407 - Train Acc: 0.8990 - Val Acc: 0.8064\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 26/50 - Loss: 137.5664 - Train Acc: 0.8982 - Val Acc: 0.8006\n",
      "[Distill] Epoch 27/50 - Loss: 131.3442 - Train Acc: 0.9015 - Val Acc: 0.8210\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 28/50 - Loss: 125.8220 - Train Acc: 0.9082 - Val Acc: 0.8384\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 29/50 - Loss: 120.8010 - Train Acc: 0.9100 - Val Acc: 0.8195\n",
      "[Distill] Epoch 30/50 - Loss: 116.3996 - Train Acc: 0.9162 - Val Acc: 0.8384\n",
      "[Distill] Epoch 31/50 - Loss: 113.8851 - Train Acc: 0.9130 - Val Acc: 0.8588\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 32/50 - Loss: 109.6886 - Train Acc: 0.9156 - Val Acc: 0.8588\n",
      "[Distill] Epoch 33/50 - Loss: 105.8946 - Train Acc: 0.9224 - Val Acc: 0.8399\n",
      "[Distill] Epoch 34/50 - Loss: 103.6966 - Train Acc: 0.9252 - Val Acc: 0.8661\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 35/50 - Loss: 99.9748 - Train Acc: 0.9242 - Val Acc: 0.8544\n",
      "[Distill] Epoch 36/50 - Loss: 97.4872 - Train Acc: 0.9279 - Val Acc: 0.8675\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 37/50 - Loss: 95.5277 - Train Acc: 0.9274 - Val Acc: 0.8588\n",
      "[Distill] Epoch 38/50 - Loss: 92.2739 - Train Acc: 0.9289 - Val Acc: 0.8588\n",
      "[Distill] Epoch 39/50 - Loss: 89.8324 - Train Acc: 0.9332 - Val Acc: 0.8748\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 40/50 - Loss: 86.8953 - Train Acc: 0.9356 - Val Acc: 0.8690\n",
      "[Distill] Epoch 41/50 - Loss: 85.4923 - Train Acc: 0.9357 - Val Acc: 0.8763\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 42/50 - Loss: 82.1799 - Train Acc: 0.9407 - Val Acc: 0.8763\n",
      "[Distill] Epoch 43/50 - Loss: 81.2931 - Train Acc: 0.9403 - Val Acc: 0.8806\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 44/50 - Loss: 79.5885 - Train Acc: 0.9400 - Val Acc: 0.8879\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 45/50 - Loss: 77.6227 - Train Acc: 0.9407 - Val Acc: 0.8894\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 46/50 - Loss: 77.6920 - Train Acc: 0.9420 - Val Acc: 0.8923\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 47/50 - Loss: 75.9691 - Train Acc: 0.9439 - Val Acc: 0.8937\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "[Distill] Epoch 48/50 - Loss: 73.4347 - Train Acc: 0.9435 - Val Acc: 0.8865\n",
      "[Distill] Epoch 49/50 - Loss: 71.7544 - Train Acc: 0.9459 - Val Acc: 0.8836\n",
      "[Distill] Epoch 50/50 - Loss: 70.5531 - Train Acc: 0.9473 - Val Acc: 0.8894\n",
      "\n",
      "📊 Final Classification Report (Student):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      1.00      1.00        21\n",
      "      Cerber       0.91      0.91      0.91        68\n",
      "    Darkside       1.00      0.84      0.91       126\n",
      "       Excel       1.00      1.00      1.00        49\n",
      "     Firefox       0.97      0.93      0.95        74\n",
      "   GandCrab4       0.81      0.76      0.79       125\n",
      "        Ryuk       0.66      0.89      0.76        71\n",
      "     SDelete       0.90      1.00      0.95        18\n",
      "  Sodinokibi       0.91      0.95      0.93        74\n",
      "  TeslaCrypt       0.92      1.00      0.96        22\n",
      "    WannaCry       1.00      1.00      1.00        18\n",
      "         Zip       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.89       687\n",
      "   macro avg       0.92      0.94      0.93       687\n",
      "weighted avg       0.90      0.89      0.90       687\n",
      "\n",
      "✅ Model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw10.pth\n",
      "\n",
      "🚀 Training Student for Td=60, Tw=15 (T_len=46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/1996663968.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2403693/4080983537.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 1220.4490 - Train Acc: 0.1594 - Val Acc: 0.1810\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1002.0874 - Train Acc: 0.4420 - Val Acc: 0.5772\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 03/50 - Loss: 760.8072 - Train Acc: 0.6571 - Val Acc: 0.6089\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 04/50 - Loss: 644.6548 - Train Acc: 0.6991 - Val Acc: 0.6278\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 05/50 - Loss: 558.0945 - Train Acc: 0.7390 - Val Acc: 0.6430\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 06/50 - Loss: 487.3886 - Train Acc: 0.7812 - Val Acc: 0.6759\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 07/50 - Loss: 430.5337 - Train Acc: 0.8010 - Val Acc: 0.6785\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 08/50 - Loss: 384.8523 - Train Acc: 0.8180 - Val Acc: 0.6987\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 09/50 - Loss: 344.4591 - Train Acc: 0.8296 - Val Acc: 0.7076\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 10/50 - Loss: 313.5321 - Train Acc: 0.8385 - Val Acc: 0.7215\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 11/50 - Loss: 287.6142 - Train Acc: 0.8511 - Val Acc: 0.7253\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 12/50 - Loss: 267.0912 - Train Acc: 0.8551 - Val Acc: 0.7481\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 13/50 - Loss: 247.1645 - Train Acc: 0.8642 - Val Acc: 0.7443\n",
      "[Distill] Epoch 14/50 - Loss: 228.5103 - Train Acc: 0.8701 - Val Acc: 0.7519\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 15/50 - Loss: 217.2658 - Train Acc: 0.8778 - Val Acc: 0.7747\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 16/50 - Loss: 203.9706 - Train Acc: 0.8826 - Val Acc: 0.7785\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 17/50 - Loss: 195.0099 - Train Acc: 0.8837 - Val Acc: 0.8013\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 18/50 - Loss: 182.6940 - Train Acc: 0.8916 - Val Acc: 0.8114\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 19/50 - Loss: 174.1485 - Train Acc: 0.8969 - Val Acc: 0.7924\n",
      "[Distill] Epoch 20/50 - Loss: 166.2373 - Train Acc: 0.9001 - Val Acc: 0.7949\n",
      "[Distill] Epoch 21/50 - Loss: 159.6821 - Train Acc: 0.9020 - Val Acc: 0.8101\n",
      "[Distill] Epoch 22/50 - Loss: 155.3657 - Train Acc: 0.9035 - Val Acc: 0.8051\n",
      "[Distill] Epoch 23/50 - Loss: 149.2653 - Train Acc: 0.9071 - Val Acc: 0.8152\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 24/50 - Loss: 141.9014 - Train Acc: 0.9127 - Val Acc: 0.8329\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 25/50 - Loss: 138.4284 - Train Acc: 0.9129 - Val Acc: 0.8456\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 26/50 - Loss: 133.2844 - Train Acc: 0.9168 - Val Acc: 0.8430\n",
      "[Distill] Epoch 27/50 - Loss: 128.5302 - Train Acc: 0.9178 - Val Acc: 0.8506\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 28/50 - Loss: 123.0062 - Train Acc: 0.9232 - Val Acc: 0.8557\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 29/50 - Loss: 121.0295 - Train Acc: 0.9213 - Val Acc: 0.8633\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 30/50 - Loss: 118.8397 - Train Acc: 0.9206 - Val Acc: 0.8570\n",
      "[Distill] Epoch 31/50 - Loss: 115.2666 - Train Acc: 0.9254 - Val Acc: 0.8722\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 32/50 - Loss: 112.8845 - Train Acc: 0.9271 - Val Acc: 0.8747\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 33/50 - Loss: 109.7875 - Train Acc: 0.9327 - Val Acc: 0.8481\n",
      "[Distill] Epoch 34/50 - Loss: 106.0129 - Train Acc: 0.9281 - Val Acc: 0.8620\n",
      "[Distill] Epoch 35/50 - Loss: 103.6059 - Train Acc: 0.9297 - Val Acc: 0.8506\n",
      "[Distill] Epoch 36/50 - Loss: 99.0633 - Train Acc: 0.9346 - Val Acc: 0.8696\n",
      "[Distill] Epoch 37/50 - Loss: 100.1201 - Train Acc: 0.9348 - Val Acc: 0.8772\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 38/50 - Loss: 97.2495 - Train Acc: 0.9365 - Val Acc: 0.8759\n",
      "[Distill] Epoch 39/50 - Loss: 92.5447 - Train Acc: 0.9401 - Val Acc: 0.8684\n",
      "[Distill] Epoch 40/50 - Loss: 92.5577 - Train Acc: 0.9387 - Val Acc: 0.8772\n",
      "[Distill] Epoch 41/50 - Loss: 90.7704 - Train Acc: 0.9392 - Val Acc: 0.8797\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 42/50 - Loss: 90.1449 - Train Acc: 0.9393 - Val Acc: 0.8797\n",
      "[Distill] Epoch 43/50 - Loss: 89.1808 - Train Acc: 0.9401 - Val Acc: 0.8861\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 44/50 - Loss: 85.7352 - Train Acc: 0.9406 - Val Acc: 0.8861\n",
      "[Distill] Epoch 45/50 - Loss: 84.6427 - Train Acc: 0.9442 - Val Acc: 0.8873\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 46/50 - Loss: 82.5565 - Train Acc: 0.9449 - Val Acc: 0.8899\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "[Distill] Epoch 47/50 - Loss: 80.5642 - Train Acc: 0.9462 - Val Acc: 0.8848\n",
      "[Distill] Epoch 48/50 - Loss: 78.9271 - Train Acc: 0.9460 - Val Acc: 0.8772\n",
      "[Distill] Epoch 49/50 - Loss: 78.8703 - Train Acc: 0.9466 - Val Acc: 0.8861\n",
      "[Distill] Epoch 50/50 - Loss: 77.6599 - Train Acc: 0.9482 - Val Acc: 0.8911\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "\n",
      "📊 Final Classification Report (Student):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      1.00      1.00        27\n",
      "      Cerber       0.95      0.83      0.89        76\n",
      "    Darkside       0.95      0.88      0.92       142\n",
      "       Excel       1.00      1.00      1.00        56\n",
      "     Firefox       1.00      0.95      0.98        85\n",
      "   GandCrab4       0.72      0.83      0.77       138\n",
      "        Ryuk       0.75      0.75      0.75        79\n",
      "     SDelete       1.00      1.00      1.00        24\n",
      "  Sodinokibi       0.89      0.90      0.90        84\n",
      "  TeslaCrypt       0.88      1.00      0.93        28\n",
      "    WannaCry       1.00      1.00      1.00        24\n",
      "         Zip       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.89       790\n",
      "   macro avg       0.93      0.93      0.93       790\n",
      "weighted avg       0.90      0.89      0.89       790\n",
      "\n",
      "✅ Model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw15.pth\n",
      "\n",
      "🚀 Training Student for Td=60, Tw=20 (T_len=41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/1996663968.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2403693/4080983537.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 1336.8097 - Train Acc: 0.1292 - Val Acc: 0.2354\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1117.6365 - Train Acc: 0.4269 - Val Acc: 0.5433\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 03/50 - Loss: 806.2226 - Train Acc: 0.6621 - Val Acc: 0.5691\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 04/50 - Loss: 675.4467 - Train Acc: 0.6971 - Val Acc: 0.5925\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 05/50 - Loss: 592.1709 - Train Acc: 0.7220 - Val Acc: 0.6066\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 06/50 - Loss: 527.7711 - Train Acc: 0.7452 - Val Acc: 0.6230\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 07/50 - Loss: 478.7730 - Train Acc: 0.7632 - Val Acc: 0.6593\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 08/50 - Loss: 433.0919 - Train Acc: 0.7857 - Val Acc: 0.6745\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 09/50 - Loss: 397.6963 - Train Acc: 0.7969 - Val Acc: 0.6885\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 10/50 - Loss: 366.1250 - Train Acc: 0.8139 - Val Acc: 0.6909\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 11/50 - Loss: 337.6587 - Train Acc: 0.8280 - Val Acc: 0.7108\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 12/50 - Loss: 314.1394 - Train Acc: 0.8379 - Val Acc: 0.7319\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 13/50 - Loss: 293.9520 - Train Acc: 0.8418 - Val Acc: 0.7330\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 14/50 - Loss: 272.9715 - Train Acc: 0.8490 - Val Acc: 0.7447\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 15/50 - Loss: 258.4157 - Train Acc: 0.8536 - Val Acc: 0.7400\n",
      "[Distill] Epoch 16/50 - Loss: 242.9791 - Train Acc: 0.8599 - Val Acc: 0.7553\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 17/50 - Loss: 231.2109 - Train Acc: 0.8629 - Val Acc: 0.7588\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 18/50 - Loss: 220.6868 - Train Acc: 0.8698 - Val Acc: 0.7705\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 19/50 - Loss: 209.6447 - Train Acc: 0.8748 - Val Acc: 0.7799\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 20/50 - Loss: 201.2827 - Train Acc: 0.8772 - Val Acc: 0.7834\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 21/50 - Loss: 193.9528 - Train Acc: 0.8804 - Val Acc: 0.7986\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 22/50 - Loss: 185.9974 - Train Acc: 0.8841 - Val Acc: 0.8044\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 23/50 - Loss: 177.9032 - Train Acc: 0.8932 - Val Acc: 0.7963\n",
      "[Distill] Epoch 24/50 - Loss: 172.7552 - Train Acc: 0.8936 - Val Acc: 0.8009\n",
      "[Distill] Epoch 25/50 - Loss: 169.0292 - Train Acc: 0.8947 - Val Acc: 0.7974\n",
      "[Distill] Epoch 26/50 - Loss: 164.2996 - Train Acc: 0.8965 - Val Acc: 0.8150\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 27/50 - Loss: 159.7212 - Train Acc: 0.8981 - Val Acc: 0.8033\n",
      "[Distill] Epoch 28/50 - Loss: 156.5641 - Train Acc: 0.8996 - Val Acc: 0.8091\n",
      "[Distill] Epoch 29/50 - Loss: 150.3227 - Train Acc: 0.9032 - Val Acc: 0.8255\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 30/50 - Loss: 147.6080 - Train Acc: 0.9054 - Val Acc: 0.8220\n",
      "[Distill] Epoch 31/50 - Loss: 143.9853 - Train Acc: 0.9053 - Val Acc: 0.8290\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 32/50 - Loss: 140.4592 - Train Acc: 0.9071 - Val Acc: 0.8126\n",
      "[Distill] Epoch 33/50 - Loss: 137.7618 - Train Acc: 0.9105 - Val Acc: 0.8290\n",
      "[Distill] Epoch 34/50 - Loss: 133.0461 - Train Acc: 0.9142 - Val Acc: 0.8407\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 35/50 - Loss: 132.1310 - Train Acc: 0.9156 - Val Acc: 0.8337\n",
      "[Distill] Epoch 36/50 - Loss: 127.8886 - Train Acc: 0.9166 - Val Acc: 0.8361\n",
      "[Distill] Epoch 37/50 - Loss: 128.5142 - Train Acc: 0.9123 - Val Acc: 0.8419\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 38/50 - Loss: 124.2879 - Train Acc: 0.9171 - Val Acc: 0.8361\n",
      "[Distill] Epoch 39/50 - Loss: 122.8668 - Train Acc: 0.9185 - Val Acc: 0.8443\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 40/50 - Loss: 120.4039 - Train Acc: 0.9185 - Val Acc: 0.8443\n",
      "[Distill] Epoch 41/50 - Loss: 118.9324 - Train Acc: 0.9219 - Val Acc: 0.8513\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 42/50 - Loss: 114.3845 - Train Acc: 0.9235 - Val Acc: 0.8443\n",
      "[Distill] Epoch 43/50 - Loss: 113.4692 - Train Acc: 0.9259 - Val Acc: 0.8501\n",
      "[Distill] Epoch 44/50 - Loss: 111.7026 - Train Acc: 0.9265 - Val Acc: 0.8548\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 45/50 - Loss: 113.6287 - Train Acc: 0.9232 - Val Acc: 0.8571\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 46/50 - Loss: 110.4459 - Train Acc: 0.9258 - Val Acc: 0.8513\n",
      "[Distill] Epoch 47/50 - Loss: 107.4948 - Train Acc: 0.9266 - Val Acc: 0.8513\n",
      "[Distill] Epoch 48/50 - Loss: 107.4735 - Train Acc: 0.9263 - Val Acc: 0.8735\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n",
      "[Distill] Epoch 49/50 - Loss: 106.3699 - Train Acc: 0.9296 - Val Acc: 0.8665\n",
      "[Distill] Epoch 50/50 - Loss: 104.9386 - Train Acc: 0.9277 - Val Acc: 0.8595\n",
      "\n",
      "📊 Final Classification Report (Student):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      1.00      1.00        28\n",
      "      Cerber       0.89      0.86      0.87        84\n",
      "    Darkside       0.97      0.82      0.89       154\n",
      "       Excel       1.00      1.00      1.00        61\n",
      "     Firefox       0.99      0.95      0.97        91\n",
      "   GandCrab4       0.73      0.81      0.77       151\n",
      "        Ryuk       0.74      0.73      0.74        88\n",
      "     SDelete       1.00      1.00      1.00        24\n",
      "  Sodinokibi       0.83      0.88      0.86        91\n",
      "  TeslaCrypt       0.71      0.96      0.82        28\n",
      "    WannaCry       1.00      1.00      1.00        25\n",
      "         Zip       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           0.87       854\n",
      "   macro avg       0.91      0.92      0.91       854\n",
      "weighted avg       0.88      0.87      0.88       854\n",
      "\n",
      "✅ Model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/student/student_Td60_Tw20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/1996663968.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "detection_times = [30, 45, 60]\n",
    "window_sizes = [10, 15, 20]\n",
    "\n",
    "base_dir = \"/home/HardDisk/Satang/thesis_proj\"\n",
    "base_teacher_dir = os.path.join(base_dir, \"Deep_Learning\",\"cross_archi\", \"transformer\",\"teacher\")\n",
    "student_save_dir = os.path.join(base_dir, \"Deep_Learning\",\"cross_archi\", \"transformer\",\"student\")\n",
    "os.makedirs(student_save_dir, exist_ok=True)\n",
    "\n",
    "for T_d in detection_times:\n",
    "    for T_w in window_sizes:\n",
    "        T_len = T_d - T_w + 1\n",
    "        expected_shape = (T_len, NUM_FEATURES)\n",
    "\n",
    "        print(f\"\\n🚀 Training Student for Td={T_d}, Tw={T_w} (T_len={T_len})\")\n",
    "\n",
    "        # === Paths ===\n",
    "        folder_name = f\"X_csv_split_{T_len}\"\n",
    "        input_dir = os.path.join(base_dir, f\"New_{T_d}\", f\"{T_w}\", \"split_tws\", folder_name)\n",
    "        train_path = os.path.join(input_dir, \"train\")\n",
    "        val_path   = os.path.join(input_dir, \"val\")\n",
    "        teacher_model_path = os.path.join(base_teacher_dir, f\"transformer_Td{T_d}_Tw{T_w}.pth\")\n",
    "        student_model_path = os.path.join(student_save_dir, f\"student_Td{T_d}_Tw{T_w}.pth\")\n",
    "\n",
    "        # === 1. Load Data ===\n",
    "        X_train_raw, y_train_raw = load_split_from_folder(train_path, expected_shape)\n",
    "        X_val_raw, y_val_raw     = load_split_from_folder(val_path, expected_shape)\n",
    "\n",
    "        # === 2. Encode & Balance ===\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_encoded = label_encoder.fit_transform(y_train_raw)\n",
    "\n",
    "        X_train_flat = X_train_raw.reshape(X_train_raw.shape[0], -1)\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X_train_flat, y_train_encoded)\n",
    "        X_train_bal = X_resampled.reshape(-1, T_len, NUM_FEATURES)\n",
    "        y_train_str = label_encoder.inverse_transform(y_resampled)\n",
    "\n",
    "        # === 3. Dataset & Dataloader ===\n",
    "        train_dataset = MultiStreamDataset(X_train_bal, y_train_str, label_encoder, augment=True)\n",
    "        val_dataset   = MultiStreamDataset(X_val_raw, y_val_raw, label_encoder, augment=False)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        class_weights_tensor = compute_class_weights(label_encoder.transform(y_train_str), device)\n",
    "\n",
    "        # === 4. Load Teacher ===\n",
    "        teacher = RansomwareTransformer(\n",
    "            input_dim=NUM_FEATURES,\n",
    "            seq_len=T_len,\n",
    "            num_classes=len(label_encoder.classes_)\n",
    "        )\n",
    "        teacher.load_state_dict(torch.load(teacher_model_path, map_location=device))\n",
    "        teacher.to(device)\n",
    "        teacher.eval()\n",
    "        for p in teacher.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # === 5. Init Student & Train ===\n",
    "        student = StudentCNN(input_length=T_len, num_classes=len(label_encoder.classes_)).to(device)\n",
    "\n",
    "        train_accs, val_accs, train_losses, val_losses = train_distilled(\n",
    "            student=student,\n",
    "            teacher=teacher,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            device=device,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            lr=0.0001,\n",
    "            class_weights=class_weights_tensor,\n",
    "            T=2.5,\n",
    "            alpha=0.8,\n",
    "            beta=0.2,\n",
    "            gamma=0.1,\n",
    "            save_path=student_model_path\n",
    "        )\n",
    "\n",
    "        # === 6. Evaluate ===\n",
    "        student.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student(inputs)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        print(\"\\n📊 Final Classification Report (Student):\")\n",
    "        print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
    "        print(f\"✅ Model saved: {student_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "71ac8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_student_baseline(student, train_loader, val_loader, device,\n",
    "                           epochs=50, lr=0.0005, class_weights=None, save_path=\"best_student_baseline.pth\",\n",
    "                           patience=10):\n",
    "\n",
    "    student.to(device)\n",
    "    optimizer = optim.Adam(student.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "    train_losses, train_accuracies, val_accuracies, val_losses = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss, correct = 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:  # ✅ inputs: (B, T, 8)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = student(inputs)  # ✅ one-shot forward pass\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(total_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # === Validation ===\n",
    "        student.eval()\n",
    "        val_correct, val_loss = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / len(val_loader.dataset)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"[Baseline] Epoch {epoch+1:02d}/{epochs} - Loss: {total_loss:.4f} \"\n",
    "              f\"- Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(student.state_dict(), save_path)\n",
    "            print(f\"💾 Saved best standalone student model to: {save_path}\")\n",
    "            epochs_no_improve = 0  # Reset counter\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"⏹ Early stopping triggered at epoch {epoch+1} due to no improvement for {patience} consecutive epochs.\")\n",
    "                break\n",
    "\n",
    "    student.load_state_dict(torch.load(save_path))\n",
    "    return train_accuracies, val_accuracies, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6f342f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training Standalone Student for Td=30, Tw=10 (T_len=21)\n",
      "[Baseline] Epoch 01/50 - Loss: 1382.9703 - Train Acc: 0.1566 - Val Acc: 0.2119\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 984.7228 - Train Acc: 0.4519 - Val Acc: 0.4374\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 754.6250 - Train Acc: 0.5910 - Val Acc: 0.5010\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 666.4675 - Train Acc: 0.6286 - Val Acc: 0.5496\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 613.3122 - Train Acc: 0.6532 - Val Acc: 0.5566\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 575.0607 - Train Acc: 0.6717 - Val Acc: 0.5857\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 544.8227 - Train Acc: 0.6847 - Val Acc: 0.6007\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 518.7083 - Train Acc: 0.6982 - Val Acc: 0.6097\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 493.4351 - Train Acc: 0.7111 - Val Acc: 0.6177\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 474.3815 - Train Acc: 0.7204 - Val Acc: 0.6328\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 454.5758 - Train Acc: 0.7287 - Val Acc: 0.6463\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 438.4158 - Train Acc: 0.7392 - Val Acc: 0.6488\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 423.8559 - Train Acc: 0.7475 - Val Acc: 0.6548\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 409.0581 - Train Acc: 0.7496 - Val Acc: 0.6588\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 396.7134 - Train Acc: 0.7580 - Val Acc: 0.6623\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 383.6625 - Train Acc: 0.7680 - Val Acc: 0.6949\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 373.0720 - Train Acc: 0.7698 - Val Acc: 0.6849\n",
      "[Baseline] Epoch 18/50 - Loss: 361.7587 - Train Acc: 0.7810 - Val Acc: 0.7019\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 352.5378 - Train Acc: 0.7853 - Val Acc: 0.6974\n",
      "[Baseline] Epoch 20/50 - Loss: 343.9798 - Train Acc: 0.7919 - Val Acc: 0.7194\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 335.3791 - Train Acc: 0.7964 - Val Acc: 0.7265\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 326.6076 - Train Acc: 0.8031 - Val Acc: 0.7084\n",
      "[Baseline] Epoch 23/50 - Loss: 319.8616 - Train Acc: 0.8061 - Val Acc: 0.7094\n",
      "[Baseline] Epoch 24/50 - Loss: 313.9383 - Train Acc: 0.8091 - Val Acc: 0.7335\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 25/50 - Loss: 307.2682 - Train Acc: 0.8136 - Val Acc: 0.7510\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 303.5786 - Train Acc: 0.8141 - Val Acc: 0.7550\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 297.1661 - Train Acc: 0.8175 - Val Acc: 0.7655\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 290.0587 - Train Acc: 0.8212 - Val Acc: 0.7761\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 284.3340 - Train Acc: 0.8257 - Val Acc: 0.7826\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 30/50 - Loss: 282.6728 - Train Acc: 0.8280 - Val Acc: 0.7685\n",
      "[Baseline] Epoch 31/50 - Loss: 276.2960 - Train Acc: 0.8322 - Val Acc: 0.7871\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 273.2511 - Train Acc: 0.8322 - Val Acc: 0.7986\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 33/50 - Loss: 271.9773 - Train Acc: 0.8334 - Val Acc: 0.7991\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 34/50 - Loss: 267.1221 - Train Acc: 0.8353 - Val Acc: 0.8071\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 35/50 - Loss: 263.2107 - Train Acc: 0.8400 - Val Acc: 0.7991\n",
      "[Baseline] Epoch 36/50 - Loss: 261.9184 - Train Acc: 0.8361 - Val Acc: 0.8156\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 255.9250 - Train Acc: 0.8443 - Val Acc: 0.8071\n",
      "[Baseline] Epoch 38/50 - Loss: 251.6696 - Train Acc: 0.8439 - Val Acc: 0.7951\n",
      "[Baseline] Epoch 39/50 - Loss: 249.7598 - Train Acc: 0.8471 - Val Acc: 0.8226\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 40/50 - Loss: 249.8960 - Train Acc: 0.8448 - Val Acc: 0.8106\n",
      "[Baseline] Epoch 41/50 - Loss: 245.3920 - Train Acc: 0.8462 - Val Acc: 0.8036\n",
      "[Baseline] Epoch 42/50 - Loss: 243.0563 - Train Acc: 0.8480 - Val Acc: 0.8066\n",
      "[Baseline] Epoch 43/50 - Loss: 242.0318 - Train Acc: 0.8500 - Val Acc: 0.8151\n",
      "[Baseline] Epoch 44/50 - Loss: 238.6823 - Train Acc: 0.8535 - Val Acc: 0.8211\n",
      "[Baseline] Epoch 45/50 - Loss: 237.7005 - Train Acc: 0.8513 - Val Acc: 0.8367\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 235.5787 - Train Acc: 0.8518 - Val Acc: 0.7891\n",
      "[Baseline] Epoch 47/50 - Loss: 233.2096 - Train Acc: 0.8546 - Val Acc: 0.8332\n",
      "[Baseline] Epoch 48/50 - Loss: 230.2388 - Train Acc: 0.8580 - Val Acc: 0.8312\n",
      "[Baseline] Epoch 49/50 - Loss: 229.0450 - Train Acc: 0.8585 - Val Acc: 0.8332\n",
      "[Baseline] Epoch 50/50 - Loss: 224.7733 - Train Acc: 0.8616 - Val Acc: 0.8262\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=30, Tw=15 (T_len=16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/2889036497.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 1825.0223 - Train Acc: 0.1600 - Val Acc: 0.2737\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 1306.9692 - Train Acc: 0.4602 - Val Acc: 0.4609\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 999.0031 - Train Acc: 0.5871 - Val Acc: 0.5125\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 862.1184 - Train Acc: 0.6333 - Val Acc: 0.5619\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 767.7518 - Train Acc: 0.6770 - Val Acc: 0.5911\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 702.0015 - Train Acc: 0.7021 - Val Acc: 0.6181\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 649.6837 - Train Acc: 0.7249 - Val Acc: 0.6268\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 611.2517 - Train Acc: 0.7417 - Val Acc: 0.6587\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 578.6716 - Train Acc: 0.7572 - Val Acc: 0.6743\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 551.8686 - Train Acc: 0.7659 - Val Acc: 0.6750\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 530.7766 - Train Acc: 0.7728 - Val Acc: 0.6788\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 512.6241 - Train Acc: 0.7785 - Val Acc: 0.6963\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 494.9947 - Train Acc: 0.7878 - Val Acc: 0.6997\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 479.4570 - Train Acc: 0.7923 - Val Acc: 0.7035\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 466.0563 - Train Acc: 0.7965 - Val Acc: 0.7111\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 452.0287 - Train Acc: 0.8033 - Val Acc: 0.7206\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 442.6791 - Train Acc: 0.8071 - Val Acc: 0.7282\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 428.9093 - Train Acc: 0.8117 - Val Acc: 0.7263\n",
      "[Baseline] Epoch 19/50 - Loss: 424.6906 - Train Acc: 0.8130 - Val Acc: 0.7297\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 412.8578 - Train Acc: 0.8180 - Val Acc: 0.7339\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 406.3975 - Train Acc: 0.8192 - Val Acc: 0.7377\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 399.2656 - Train Acc: 0.8216 - Val Acc: 0.7369\n",
      "[Baseline] Epoch 23/50 - Loss: 388.7288 - Train Acc: 0.8284 - Val Acc: 0.7377\n",
      "[Baseline] Epoch 24/50 - Loss: 377.3586 - Train Acc: 0.8342 - Val Acc: 0.7498\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 25/50 - Loss: 370.6024 - Train Acc: 0.8368 - Val Acc: 0.7460\n",
      "[Baseline] Epoch 26/50 - Loss: 361.0387 - Train Acc: 0.8404 - Val Acc: 0.7411\n",
      "[Baseline] Epoch 27/50 - Loss: 354.3248 - Train Acc: 0.8436 - Val Acc: 0.7559\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 348.6923 - Train Acc: 0.8472 - Val Acc: 0.7631\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 342.1976 - Train Acc: 0.8486 - Val Acc: 0.7601\n",
      "[Baseline] Epoch 30/50 - Loss: 335.1830 - Train Acc: 0.8514 - Val Acc: 0.7703\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 31/50 - Loss: 328.4316 - Train Acc: 0.8561 - Val Acc: 0.7775\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 323.7441 - Train Acc: 0.8569 - Val Acc: 0.7658\n",
      "[Baseline] Epoch 33/50 - Loss: 316.1961 - Train Acc: 0.8592 - Val Acc: 0.7790\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 34/50 - Loss: 314.0146 - Train Acc: 0.8599 - Val Acc: 0.7813\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 35/50 - Loss: 307.3615 - Train Acc: 0.8623 - Val Acc: 0.7954\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 36/50 - Loss: 302.3210 - Train Acc: 0.8653 - Val Acc: 0.7790\n",
      "[Baseline] Epoch 37/50 - Loss: 298.1471 - Train Acc: 0.8675 - Val Acc: 0.7847\n",
      "[Baseline] Epoch 38/50 - Loss: 292.1092 - Train Acc: 0.8692 - Val Acc: 0.7984\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 39/50 - Loss: 289.2022 - Train Acc: 0.8711 - Val Acc: 0.7935\n",
      "[Baseline] Epoch 40/50 - Loss: 285.1358 - Train Acc: 0.8721 - Val Acc: 0.8007\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 41/50 - Loss: 282.6914 - Train Acc: 0.8736 - Val Acc: 0.7988\n",
      "[Baseline] Epoch 42/50 - Loss: 278.5368 - Train Acc: 0.8737 - Val Acc: 0.8060\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 43/50 - Loss: 275.7939 - Train Acc: 0.8773 - Val Acc: 0.8185\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 44/50 - Loss: 270.2596 - Train Acc: 0.8791 - Val Acc: 0.8208\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 45/50 - Loss: 269.0776 - Train Acc: 0.8782 - Val Acc: 0.8242\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 264.2148 - Train Acc: 0.8822 - Val Acc: 0.8147\n",
      "[Baseline] Epoch 47/50 - Loss: 260.8837 - Train Acc: 0.8824 - Val Acc: 0.8106\n",
      "[Baseline] Epoch 48/50 - Loss: 256.5370 - Train Acc: 0.8842 - Val Acc: 0.8235\n",
      "[Baseline] Epoch 49/50 - Loss: 254.9478 - Train Acc: 0.8843 - Val Acc: 0.8231\n",
      "[Baseline] Epoch 50/50 - Loss: 252.0909 - Train Acc: 0.8873 - Val Acc: 0.8288\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=30, Tw=20 (T_len=11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/2889036497.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 2924.0144 - Train Acc: 0.3669 - Val Acc: 0.5140\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 1792.7137 - Train Acc: 0.6387 - Val Acc: 0.5876\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 1447.5177 - Train Acc: 0.6964 - Val Acc: 0.6143\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 1250.0200 - Train Acc: 0.7264 - Val Acc: 0.6315\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 1123.0470 - Train Acc: 0.7508 - Val Acc: 0.6514\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 1031.3205 - Train Acc: 0.7681 - Val Acc: 0.6694\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 958.4355 - Train Acc: 0.7828 - Val Acc: 0.6895\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 898.9603 - Train Acc: 0.7976 - Val Acc: 0.7145\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 857.7100 - Train Acc: 0.8063 - Val Acc: 0.7184\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 817.2153 - Train Acc: 0.8147 - Val Acc: 0.7337\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 785.7463 - Train Acc: 0.8209 - Val Acc: 0.7266\n",
      "[Baseline] Epoch 12/50 - Loss: 758.6712 - Train Acc: 0.8273 - Val Acc: 0.7459\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 733.4449 - Train Acc: 0.8316 - Val Acc: 0.7610\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 715.2406 - Train Acc: 0.8354 - Val Acc: 0.7528\n",
      "[Baseline] Epoch 15/50 - Loss: 695.3584 - Train Acc: 0.8401 - Val Acc: 0.7610\n",
      "[Baseline] Epoch 16/50 - Loss: 677.6986 - Train Acc: 0.8454 - Val Acc: 0.7744\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 657.8190 - Train Acc: 0.8495 - Val Acc: 0.7872\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 644.4963 - Train Acc: 0.8526 - Val Acc: 0.7832\n",
      "[Baseline] Epoch 19/50 - Loss: 635.0327 - Train Acc: 0.8538 - Val Acc: 0.7901\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 621.8958 - Train Acc: 0.8549 - Val Acc: 0.7828\n",
      "[Baseline] Epoch 21/50 - Loss: 610.6561 - Train Acc: 0.8596 - Val Acc: 0.8023\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 596.0898 - Train Acc: 0.8614 - Val Acc: 0.8063\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 23/50 - Loss: 587.3205 - Train Acc: 0.8661 - Val Acc: 0.8061\n",
      "[Baseline] Epoch 24/50 - Loss: 580.7753 - Train Acc: 0.8654 - Val Acc: 0.8147\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 25/50 - Loss: 568.5833 - Train Acc: 0.8688 - Val Acc: 0.8153\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 566.2447 - Train Acc: 0.8686 - Val Acc: 0.8203\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 555.5369 - Train Acc: 0.8713 - Val Acc: 0.8094\n",
      "[Baseline] Epoch 28/50 - Loss: 548.6580 - Train Acc: 0.8732 - Val Acc: 0.8111\n",
      "[Baseline] Epoch 29/50 - Loss: 544.1812 - Train Acc: 0.8736 - Val Acc: 0.8082\n",
      "[Baseline] Epoch 30/50 - Loss: 537.2297 - Train Acc: 0.8749 - Val Acc: 0.8040\n",
      "[Baseline] Epoch 31/50 - Loss: 528.2610 - Train Acc: 0.8765 - Val Acc: 0.8048\n",
      "[Baseline] Epoch 32/50 - Loss: 522.3085 - Train Acc: 0.8786 - Val Acc: 0.8178\n",
      "[Baseline] Epoch 33/50 - Loss: 514.5532 - Train Acc: 0.8784 - Val Acc: 0.8164\n",
      "[Baseline] Epoch 34/50 - Loss: 511.8141 - Train Acc: 0.8814 - Val Acc: 0.8294\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 35/50 - Loss: 504.5293 - Train Acc: 0.8827 - Val Acc: 0.8266\n",
      "[Baseline] Epoch 36/50 - Loss: 500.3357 - Train Acc: 0.8828 - Val Acc: 0.8256\n",
      "[Baseline] Epoch 37/50 - Loss: 492.9621 - Train Acc: 0.8851 - Val Acc: 0.8272\n",
      "[Baseline] Epoch 38/50 - Loss: 492.6188 - Train Acc: 0.8844 - Val Acc: 0.8373\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 39/50 - Loss: 485.9892 - Train Acc: 0.8861 - Val Acc: 0.8298\n",
      "[Baseline] Epoch 40/50 - Loss: 481.5886 - Train Acc: 0.8878 - Val Acc: 0.8392\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 41/50 - Loss: 477.4096 - Train Acc: 0.8890 - Val Acc: 0.8398\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 42/50 - Loss: 472.7875 - Train Acc: 0.8894 - Val Acc: 0.8505\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 43/50 - Loss: 467.4022 - Train Acc: 0.8916 - Val Acc: 0.8468\n",
      "[Baseline] Epoch 44/50 - Loss: 463.5750 - Train Acc: 0.8918 - Val Acc: 0.8499\n",
      "[Baseline] Epoch 45/50 - Loss: 458.9911 - Train Acc: 0.8918 - Val Acc: 0.8512\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 456.1135 - Train Acc: 0.8924 - Val Acc: 0.8461\n",
      "[Baseline] Epoch 47/50 - Loss: 455.6586 - Train Acc: 0.8931 - Val Acc: 0.8415\n",
      "[Baseline] Epoch 48/50 - Loss: 448.8018 - Train Acc: 0.8950 - Val Acc: 0.8424\n",
      "[Baseline] Epoch 49/50 - Loss: 442.1710 - Train Acc: 0.8961 - Val Acc: 0.8516\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 50/50 - Loss: 440.4719 - Train Acc: 0.8988 - Val Acc: 0.8423\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=45, Tw=10 (T_len=36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/2889036497.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 795.1850 - Train Acc: 0.0982 - Val Acc: 0.1715\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 757.9555 - Train Acc: 0.1814 - Val Acc: 0.2820\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 660.4844 - Train Acc: 0.3393 - Val Acc: 0.4729\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 496.3854 - Train Acc: 0.5267 - Val Acc: 0.5126\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 423.6376 - Train Acc: 0.5992 - Val Acc: 0.5543\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 379.2786 - Train Acc: 0.6361 - Val Acc: 0.5736\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 344.0089 - Train Acc: 0.6698 - Val Acc: 0.5775\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 316.6165 - Train Acc: 0.7027 - Val Acc: 0.6153\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 293.7973 - Train Acc: 0.7249 - Val Acc: 0.6347\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 274.0228 - Train Acc: 0.7446 - Val Acc: 0.6773\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 258.8548 - Train Acc: 0.7544 - Val Acc: 0.6744\n",
      "[Baseline] Epoch 12/50 - Loss: 244.8483 - Train Acc: 0.7711 - Val Acc: 0.6812\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 232.9615 - Train Acc: 0.7787 - Val Acc: 0.6851\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 222.5428 - Train Acc: 0.7834 - Val Acc: 0.7006\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 216.0166 - Train Acc: 0.7865 - Val Acc: 0.7258\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 206.1416 - Train Acc: 0.7958 - Val Acc: 0.7238\n",
      "[Baseline] Epoch 17/50 - Loss: 198.9668 - Train Acc: 0.7973 - Val Acc: 0.7190\n",
      "[Baseline] Epoch 18/50 - Loss: 191.9049 - Train Acc: 0.8038 - Val Acc: 0.7161\n",
      "[Baseline] Epoch 19/50 - Loss: 186.1250 - Train Acc: 0.8042 - Val Acc: 0.7306\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 179.8489 - Train Acc: 0.8139 - Val Acc: 0.7297\n",
      "[Baseline] Epoch 21/50 - Loss: 175.6476 - Train Acc: 0.8147 - Val Acc: 0.7200\n",
      "[Baseline] Epoch 22/50 - Loss: 171.1561 - Train Acc: 0.8167 - Val Acc: 0.7422\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 23/50 - Loss: 165.5025 - Train Acc: 0.8232 - Val Acc: 0.7481\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 162.8986 - Train Acc: 0.8236 - Val Acc: 0.7529\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 25/50 - Loss: 158.0053 - Train Acc: 0.8313 - Val Acc: 0.7607\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 154.0529 - Train Acc: 0.8363 - Val Acc: 0.7413\n",
      "[Baseline] Epoch 27/50 - Loss: 150.8378 - Train Acc: 0.8352 - Val Acc: 0.7558\n",
      "[Baseline] Epoch 28/50 - Loss: 147.7099 - Train Acc: 0.8392 - Val Acc: 0.7674\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 144.0143 - Train Acc: 0.8473 - Val Acc: 0.7626\n",
      "[Baseline] Epoch 30/50 - Loss: 140.9270 - Train Acc: 0.8459 - Val Acc: 0.7791\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 31/50 - Loss: 138.5724 - Train Acc: 0.8473 - Val Acc: 0.7839\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 136.3327 - Train Acc: 0.8519 - Val Acc: 0.7694\n",
      "[Baseline] Epoch 33/50 - Loss: 134.3365 - Train Acc: 0.8547 - Val Acc: 0.7752\n",
      "[Baseline] Epoch 34/50 - Loss: 131.1175 - Train Acc: 0.8581 - Val Acc: 0.7839\n",
      "[Baseline] Epoch 35/50 - Loss: 130.6562 - Train Acc: 0.8577 - Val Acc: 0.7878\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 36/50 - Loss: 126.7455 - Train Acc: 0.8600 - Val Acc: 0.7984\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 125.7853 - Train Acc: 0.8628 - Val Acc: 0.7820\n",
      "[Baseline] Epoch 38/50 - Loss: 122.9169 - Train Acc: 0.8659 - Val Acc: 0.8023\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 39/50 - Loss: 121.5417 - Train Acc: 0.8665 - Val Acc: 0.8072\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 40/50 - Loss: 118.3507 - Train Acc: 0.8692 - Val Acc: 0.8023\n",
      "[Baseline] Epoch 41/50 - Loss: 116.4304 - Train Acc: 0.8754 - Val Acc: 0.8033\n",
      "[Baseline] Epoch 42/50 - Loss: 117.2239 - Train Acc: 0.8715 - Val Acc: 0.8149\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 43/50 - Loss: 114.3829 - Train Acc: 0.8754 - Val Acc: 0.8188\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 44/50 - Loss: 113.6345 - Train Acc: 0.8728 - Val Acc: 0.8072\n",
      "[Baseline] Epoch 45/50 - Loss: 111.4827 - Train Acc: 0.8760 - Val Acc: 0.8217\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 112.0515 - Train Acc: 0.8764 - Val Acc: 0.8217\n",
      "[Baseline] Epoch 47/50 - Loss: 108.5182 - Train Acc: 0.8827 - Val Acc: 0.8062\n",
      "[Baseline] Epoch 48/50 - Loss: 106.8453 - Train Acc: 0.8853 - Val Acc: 0.8198\n",
      "[Baseline] Epoch 49/50 - Loss: 106.0826 - Train Acc: 0.8845 - Val Acc: 0.8236\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 50/50 - Loss: 103.8877 - Train Acc: 0.8893 - Val Acc: 0.8198\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=45, Tw=15 (T_len=31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/2889036497.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 1021.2748 - Train Acc: 0.1151 - Val Acc: 0.1936\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 903.2810 - Train Acc: 0.2846 - Val Acc: 0.3535\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 646.2588 - Train Acc: 0.5116 - Val Acc: 0.5252\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 539.2468 - Train Acc: 0.6204 - Val Acc: 0.5515\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 474.6325 - Train Acc: 0.6711 - Val Acc: 0.5961\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 428.3898 - Train Acc: 0.7043 - Val Acc: 0.6158\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 393.4602 - Train Acc: 0.7249 - Val Acc: 0.6224\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 362.5944 - Train Acc: 0.7390 - Val Acc: 0.6370\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 339.9508 - Train Acc: 0.7492 - Val Acc: 0.6421\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 318.6683 - Train Acc: 0.7602 - Val Acc: 0.6538\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 300.3101 - Train Acc: 0.7735 - Val Acc: 0.6640\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 286.8128 - Train Acc: 0.7804 - Val Acc: 0.6720\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 273.5245 - Train Acc: 0.7851 - Val Acc: 0.6815\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 261.8604 - Train Acc: 0.7931 - Val Acc: 0.6786\n",
      "[Baseline] Epoch 15/50 - Loss: 250.6325 - Train Acc: 0.7965 - Val Acc: 0.6969\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 241.7865 - Train Acc: 0.8053 - Val Acc: 0.6932\n",
      "[Baseline] Epoch 17/50 - Loss: 232.6011 - Train Acc: 0.8127 - Val Acc: 0.7005\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 224.8942 - Train Acc: 0.8191 - Val Acc: 0.7144\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 217.8901 - Train Acc: 0.8260 - Val Acc: 0.7151\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 211.2519 - Train Acc: 0.8296 - Val Acc: 0.7166\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 205.5296 - Train Acc: 0.8329 - Val Acc: 0.7283\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 198.5412 - Train Acc: 0.8418 - Val Acc: 0.7356\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 23/50 - Loss: 192.7982 - Train Acc: 0.8457 - Val Acc: 0.7407\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 187.9269 - Train Acc: 0.8491 - Val Acc: 0.7385\n",
      "[Baseline] Epoch 25/50 - Loss: 182.0712 - Train Acc: 0.8535 - Val Acc: 0.7378\n",
      "[Baseline] Epoch 26/50 - Loss: 180.4764 - Train Acc: 0.8576 - Val Acc: 0.7575\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 174.1621 - Train Acc: 0.8606 - Val Acc: 0.7531\n",
      "[Baseline] Epoch 28/50 - Loss: 169.4646 - Train Acc: 0.8651 - Val Acc: 0.7582\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 164.8216 - Train Acc: 0.8680 - Val Acc: 0.7531\n",
      "[Baseline] Epoch 30/50 - Loss: 162.0488 - Train Acc: 0.8718 - Val Acc: 0.7575\n",
      "[Baseline] Epoch 31/50 - Loss: 159.3734 - Train Acc: 0.8740 - Val Acc: 0.7684\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 155.4166 - Train Acc: 0.8766 - Val Acc: 0.7604\n",
      "[Baseline] Epoch 33/50 - Loss: 151.1950 - Train Acc: 0.8799 - Val Acc: 0.7568\n",
      "[Baseline] Epoch 34/50 - Loss: 147.9127 - Train Acc: 0.8828 - Val Acc: 0.7940\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 35/50 - Loss: 146.6377 - Train Acc: 0.8818 - Val Acc: 0.7692\n",
      "[Baseline] Epoch 36/50 - Loss: 143.9155 - Train Acc: 0.8833 - Val Acc: 0.7955\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 139.2893 - Train Acc: 0.8897 - Val Acc: 0.7874\n",
      "[Baseline] Epoch 38/50 - Loss: 138.1666 - Train Acc: 0.8903 - Val Acc: 0.8006\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 39/50 - Loss: 135.2562 - Train Acc: 0.8923 - Val Acc: 0.7867\n",
      "[Baseline] Epoch 40/50 - Loss: 133.1481 - Train Acc: 0.8940 - Val Acc: 0.7750\n",
      "[Baseline] Epoch 41/50 - Loss: 131.4750 - Train Acc: 0.8947 - Val Acc: 0.8123\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 42/50 - Loss: 127.9074 - Train Acc: 0.8979 - Val Acc: 0.8035\n",
      "[Baseline] Epoch 43/50 - Loss: 124.9728 - Train Acc: 0.9039 - Val Acc: 0.8188\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 44/50 - Loss: 123.7865 - Train Acc: 0.9010 - Val Acc: 0.8269\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 45/50 - Loss: 121.5960 - Train Acc: 0.9032 - Val Acc: 0.8298\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 119.2728 - Train Acc: 0.9063 - Val Acc: 0.8225\n",
      "[Baseline] Epoch 47/50 - Loss: 119.2531 - Train Acc: 0.9042 - Val Acc: 0.8152\n",
      "[Baseline] Epoch 48/50 - Loss: 117.8722 - Train Acc: 0.9062 - Val Acc: 0.8137\n",
      "[Baseline] Epoch 49/50 - Loss: 114.1560 - Train Acc: 0.9093 - Val Acc: 0.8298\n",
      "[Baseline] Epoch 50/50 - Loss: 114.5314 - Train Acc: 0.9088 - Val Acc: 0.8225\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=45, Tw=20 (T_len=26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/2889036497.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 1189.9786 - Train Acc: 0.1133 - Val Acc: 0.2114\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 990.4392 - Train Acc: 0.3388 - Val Acc: 0.4095\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 696.7639 - Train Acc: 0.5528 - Val Acc: 0.4890\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 589.5908 - Train Acc: 0.6185 - Val Acc: 0.5199\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 526.4869 - Train Acc: 0.6587 - Val Acc: 0.5514\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 479.3709 - Train Acc: 0.6808 - Val Acc: 0.5811\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 446.6503 - Train Acc: 0.7027 - Val Acc: 0.5981\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 417.0485 - Train Acc: 0.7197 - Val Acc: 0.6309\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 392.9793 - Train Acc: 0.7333 - Val Acc: 0.6372\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 370.0808 - Train Acc: 0.7493 - Val Acc: 0.6536\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 351.1047 - Train Acc: 0.7606 - Val Acc: 0.6479\n",
      "[Baseline] Epoch 12/50 - Loss: 333.8250 - Train Acc: 0.7702 - Val Acc: 0.6726\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 317.0943 - Train Acc: 0.7819 - Val Acc: 0.6845\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 305.0518 - Train Acc: 0.7907 - Val Acc: 0.7016\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 291.1190 - Train Acc: 0.7989 - Val Acc: 0.7009\n",
      "[Baseline] Epoch 16/50 - Loss: 279.2916 - Train Acc: 0.8067 - Val Acc: 0.7186\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 268.5996 - Train Acc: 0.8148 - Val Acc: 0.7180\n",
      "[Baseline] Epoch 18/50 - Loss: 259.2826 - Train Acc: 0.8195 - Val Acc: 0.7256\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 249.4867 - Train Acc: 0.8286 - Val Acc: 0.7230\n",
      "[Baseline] Epoch 20/50 - Loss: 243.3073 - Train Acc: 0.8326 - Val Acc: 0.7432\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 235.7675 - Train Acc: 0.8368 - Val Acc: 0.7457\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 230.4534 - Train Acc: 0.8371 - Val Acc: 0.7502\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 23/50 - Loss: 224.1025 - Train Acc: 0.8416 - Val Acc: 0.7634\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 219.2544 - Train Acc: 0.8458 - Val Acc: 0.7546\n",
      "[Baseline] Epoch 25/50 - Loss: 214.2514 - Train Acc: 0.8514 - Val Acc: 0.7590\n",
      "[Baseline] Epoch 26/50 - Loss: 210.3756 - Train Acc: 0.8541 - Val Acc: 0.7754\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 205.9076 - Train Acc: 0.8568 - Val Acc: 0.7760\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 200.5918 - Train Acc: 0.8616 - Val Acc: 0.7855\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 197.4706 - Train Acc: 0.8632 - Val Acc: 0.7868\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 30/50 - Loss: 193.2987 - Train Acc: 0.8655 - Val Acc: 0.7760\n",
      "[Baseline] Epoch 31/50 - Loss: 190.6203 - Train Acc: 0.8677 - Val Acc: 0.7760\n",
      "[Baseline] Epoch 32/50 - Loss: 187.7817 - Train Acc: 0.8690 - Val Acc: 0.8013\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 33/50 - Loss: 185.0140 - Train Acc: 0.8727 - Val Acc: 0.7905\n",
      "[Baseline] Epoch 34/50 - Loss: 182.4678 - Train Acc: 0.8715 - Val Acc: 0.7981\n",
      "[Baseline] Epoch 35/50 - Loss: 179.2859 - Train Acc: 0.8731 - Val Acc: 0.7886\n",
      "[Baseline] Epoch 36/50 - Loss: 176.9585 - Train Acc: 0.8743 - Val Acc: 0.8076\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 173.5570 - Train Acc: 0.8793 - Val Acc: 0.8038\n",
      "[Baseline] Epoch 38/50 - Loss: 171.0084 - Train Acc: 0.8797 - Val Acc: 0.8032\n",
      "[Baseline] Epoch 39/50 - Loss: 167.2535 - Train Acc: 0.8817 - Val Acc: 0.8114\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 40/50 - Loss: 165.7594 - Train Acc: 0.8844 - Val Acc: 0.8227\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 41/50 - Loss: 163.0366 - Train Acc: 0.8875 - Val Acc: 0.8126\n",
      "[Baseline] Epoch 42/50 - Loss: 161.1967 - Train Acc: 0.8871 - Val Acc: 0.8202\n",
      "[Baseline] Epoch 43/50 - Loss: 157.3609 - Train Acc: 0.8887 - Val Acc: 0.8050\n",
      "[Baseline] Epoch 44/50 - Loss: 157.4529 - Train Acc: 0.8885 - Val Acc: 0.8278\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 45/50 - Loss: 155.2402 - Train Acc: 0.8922 - Val Acc: 0.8221\n",
      "[Baseline] Epoch 46/50 - Loss: 153.2261 - Train Acc: 0.8928 - Val Acc: 0.8208\n",
      "[Baseline] Epoch 47/50 - Loss: 152.1911 - Train Acc: 0.8935 - Val Acc: 0.8309\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 48/50 - Loss: 149.2420 - Train Acc: 0.8976 - Val Acc: 0.8334\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 49/50 - Loss: 146.8742 - Train Acc: 0.8982 - Val Acc: 0.8360\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 50/50 - Loss: 145.5876 - Train Acc: 0.8992 - Val Acc: 0.8366\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=60, Tw=10 (T_len=51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/2889036497.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 563.7924 - Train Acc: 0.0908 - Val Acc: 0.0975\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 548.1748 - Train Acc: 0.1426 - Val Acc: 0.2518\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 516.0055 - Train Acc: 0.2524 - Val Acc: 0.3217\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 425.7091 - Train Acc: 0.4012 - Val Acc: 0.4396\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 331.3293 - Train Acc: 0.5530 - Val Acc: 0.5415\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 286.3548 - Train Acc: 0.6359 - Val Acc: 0.5968\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 258.8428 - Train Acc: 0.6689 - Val Acc: 0.6361\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 236.9295 - Train Acc: 0.6925 - Val Acc: 0.6579\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 220.8065 - Train Acc: 0.7110 - Val Acc: 0.6652\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 207.7650 - Train Acc: 0.7241 - Val Acc: 0.6638\n",
      "[Baseline] Epoch 11/50 - Loss: 196.5041 - Train Acc: 0.7408 - Val Acc: 0.6783\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 187.5751 - Train Acc: 0.7513 - Val Acc: 0.6812\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 179.8300 - Train Acc: 0.7586 - Val Acc: 0.6929\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 173.0709 - Train Acc: 0.7611 - Val Acc: 0.7016\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 165.2328 - Train Acc: 0.7801 - Val Acc: 0.7045\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 160.2999 - Train Acc: 0.7773 - Val Acc: 0.7045\n",
      "[Baseline] Epoch 17/50 - Loss: 155.1158 - Train Acc: 0.7884 - Val Acc: 0.7074\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 149.3323 - Train Acc: 0.7998 - Val Acc: 0.7234\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 144.2769 - Train Acc: 0.8036 - Val Acc: 0.7307\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 139.6084 - Train Acc: 0.8114 - Val Acc: 0.7249\n",
      "[Baseline] Epoch 21/50 - Loss: 135.5506 - Train Acc: 0.8166 - Val Acc: 0.7394\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 131.1850 - Train Acc: 0.8204 - Val Acc: 0.7409\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 23/50 - Loss: 127.7128 - Train Acc: 0.8228 - Val Acc: 0.7555\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 123.4884 - Train Acc: 0.8294 - Val Acc: 0.7715\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 25/50 - Loss: 120.1121 - Train Acc: 0.8381 - Val Acc: 0.7569\n",
      "[Baseline] Epoch 26/50 - Loss: 115.7011 - Train Acc: 0.8422 - Val Acc: 0.7686\n",
      "[Baseline] Epoch 27/50 - Loss: 112.1436 - Train Acc: 0.8449 - Val Acc: 0.7773\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 109.4579 - Train Acc: 0.8486 - Val Acc: 0.7948\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 106.4995 - Train Acc: 0.8514 - Val Acc: 0.7889\n",
      "[Baseline] Epoch 30/50 - Loss: 103.9128 - Train Acc: 0.8536 - Val Acc: 0.7715\n",
      "[Baseline] Epoch 31/50 - Loss: 101.0468 - Train Acc: 0.8560 - Val Acc: 0.8108\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 97.4758 - Train Acc: 0.8584 - Val Acc: 0.7918\n",
      "[Baseline] Epoch 33/50 - Loss: 96.1089 - Train Acc: 0.8596 - Val Acc: 0.8049\n",
      "[Baseline] Epoch 34/50 - Loss: 92.8385 - Train Acc: 0.8639 - Val Acc: 0.7933\n",
      "[Baseline] Epoch 35/50 - Loss: 90.3360 - Train Acc: 0.8683 - Val Acc: 0.8064\n",
      "[Baseline] Epoch 36/50 - Loss: 89.1764 - Train Acc: 0.8699 - Val Acc: 0.8020\n",
      "[Baseline] Epoch 37/50 - Loss: 85.5799 - Train Acc: 0.8742 - Val Acc: 0.8064\n",
      "[Baseline] Epoch 38/50 - Loss: 84.6644 - Train Acc: 0.8760 - Val Acc: 0.8224\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 39/50 - Loss: 83.7497 - Train Acc: 0.8731 - Val Acc: 0.8166\n",
      "[Baseline] Epoch 40/50 - Loss: 81.9006 - Train Acc: 0.8770 - Val Acc: 0.8210\n",
      "[Baseline] Epoch 41/50 - Loss: 80.2015 - Train Acc: 0.8798 - Val Acc: 0.8311\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 42/50 - Loss: 77.4919 - Train Acc: 0.8820 - Val Acc: 0.8239\n",
      "[Baseline] Epoch 43/50 - Loss: 76.3943 - Train Acc: 0.8854 - Val Acc: 0.8210\n",
      "[Baseline] Epoch 44/50 - Loss: 75.5619 - Train Acc: 0.8856 - Val Acc: 0.8268\n",
      "[Baseline] Epoch 45/50 - Loss: 73.5413 - Train Acc: 0.8870 - Val Acc: 0.8326\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 72.4926 - Train Acc: 0.8880 - Val Acc: 0.8166\n",
      "[Baseline] Epoch 47/50 - Loss: 71.1504 - Train Acc: 0.8930 - Val Acc: 0.8297\n",
      "[Baseline] Epoch 48/50 - Loss: 71.0320 - Train Acc: 0.8886 - Val Acc: 0.8515\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 49/50 - Loss: 69.4318 - Train Acc: 0.8918 - Val Acc: 0.8443\n",
      "[Baseline] Epoch 50/50 - Loss: 68.5337 - Train Acc: 0.8961 - Val Acc: 0.8282\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=60, Tw=15 (T_len=46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/2889036497.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 616.3801 - Train Acc: 0.1204 - Val Acc: 0.2316\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 571.6800 - Train Acc: 0.2717 - Val Acc: 0.3063\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 475.4276 - Train Acc: 0.3946 - Val Acc: 0.4595\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 384.5420 - Train Acc: 0.5441 - Val Acc: 0.5278\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 330.1582 - Train Acc: 0.6391 - Val Acc: 0.5772\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 291.8006 - Train Acc: 0.6887 - Val Acc: 0.5987\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 260.7522 - Train Acc: 0.7274 - Val Acc: 0.6203\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 236.8064 - Train Acc: 0.7439 - Val Acc: 0.6392\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 216.8049 - Train Acc: 0.7594 - Val Acc: 0.6481\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 201.1830 - Train Acc: 0.7722 - Val Acc: 0.6418\n",
      "[Baseline] Epoch 11/50 - Loss: 188.4779 - Train Acc: 0.7820 - Val Acc: 0.6468\n",
      "[Baseline] Epoch 12/50 - Loss: 175.9882 - Train Acc: 0.7935 - Val Acc: 0.6633\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 167.5522 - Train Acc: 0.8016 - Val Acc: 0.6595\n",
      "[Baseline] Epoch 14/50 - Loss: 158.4778 - Train Acc: 0.8066 - Val Acc: 0.6557\n",
      "[Baseline] Epoch 15/50 - Loss: 151.9422 - Train Acc: 0.8149 - Val Acc: 0.6785\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 144.8913 - Train Acc: 0.8219 - Val Acc: 0.6722\n",
      "[Baseline] Epoch 17/50 - Loss: 139.9324 - Train Acc: 0.8238 - Val Acc: 0.6734\n",
      "[Baseline] Epoch 18/50 - Loss: 133.0617 - Train Acc: 0.8316 - Val Acc: 0.6810\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 127.7487 - Train Acc: 0.8392 - Val Acc: 0.6911\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 122.6550 - Train Acc: 0.8476 - Val Acc: 0.6886\n",
      "[Baseline] Epoch 21/50 - Loss: 117.8684 - Train Acc: 0.8506 - Val Acc: 0.7190\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 114.5540 - Train Acc: 0.8534 - Val Acc: 0.7101\n",
      "[Baseline] Epoch 23/50 - Loss: 110.7523 - Train Acc: 0.8560 - Val Acc: 0.7291\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 107.8582 - Train Acc: 0.8612 - Val Acc: 0.7278\n",
      "[Baseline] Epoch 25/50 - Loss: 105.3418 - Train Acc: 0.8654 - Val Acc: 0.7380\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 101.5444 - Train Acc: 0.8709 - Val Acc: 0.7494\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 98.7122 - Train Acc: 0.8773 - Val Acc: 0.7532\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 95.9075 - Train Acc: 0.8838 - Val Acc: 0.7633\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 93.9980 - Train Acc: 0.8827 - Val Acc: 0.7544\n",
      "[Baseline] Epoch 30/50 - Loss: 90.7245 - Train Acc: 0.8875 - Val Acc: 0.7557\n",
      "[Baseline] Epoch 31/50 - Loss: 88.9044 - Train Acc: 0.8914 - Val Acc: 0.7785\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 87.0416 - Train Acc: 0.8927 - Val Acc: 0.7861\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 33/50 - Loss: 84.3418 - Train Acc: 0.8960 - Val Acc: 0.7785\n",
      "[Baseline] Epoch 34/50 - Loss: 81.8763 - Train Acc: 0.8994 - Val Acc: 0.7962\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 35/50 - Loss: 80.4993 - Train Acc: 0.9016 - Val Acc: 0.7835\n",
      "[Baseline] Epoch 36/50 - Loss: 78.4736 - Train Acc: 0.9038 - Val Acc: 0.8076\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 77.2158 - Train Acc: 0.9054 - Val Acc: 0.8051\n",
      "[Baseline] Epoch 38/50 - Loss: 75.3500 - Train Acc: 0.9080 - Val Acc: 0.8076\n",
      "[Baseline] Epoch 39/50 - Loss: 74.3380 - Train Acc: 0.9109 - Val Acc: 0.8139\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 40/50 - Loss: 72.6499 - Train Acc: 0.9091 - Val Acc: 0.8139\n",
      "[Baseline] Epoch 41/50 - Loss: 71.6913 - Train Acc: 0.9128 - Val Acc: 0.8253\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 42/50 - Loss: 70.0995 - Train Acc: 0.9089 - Val Acc: 0.8304\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 43/50 - Loss: 67.5013 - Train Acc: 0.9170 - Val Acc: 0.8380\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 44/50 - Loss: 67.5377 - Train Acc: 0.9147 - Val Acc: 0.8392\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 45/50 - Loss: 65.8666 - Train Acc: 0.9192 - Val Acc: 0.8392\n",
      "[Baseline] Epoch 46/50 - Loss: 65.3863 - Train Acc: 0.9182 - Val Acc: 0.8418\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 47/50 - Loss: 63.0238 - Train Acc: 0.9231 - Val Acc: 0.8456\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 48/50 - Loss: 63.8602 - Train Acc: 0.9203 - Val Acc: 0.8519\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 49/50 - Loss: 62.5653 - Train Acc: 0.9233 - Val Acc: 0.8557\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 50/50 - Loss: 61.2464 - Train Acc: 0.9239 - Val Acc: 0.8519\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=60, Tw=20 (T_len=41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/2889036497.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 687.8594 - Train Acc: 0.1078 - Val Acc: 0.1874\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 661.6139 - Train Acc: 0.1793 - Val Acc: 0.3091\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 591.5781 - Train Acc: 0.3184 - Val Acc: 0.4450\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 442.2271 - Train Acc: 0.5093 - Val Acc: 0.5082\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 384.5699 - Train Acc: 0.5799 - Val Acc: 0.5386\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 349.4540 - Train Acc: 0.6190 - Val Acc: 0.5644\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 324.4666 - Train Acc: 0.6450 - Val Acc: 0.5867\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 303.7319 - Train Acc: 0.6711 - Val Acc: 0.6054\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 283.3491 - Train Acc: 0.6890 - Val Acc: 0.5937\n",
      "[Baseline] Epoch 10/50 - Loss: 266.4719 - Train Acc: 0.7080 - Val Acc: 0.6241\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 251.2754 - Train Acc: 0.7255 - Val Acc: 0.6311\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 238.3884 - Train Acc: 0.7429 - Val Acc: 0.6417\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 224.2302 - Train Acc: 0.7580 - Val Acc: 0.6522\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 215.1324 - Train Acc: 0.7664 - Val Acc: 0.6569\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 205.9810 - Train Acc: 0.7753 - Val Acc: 0.6663\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 196.7949 - Train Acc: 0.7780 - Val Acc: 0.6663\n",
      "[Baseline] Epoch 17/50 - Loss: 189.5181 - Train Acc: 0.7862 - Val Acc: 0.6651\n",
      "[Baseline] Epoch 18/50 - Loss: 182.1877 - Train Acc: 0.7934 - Val Acc: 0.6850\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 174.5861 - Train Acc: 0.8010 - Val Acc: 0.6885\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 166.9020 - Train Acc: 0.8081 - Val Acc: 0.6967\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 160.4900 - Train Acc: 0.8144 - Val Acc: 0.7143\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 155.9140 - Train Acc: 0.8184 - Val Acc: 0.7026\n",
      "[Baseline] Epoch 23/50 - Loss: 150.5665 - Train Acc: 0.8271 - Val Acc: 0.7213\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 145.3176 - Train Acc: 0.8300 - Val Acc: 0.7155\n",
      "[Baseline] Epoch 25/50 - Loss: 139.6966 - Train Acc: 0.8390 - Val Acc: 0.7201\n",
      "[Baseline] Epoch 26/50 - Loss: 136.3398 - Train Acc: 0.8423 - Val Acc: 0.7237\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 131.7802 - Train Acc: 0.8471 - Val Acc: 0.7354\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 127.8235 - Train Acc: 0.8520 - Val Acc: 0.7471\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 123.6342 - Train Acc: 0.8567 - Val Acc: 0.7693\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 30/50 - Loss: 121.7628 - Train Acc: 0.8571 - Val Acc: 0.7529\n",
      "[Baseline] Epoch 31/50 - Loss: 118.2737 - Train Acc: 0.8591 - Val Acc: 0.7763\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 114.7304 - Train Acc: 0.8678 - Val Acc: 0.7881\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 33/50 - Loss: 112.4088 - Train Acc: 0.8720 - Val Acc: 0.7658\n",
      "[Baseline] Epoch 34/50 - Loss: 109.9288 - Train Acc: 0.8719 - Val Acc: 0.7541\n",
      "[Baseline] Epoch 35/50 - Loss: 107.3495 - Train Acc: 0.8759 - Val Acc: 0.7857\n",
      "[Baseline] Epoch 36/50 - Loss: 104.1280 - Train Acc: 0.8809 - Val Acc: 0.7752\n",
      "[Baseline] Epoch 37/50 - Loss: 102.5364 - Train Acc: 0.8810 - Val Acc: 0.8056\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 38/50 - Loss: 100.9499 - Train Acc: 0.8805 - Val Acc: 0.7939\n",
      "[Baseline] Epoch 39/50 - Loss: 99.1904 - Train Acc: 0.8824 - Val Acc: 0.8056\n",
      "[Baseline] Epoch 40/50 - Loss: 96.8434 - Train Acc: 0.8842 - Val Acc: 0.8021\n",
      "[Baseline] Epoch 41/50 - Loss: 95.8480 - Train Acc: 0.8875 - Val Acc: 0.8044\n",
      "[Baseline] Epoch 42/50 - Loss: 93.7745 - Train Acc: 0.8905 - Val Acc: 0.7974\n",
      "[Baseline] Epoch 43/50 - Loss: 91.9191 - Train Acc: 0.8922 - Val Acc: 0.8091\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 44/50 - Loss: 90.0634 - Train Acc: 0.8958 - Val Acc: 0.8009\n",
      "[Baseline] Epoch 45/50 - Loss: 90.0926 - Train Acc: 0.8926 - Val Acc: 0.8255\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 86.8418 - Train Acc: 0.8971 - Val Acc: 0.8150\n",
      "[Baseline] Epoch 47/50 - Loss: 85.1753 - Train Acc: 0.9023 - Val Acc: 0.8056\n",
      "[Baseline] Epoch 48/50 - Loss: 85.0969 - Train Acc: 0.8975 - Val Acc: 0.8208\n",
      "[Baseline] Epoch 49/50 - Loss: 83.2899 - Train Acc: 0.9021 - Val Acc: 0.8208\n",
      "[Baseline] Epoch 50/50 - Loss: 80.8252 - Train Acc: 0.9065 - Val Acc: 0.8208\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student/student_baseline_Td60_Tw20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/2889036497.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    }
   ],
   "source": [
    "baseline_save_dir = \"/home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/baseline_student\"\n",
    "os.makedirs(baseline_save_dir, exist_ok=True)\n",
    "detection_times = [30, 45, 60]\n",
    "window_sizes = [10, 15, 20]\n",
    "base_dir = \"/home/HardDisk/Satang/thesis_proj\"\n",
    "for T_d in detection_times:\n",
    "    for T_w in window_sizes:\n",
    "        T_len = T_d - T_w + 1\n",
    "        expected_shape = (T_len, NUM_FEATURES)\n",
    "\n",
    "        print(f\"\\n🚀 Training Standalone Student for Td={T_d}, Tw={T_w} (T_len={T_len})\")\n",
    "\n",
    "        # === Paths\n",
    "        folder_name = f\"X_csv_split_{T_len}\"\n",
    "        input_dir = os.path.join(base_dir, f\"New_{T_d}\", f\"{T_w}\", \"split_tws\", folder_name)\n",
    "        train_path = os.path.join(input_dir, \"train\")\n",
    "        val_path   = os.path.join(input_dir, \"val\")\n",
    "        student_model_path = os.path.join(baseline_save_dir, f\"student_baseline_Td{T_d}_Tw{T_w}.pth\")\n",
    "\n",
    "        # === Load Data\n",
    "        X_train_raw, y_train_raw = load_split_from_folder(train_path, expected_shape)\n",
    "        X_val_raw, y_val_raw     = load_split_from_folder(val_path, expected_shape)\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_encoded = label_encoder.fit_transform(y_train_raw)\n",
    "\n",
    "        X_train_flat = X_train_raw.reshape(X_train_raw.shape[0], -1)\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X_train_flat, y_train_encoded)\n",
    "        X_train_bal = X_resampled.reshape(-1, T_len, NUM_FEATURES)\n",
    "        y_train_str = label_encoder.inverse_transform(y_resampled)\n",
    "\n",
    "        train_dataset = MultiStreamDataset(X_train_bal, y_train_str, label_encoder, augment=True)\n",
    "        val_dataset   = MultiStreamDataset(X_val_raw, y_val_raw, label_encoder, augment=False)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        class_weights_tensor = compute_class_weights(label_encoder.transform(y_train_str), device)\n",
    "\n",
    "        # === Initialize Student Model\n",
    "        student_baseline = StudentCNN(input_length=T_len, num_classes=len(label_encoder.classes_)).to(device)\n",
    "\n",
    "        # === Train (No KD)\n",
    "        train_accs_b, val_accs_b, train_losses_b, val_losses_b = train_student_baseline(\n",
    "            student=student_baseline,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            device=device,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            lr=0.00005,\n",
    "            class_weights=class_weights_tensor,\n",
    "            save_path=student_model_path\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Saved standalone student model: {student_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4cfc3e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2403693/4250007063.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All evaluation results saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/transformer/results/model_eval_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# === CONFIG ===\n",
    "detection_times = [30, 45, 60]\n",
    "window_sizes = [10, 15, 20]\n",
    "NUM_FEATURES = 8\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_dir = \"/home/HardDisk/Satang/thesis_proj/\"\n",
    "base_teacher_dir = os.path.join(base_dir, \"Deep_Learning\", \"cross_archi\",\"transformer\", \"teacher\")\n",
    "student_kd_dir = os.path.join(base_dir, \"Deep_Learning\",\"cross_archi\",\"transformer\", \"student\")\n",
    "student_baseline_dir = os.path.join(base_dir, \"Deep_Learning\",\"cross_archi\",\"transformer\", \"baseline_student\")\n",
    "csv_output_path = os.path.join(base_dir, \"Deep_Learning\",\"cross_archi\",\"transformer\", \"results\", \"model_eval_summary.csv\")\n",
    "os.makedirs(os.path.dirname(csv_output_path), exist_ok=True)\n",
    "\n",
    "# # === YOUR MODULE IMPORTS ===\n",
    "# from your_module import load_split_from_folder, MultiStreamDataset, RansomwareTransformer, StudentCNN\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_and_log(model, model_path, test_loader, label_encoder, T_d, T_w, model_type, results_list):\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    report = classification_report(all_labels, all_preds, target_names=label_encoder.classes_, output_dict=True)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    results_list.append({\n",
    "        \"Td\": T_d,\n",
    "        \"Tw\": T_w,\n",
    "        \"T_len\": T_d - T_w + 1,\n",
    "        \"Model\": model_type,\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"Precision_macro\": round(report[\"macro avg\"][\"precision\"], 4),\n",
    "        \"Recall_macro\": round(report[\"macro avg\"][\"recall\"], 4),\n",
    "        \"F1_macro\": round(report[\"macro avg\"][\"f1-score\"], 4),\n",
    "        \"F1_weighted\": round(report[\"weighted avg\"][\"f1-score\"], 4),\n",
    "    })\n",
    "\n",
    "# === MAIN EVALUATION LOOP ===\n",
    "for T_d in detection_times:\n",
    "    for T_w in window_sizes:\n",
    "        T_len = T_d - T_w + 1\n",
    "        expected_shape = (T_len, NUM_FEATURES)\n",
    "        folder_name = f\"X_csv_split_{T_len}\"\n",
    "        test_path = os.path.join(base_dir, f\"New_{T_d}\", f\"{T_w}\", \"split_tws\", folder_name, \"test\")\n",
    "\n",
    "        # === Load test set ===\n",
    "        X_test_raw, y_test_raw = load_split_from_folder(test_path, expected_shape)\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.fit(y_test_raw)\n",
    "\n",
    "        test_dataset = MultiStreamDataset(X_test_raw, y_test_raw, label_encoder, augment=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # === Teacher ===\n",
    "        teacher_path = os.path.join(base_teacher_dir, f\"transformer_Td{T_d}_Tw{T_w}.pth\")\n",
    "        teacher = RansomwareTransformer(input_dim=NUM_FEATURES, seq_len=T_len, num_classes=len(label_encoder.classes_))\n",
    "        evaluate_and_log(teacher, teacher_path, test_loader, label_encoder, T_d, T_w, \"Teacher\", results)\n",
    "\n",
    "        # === Student with KD ===\n",
    "        student_kd_path = os.path.join(student_kd_dir, f\"student_Td{T_d}_Tw{T_w}.pth\")\n",
    "        student_kd = StudentCNN(input_length=T_len, num_classes=len(label_encoder.classes_))\n",
    "        evaluate_and_log(student_kd, student_kd_path, test_loader, label_encoder, T_d, T_w, \"Student_KD\", results)\n",
    "\n",
    "        # === Student Baseline ===\n",
    "        student_b_path = os.path.join(student_baseline_dir, f\"student_baseline_Td{T_d}_Tw{T_w}.pth\")\n",
    "        student_b = StudentCNN(input_length=T_len, num_classes=len(label_encoder.classes_))\n",
    "        evaluate_and_log(student_b, student_b_path, test_loader, label_encoder, T_d, T_w, \"Student_Baseline\", results)\n",
    "\n",
    "# === Save to CSV ===\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(csv_output_path, index=False)\n",
    "print(f\"\\n✅ All evaluation results saved to {csv_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e710ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_satang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
