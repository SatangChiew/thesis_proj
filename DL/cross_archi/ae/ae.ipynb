{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7620488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ba272555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "INPUT_DIR = \"/home/HardDisk/Satang/thesis_proj/New_45/15/split_tws/X_csv_split_31\"\n",
    "CHUNK_SIZE = 31\n",
    "NUM_FEATURES = 8\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "K_FOLDS = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf7ac9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPERS ===\n",
    "def collate_fn(batch):\n",
    "    streams, labels = zip(*batch)\n",
    "    streams = list(zip(*streams))\n",
    "    streams = [torch.stack(s) for s in streams]\n",
    "    labels = torch.tensor(labels)\n",
    "    return streams, labels\n",
    "\n",
    "def compute_class_weights(labels, device):\n",
    "    counter = Counter(labels)\n",
    "    total = sum(counter.values())\n",
    "    weights = [np.log(total / (counter[i] + 1)) for i in range(len(counter))]\n",
    "    return torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "def print_model_info(model):\n",
    "    print(\"Model Architecture:\")\n",
    "    print(model)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "def plot_loss_curve(train_losses, val_losses):\n",
    "    epochs = range(len(train_losses))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, label='Train Loss', color='blue')\n",
    "    plt.plot(epochs, val_losses, label='Val Loss', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_curve(train_acc, val_acc):\n",
    "    epochs = range(len(train_acc))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_acc, label='Train Accuracy', color='green')\n",
    "    plt.plot(epochs, val_acc, label='Val Accuracy', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training vs Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86cf8f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATASET CLASS ===\n",
    "class MultiStreamDataset(Dataset):\n",
    "    def __init__(self, data, labels, label_encoder, augment=False):\n",
    "        self.data = data\n",
    "        self.labels = label_encoder.transform(labels)\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def augment_stream(self, stream):\n",
    "        jitter = np.random.normal(0, 0.01, stream.shape)\n",
    "        scale = np.random.normal(1.0, 0.05, stream.shape)\n",
    "        return stream * scale + jitter\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]  # shape: (T, 8)\n",
    "        \n",
    "        if self.augment:\n",
    "            # Apply augmentation to each feature independently\n",
    "            jitter = np.random.normal(0, 0.01, sample.shape)\n",
    "            scale = np.random.normal(1.0, 0.05, sample.shape)\n",
    "            sample = sample * scale + jitter\n",
    "\n",
    "        sample_tensor = torch.tensor(sample, dtype=torch.float32)  # shape: (T, 8)\n",
    "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "    \n",
    "        return sample_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04b030d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class AEWithClassifier(nn.Module):\n",
    "    def __init__(self, input_length=31, feature_dim=8, latent_dim=64, num_classes=12, proj_dim=128):\n",
    "        super(AEWithClassifier, self).__init__()\n",
    "\n",
    "        self.encoder_out_len = math.ceil(input_length / 2)  # ceil(31/2) = 16\n",
    "\n",
    "        # === Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(feature_dim, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * self.encoder_out_len, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # === Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64 * self.encoder_out_len),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (64, self.encoder_out_len)),\n",
    "            nn.ConvTranspose1d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, feature_dim, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        # === Classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "        # === Projection for KD (feature distillation)\n",
    "        self.projection = nn.Linear(latent_dim, proj_dim)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        \"\"\"\n",
    "        return_features:\n",
    "            - False → returns logits and recon (for training)\n",
    "            - True  → returns logits, recon, and projected feature (for KD)\n",
    "        \"\"\"\n",
    "        T_orig = x.shape[1]               # (B, 31, 8)\n",
    "        x = x.permute(0, 2, 1)            # → (B, 8, 31)\n",
    "        latent = self.encoder(x)          # → (B, latent_dim)\n",
    "        recon = self.decoder(latent).permute(0, 2, 1)\n",
    "        recon = recon[:, :T_orig, :]      # trim to match input shape\n",
    "        logits = self.classifier(latent)\n",
    "        proj_feat = self.projection(latent)  # → (B, proj_dim)\n",
    "\n",
    "        if return_features:\n",
    "            return logits, recon, proj_feat\n",
    "        else:\n",
    "            return logits, recon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d3ade61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # === COLLATE FUNCTION ===\n",
    "# def collate_fn(batch):\n",
    "#     streams, labels = zip(*batch)\n",
    "#     streams = list(zip(*streams))\n",
    "#     streams = [torch.stack(s) for s in streams]\n",
    "#     labels = torch.tensor(labels)\n",
    "#     return streams, labels\n",
    "\n",
    "# === LOAD SPLIT FUNCTION ===\n",
    "def load_split_from_folder(split_dir, expected_shape):\n",
    "    X, y = [], []\n",
    "    for class_name in sorted(os.listdir(split_dir)):\n",
    "        class_path = os.path.join(split_dir, class_name)\n",
    "        for fname in sorted(os.listdir(class_path)):\n",
    "            if fname.endswith(\".csv\"):\n",
    "                fpath = os.path.join(class_path, fname)\n",
    "                chunk = pd.read_csv(fpath, header=None).values\n",
    "                if chunk.shape == expected_shape:\n",
    "                    X.append(chunk)\n",
    "                    y.append(class_name)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5820cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === APPLY SMOTE ===\n",
    "def apply_smote_on_training(X_chunks, y_labels, chunk_size, num_features):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y_labels)\n",
    "\n",
    "    smote_encoder = LabelEncoder()\n",
    "    y_encoded_for_smote = smote_encoder.fit_transform(y_labels)\n",
    "\n",
    "    X_flat = X_chunks.reshape(X_chunks.shape[0], -1)\n",
    "    X_resampled, y_resampled = SMOTE().fit_resample(X_flat, y_encoded_for_smote)\n",
    "\n",
    "    X_res = X_resampled.reshape(-1, chunk_size, num_features)\n",
    "    y_res_str = smote_encoder.inverse_transform(y_resampled)\n",
    "\n",
    "    return X_res, y_res_str, label_encoder\n",
    "\n",
    "# # === LOAD DATASETS ===\n",
    "# expected_shape = (CHUNK_SIZE, NUM_FEATURES)\n",
    "\n",
    "# X_train_raw, y_train_raw = load_split_from_folder(os.path.join(INPUT_DIR, \"train\"), expected_shape)\n",
    "# X_val_raw,   y_val_raw   = load_split_from_folder(os.path.join(INPUT_DIR, \"val\"), expected_shape)\n",
    "\n",
    "# # === SMOTE ONLY ON TRAIN ===\n",
    "# X_train_balanced, y_train_str, label_encoder = apply_smote_on_training(\n",
    "#     X_train_raw, y_train_raw, CHUNK_SIZE, NUM_FEATURES\n",
    "# )\n",
    "\n",
    "# # === CREATE DATASETS ===\n",
    "# train_dataset = MultiStreamDataset(X_train_balanced, y_train_str, label_encoder, augment=True)\n",
    "# val_dataset   = MultiStreamDataset(X_val_raw, y_val_raw, label_encoder, augment=False)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01654335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLASS WEIGHTING ===\n",
    "def compute_class_weights(labels, device):\n",
    "    from collections import Counter\n",
    "    total = len(labels)\n",
    "    counts = Counter(labels)\n",
    "    weights = [np.log(total / (counts[i] + 1)) for i in range(len(counts))]\n",
    "    return torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "# class_weights_tensor = compute_class_weights(label_encoder.transform(y_train_str), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bcba14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=50, lr=0.001,\n",
    "                class_weights=None, optimizer=None, scheduler=None,\n",
    "                alpha=1.0, beta=1.0, best_model_path=\"ae_classifier_model.pth\"):\n",
    "\n",
    "    print(\"🔍 Class Weights Tensor:\")\n",
    "    print(class_weights)\n",
    "\n",
    "    criterion_ce = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion_mse = nn.MSELoss()\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct = 0.0, 0\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            logits, recon = model(inputs)\n",
    "\n",
    "            loss_ce = criterion_ce(logits, labels)\n",
    "            loss_mse = criterion_mse(recon, inputs)\n",
    "            loss = alpha * loss_ce + beta * loss_mse\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (logits.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(total_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # === Validation ===\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                logits, recon = model(inputs)\n",
    "\n",
    "                loss_ce = criterion_ce(logits, labels)\n",
    "                loss_mse = criterion_mse(recon, inputs)\n",
    "                loss = alpha * loss_ce + beta * loss_mse\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (logits.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "              f\"Train Loss: {total_loss:.4f} - Val Loss: {val_loss:.4f} - \"\n",
    "              f\"Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"💾 Best model saved to: {best_model_path}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    return train_accuracies, val_accuracies, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e0fac89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running for Td=30, Tw=10\n",
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4843, 2.4843, 2.4843, 2.4843, 2.4843, 2.4843, 2.4843, 2.4843, 2.4843,\n",
      "        2.4843, 2.4843, 2.4843], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 665.3254 - Val Loss: 61.3876 - Train Acc: 0.5477 - Val Acc: 0.5952\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 2/50 - Train Loss: 438.9683 - Val Loss: 58.2725 - Train Acc: 0.7115 - Val Acc: 0.6303\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 3/50 - Train Loss: 371.9378 - Val Loss: 47.9647 - Train Acc: 0.7565 - Val Acc: 0.6633\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 4/50 - Train Loss: 348.6307 - Val Loss: 53.7893 - Train Acc: 0.7758 - Val Acc: 0.6628\n",
      "Epoch 5/50 - Train Loss: 339.3365 - Val Loss: 44.8948 - Train Acc: 0.7848 - Val Acc: 0.6859\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 6/50 - Train Loss: 308.2572 - Val Loss: 46.7206 - Train Acc: 0.7995 - Val Acc: 0.6909\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 7/50 - Train Loss: 313.3342 - Val Loss: 41.9789 - Train Acc: 0.8035 - Val Acc: 0.7435\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 8/50 - Train Loss: 323.9992 - Val Loss: 43.2175 - Train Acc: 0.8011 - Val Acc: 0.7109\n",
      "Epoch 9/50 - Train Loss: 290.5084 - Val Loss: 41.3762 - Train Acc: 0.8172 - Val Acc: 0.7290\n",
      "Epoch 10/50 - Train Loss: 288.6176 - Val Loss: 42.2964 - Train Acc: 0.8210 - Val Acc: 0.7410\n",
      "Epoch 11/50 - Train Loss: 266.3137 - Val Loss: 41.9267 - Train Acc: 0.8328 - Val Acc: 0.7515\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 12/50 - Train Loss: 271.3162 - Val Loss: 40.0439 - Train Acc: 0.8365 - Val Acc: 0.7325\n",
      "Epoch 13/50 - Train Loss: 263.2266 - Val Loss: 38.6586 - Train Acc: 0.8386 - Val Acc: 0.7500\n",
      "Epoch 14/50 - Train Loss: 268.4886 - Val Loss: 36.6114 - Train Acc: 0.8378 - Val Acc: 0.7735\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 15/50 - Train Loss: 247.1157 - Val Loss: 46.4870 - Train Acc: 0.8512 - Val Acc: 0.7605\n",
      "Epoch 16/50 - Train Loss: 255.9970 - Val Loss: 31.7120 - Train Acc: 0.8498 - Val Acc: 0.8186\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 17/50 - Train Loss: 234.6225 - Val Loss: 37.4447 - Train Acc: 0.8545 - Val Acc: 0.7876\n",
      "Epoch 18/50 - Train Loss: 231.4228 - Val Loss: 32.2779 - Train Acc: 0.8611 - Val Acc: 0.8061\n",
      "Epoch 19/50 - Train Loss: 233.3938 - Val Loss: 35.4950 - Train Acc: 0.8619 - Val Acc: 0.7901\n",
      "Epoch 20/50 - Train Loss: 214.8914 - Val Loss: 32.1170 - Train Acc: 0.8671 - Val Acc: 0.8267\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 21/50 - Train Loss: 213.4222 - Val Loss: 30.5339 - Train Acc: 0.8709 - Val Acc: 0.8287\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 22/50 - Train Loss: 210.1560 - Val Loss: 30.0493 - Train Acc: 0.8714 - Val Acc: 0.8211\n",
      "Epoch 23/50 - Train Loss: 199.8514 - Val Loss: 33.4964 - Train Acc: 0.8786 - Val Acc: 0.7966\n",
      "Epoch 24/50 - Train Loss: 190.9579 - Val Loss: 28.8929 - Train Acc: 0.8827 - Val Acc: 0.8347\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 25/50 - Train Loss: 187.4810 - Val Loss: 27.0558 - Train Acc: 0.8834 - Val Acc: 0.8287\n",
      "Epoch 26/50 - Train Loss: 177.1602 - Val Loss: 26.9435 - Train Acc: 0.8902 - Val Acc: 0.8457\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 27/50 - Train Loss: 188.2356 - Val Loss: 24.3576 - Train Acc: 0.8900 - Val Acc: 0.8432\n",
      "Epoch 28/50 - Train Loss: 173.2594 - Val Loss: 27.5113 - Train Acc: 0.8942 - Val Acc: 0.8492\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 29/50 - Train Loss: 163.2467 - Val Loss: 24.4451 - Train Acc: 0.8990 - Val Acc: 0.8617\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 30/50 - Train Loss: 163.7316 - Val Loss: 23.8143 - Train Acc: 0.9037 - Val Acc: 0.8667\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 31/50 - Train Loss: 157.6182 - Val Loss: 28.3095 - Train Acc: 0.9035 - Val Acc: 0.8236\n",
      "Epoch 32/50 - Train Loss: 149.8629 - Val Loss: 23.5828 - Train Acc: 0.9070 - Val Acc: 0.8687\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 33/50 - Train Loss: 146.9218 - Val Loss: 23.1251 - Train Acc: 0.9118 - Val Acc: 0.8707\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 34/50 - Train Loss: 141.2733 - Val Loss: 25.8635 - Train Acc: 0.9138 - Val Acc: 0.8532\n",
      "Epoch 35/50 - Train Loss: 136.6029 - Val Loss: 23.5405 - Train Acc: 0.9162 - Val Acc: 0.8672\n",
      "Epoch 36/50 - Train Loss: 135.5200 - Val Loss: 21.3856 - Train Acc: 0.9185 - Val Acc: 0.8813\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 37/50 - Train Loss: 129.8598 - Val Loss: 22.5072 - Train Acc: 0.9230 - Val Acc: 0.8793\n",
      "Epoch 38/50 - Train Loss: 125.7885 - Val Loss: 22.2244 - Train Acc: 0.9235 - Val Acc: 0.8783\n",
      "Epoch 39/50 - Train Loss: 128.3978 - Val Loss: 21.9029 - Train Acc: 0.9222 - Val Acc: 0.8863\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 40/50 - Train Loss: 124.4006 - Val Loss: 22.0252 - Train Acc: 0.9250 - Val Acc: 0.8873\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 41/50 - Train Loss: 122.6923 - Val Loss: 21.8602 - Train Acc: 0.9251 - Val Acc: 0.8888\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 42/50 - Train Loss: 119.9438 - Val Loss: 22.1269 - Train Acc: 0.9277 - Val Acc: 0.8768\n",
      "Epoch 43/50 - Train Loss: 118.7629 - Val Loss: 20.8497 - Train Acc: 0.9296 - Val Acc: 0.8883\n",
      "Epoch 44/50 - Train Loss: 118.4226 - Val Loss: 21.5268 - Train Acc: 0.9279 - Val Acc: 0.8888\n",
      "Epoch 45/50 - Train Loss: 114.2592 - Val Loss: 21.0523 - Train Acc: 0.9307 - Val Acc: 0.8918\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "Epoch 46/50 - Train Loss: 111.9259 - Val Loss: 21.5106 - Train Acc: 0.9326 - Val Acc: 0.8878\n",
      "Epoch 47/50 - Train Loss: 113.2869 - Val Loss: 21.1637 - Train Acc: 0.9310 - Val Acc: 0.8918\n",
      "Epoch 48/50 - Train Loss: 112.3913 - Val Loss: 21.1502 - Train Acc: 0.9319 - Val Acc: 0.8883\n",
      "Epoch 49/50 - Train Loss: 111.5736 - Val Loss: 21.2291 - Train Acc: 0.9329 - Val Acc: 0.8893\n",
      "Epoch 50/50 - Train Loss: 112.6304 - Val Loss: 21.2291 - Train Acc: 0.9323 - Val Acc: 0.8893\n",
      "✅ Finished Td=30, Tw=10 — saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw10.pth\n",
      "\n",
      "🚀 Running for Td=30, Tw=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/2838713473.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4844, 2.4844, 2.4844, 2.4844, 2.4844, 2.4844, 2.4844, 2.4844, 2.4844,\n",
      "        2.4844, 2.4844, 2.4844], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 844.6827 - Val Loss: 83.3527 - Train Acc: 0.6035 - Val Acc: 0.6241\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 2/50 - Train Loss: 538.4773 - Val Loss: 85.3176 - Train Acc: 0.7544 - Val Acc: 0.6424\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 3/50 - Train Loss: 465.4708 - Val Loss: 62.9853 - Train Acc: 0.7895 - Val Acc: 0.7122\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 4/50 - Train Loss: 429.6114 - Val Loss: 58.1299 - Train Acc: 0.8041 - Val Acc: 0.7251\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 5/50 - Train Loss: 423.5153 - Val Loss: 63.1255 - Train Acc: 0.8137 - Val Acc: 0.7210\n",
      "Epoch 6/50 - Train Loss: 400.5272 - Val Loss: 60.1174 - Train Acc: 0.8204 - Val Acc: 0.7179\n",
      "Epoch 7/50 - Train Loss: 363.1933 - Val Loss: 61.5651 - Train Acc: 0.8333 - Val Acc: 0.7304\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 8/50 - Train Loss: 355.5422 - Val Loss: 55.3450 - Train Acc: 0.8417 - Val Acc: 0.7479\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 9/50 - Train Loss: 349.6590 - Val Loss: 71.4783 - Train Acc: 0.8463 - Val Acc: 0.7745\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 10/50 - Train Loss: 335.6664 - Val Loss: 54.3452 - Train Acc: 0.8476 - Val Acc: 0.7498\n",
      "Epoch 11/50 - Train Loss: 329.1544 - Val Loss: 61.2198 - Train Acc: 0.8513 - Val Acc: 0.7418\n",
      "Epoch 12/50 - Train Loss: 320.4992 - Val Loss: 55.4196 - Train Acc: 0.8566 - Val Acc: 0.7555\n",
      "Epoch 13/50 - Train Loss: 299.0253 - Val Loss: 64.1552 - Train Acc: 0.8622 - Val Acc: 0.7593\n",
      "Epoch 14/50 - Train Loss: 313.1615 - Val Loss: 69.9505 - Train Acc: 0.8617 - Val Acc: 0.7593\n",
      "Epoch 15/50 - Train Loss: 279.9333 - Val Loss: 55.0246 - Train Acc: 0.8752 - Val Acc: 0.7935\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 16/50 - Train Loss: 295.4694 - Val Loss: 55.9557 - Train Acc: 0.8788 - Val Acc: 0.8090\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 17/50 - Train Loss: 258.9897 - Val Loss: 79.9569 - Train Acc: 0.8870 - Val Acc: 0.8052\n",
      "Epoch 18/50 - Train Loss: 254.6817 - Val Loss: 59.3191 - Train Acc: 0.8898 - Val Acc: 0.8052\n",
      "Epoch 19/50 - Train Loss: 245.8374 - Val Loss: 93.5462 - Train Acc: 0.8936 - Val Acc: 0.8079\n",
      "Epoch 20/50 - Train Loss: 245.6877 - Val Loss: 67.6768 - Train Acc: 0.8947 - Val Acc: 0.8280\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 21/50 - Train Loss: 233.7617 - Val Loss: 52.2671 - Train Acc: 0.8993 - Val Acc: 0.8189\n",
      "Epoch 22/50 - Train Loss: 216.6667 - Val Loss: 77.9343 - Train Acc: 0.9081 - Val Acc: 0.8261\n",
      "Epoch 23/50 - Train Loss: 225.5735 - Val Loss: 60.7049 - Train Acc: 0.9087 - Val Acc: 0.8246\n",
      "Epoch 24/50 - Train Loss: 205.1700 - Val Loss: 50.1781 - Train Acc: 0.9137 - Val Acc: 0.8383\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 25/50 - Train Loss: 195.6299 - Val Loss: 56.8686 - Train Acc: 0.9188 - Val Acc: 0.8474\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 26/50 - Train Loss: 191.4061 - Val Loss: 70.8862 - Train Acc: 0.9192 - Val Acc: 0.8413\n",
      "Epoch 27/50 - Train Loss: 184.6071 - Val Loss: 45.0545 - Train Acc: 0.9209 - Val Acc: 0.8478\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 28/50 - Train Loss: 170.2224 - Val Loss: 66.9472 - Train Acc: 0.9261 - Val Acc: 0.8580\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 29/50 - Train Loss: 167.2981 - Val Loss: 64.6744 - Train Acc: 0.9291 - Val Acc: 0.8500\n",
      "Epoch 30/50 - Train Loss: 170.6616 - Val Loss: 50.8183 - Train Acc: 0.9314 - Val Acc: 0.8660\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 31/50 - Train Loss: 156.3215 - Val Loss: 67.4281 - Train Acc: 0.9334 - Val Acc: 0.8709\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 32/50 - Train Loss: 151.1175 - Val Loss: 49.5986 - Train Acc: 0.9353 - Val Acc: 0.8641\n",
      "Epoch 33/50 - Train Loss: 148.0177 - Val Loss: 46.2417 - Train Acc: 0.9378 - Val Acc: 0.8690\n",
      "Epoch 34/50 - Train Loss: 139.3823 - Val Loss: 45.9777 - Train Acc: 0.9405 - Val Acc: 0.8660\n",
      "Epoch 35/50 - Train Loss: 132.0825 - Val Loss: 47.4640 - Train Acc: 0.9445 - Val Acc: 0.8781\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 36/50 - Train Loss: 129.7886 - Val Loss: 47.8110 - Train Acc: 0.9452 - Val Acc: 0.8713\n",
      "Epoch 37/50 - Train Loss: 130.0575 - Val Loss: 44.6103 - Train Acc: 0.9442 - Val Acc: 0.8797\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 38/50 - Train Loss: 122.3037 - Val Loss: 45.4677 - Train Acc: 0.9471 - Val Acc: 0.8812\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 39/50 - Train Loss: 116.3498 - Val Loss: 46.2222 - Train Acc: 0.9493 - Val Acc: 0.8743\n",
      "Epoch 40/50 - Train Loss: 116.0357 - Val Loss: 53.0677 - Train Acc: 0.9492 - Val Acc: 0.8778\n",
      "Epoch 41/50 - Train Loss: 111.4731 - Val Loss: 50.0022 - Train Acc: 0.9515 - Val Acc: 0.8819\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 42/50 - Train Loss: 110.3705 - Val Loss: 53.6461 - Train Acc: 0.9530 - Val Acc: 0.8759\n",
      "Epoch 43/50 - Train Loss: 106.7266 - Val Loss: 52.3122 - Train Acc: 0.9533 - Val Acc: 0.8785\n",
      "Epoch 44/50 - Train Loss: 105.5528 - Val Loss: 55.1712 - Train Acc: 0.9539 - Val Acc: 0.8781\n",
      "Epoch 45/50 - Train Loss: 103.9017 - Val Loss: 55.0786 - Train Acc: 0.9547 - Val Acc: 0.8838\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "Epoch 46/50 - Train Loss: 101.8631 - Val Loss: 54.5491 - Train Acc: 0.9559 - Val Acc: 0.8823\n",
      "Epoch 47/50 - Train Loss: 102.0789 - Val Loss: 53.9046 - Train Acc: 0.9567 - Val Acc: 0.8834\n",
      "Epoch 48/50 - Train Loss: 101.6178 - Val Loss: 54.0697 - Train Acc: 0.9561 - Val Acc: 0.8823\n",
      "Epoch 49/50 - Train Loss: 100.7712 - Val Loss: 54.1765 - Train Acc: 0.9562 - Val Acc: 0.8815\n",
      "Epoch 50/50 - Train Loss: 100.5801 - Val Loss: 54.1765 - Train Acc: 0.9567 - Val Acc: 0.8815\n",
      "✅ Finished Td=30, Tw=15 — saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw15.pth\n",
      "\n",
      "🚀 Running for Td=30, Tw=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/2838713473.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4847, 2.4847, 2.4847, 2.4847, 2.4847, 2.4847, 2.4847, 2.4847, 2.4847,\n",
      "        2.4847, 2.4847, 2.4847], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 1467.6679 - Val Loss: 146.4048 - Train Acc: 0.6495 - Val Acc: 0.6489\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 2/50 - Train Loss: 913.0849 - Val Loss: 133.7987 - Train Acc: 0.7902 - Val Acc: 0.7086\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 3/50 - Train Loss: 809.4099 - Val Loss: 125.2087 - Train Acc: 0.8127 - Val Acc: 0.7231\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 4/50 - Train Loss: 773.2794 - Val Loss: 116.9252 - Train Acc: 0.8236 - Val Acc: 0.7348\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 5/50 - Train Loss: 732.0862 - Val Loss: 120.8637 - Train Acc: 0.8350 - Val Acc: 0.7539\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 6/50 - Train Loss: 686.6946 - Val Loss: 122.8813 - Train Acc: 0.8456 - Val Acc: 0.7501\n",
      "Epoch 7/50 - Train Loss: 701.8142 - Val Loss: 117.9232 - Train Acc: 0.8425 - Val Acc: 0.7598\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 8/50 - Train Loss: 667.8610 - Val Loss: 118.9122 - Train Acc: 0.8538 - Val Acc: 0.7524\n",
      "Epoch 9/50 - Train Loss: 652.8001 - Val Loss: 107.6180 - Train Acc: 0.8596 - Val Acc: 0.7751\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 10/50 - Train Loss: 634.4340 - Val Loss: 101.1697 - Train Acc: 0.8596 - Val Acc: 0.7969\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 11/50 - Train Loss: 612.7073 - Val Loss: 105.5948 - Train Acc: 0.8656 - Val Acc: 0.7946\n",
      "Epoch 12/50 - Train Loss: 625.4390 - Val Loss: 102.6293 - Train Acc: 0.8685 - Val Acc: 0.7734\n",
      "Epoch 13/50 - Train Loss: 598.7116 - Val Loss: 94.7816 - Train Acc: 0.8687 - Val Acc: 0.8252\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 14/50 - Train Loss: 568.4246 - Val Loss: 102.7535 - Train Acc: 0.8790 - Val Acc: 0.8086\n",
      "Epoch 15/50 - Train Loss: 553.5327 - Val Loss: 116.3692 - Train Acc: 0.8824 - Val Acc: 0.8283\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 16/50 - Train Loss: 530.0667 - Val Loss: 94.7365 - Train Acc: 0.8862 - Val Acc: 0.8382\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 17/50 - Train Loss: 527.0632 - Val Loss: 106.4142 - Train Acc: 0.8876 - Val Acc: 0.8247\n",
      "Epoch 18/50 - Train Loss: 503.0310 - Val Loss: 113.2495 - Train Acc: 0.8927 - Val Acc: 0.8258\n",
      "Epoch 19/50 - Train Loss: 488.9966 - Val Loss: 99.4293 - Train Acc: 0.8982 - Val Acc: 0.8306\n",
      "Epoch 20/50 - Train Loss: 472.0290 - Val Loss: 87.3308 - Train Acc: 0.9011 - Val Acc: 0.8570\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 21/50 - Train Loss: 462.1491 - Val Loss: 100.6947 - Train Acc: 0.9024 - Val Acc: 0.8541\n",
      "Epoch 22/50 - Train Loss: 452.3167 - Val Loss: 92.9568 - Train Acc: 0.9057 - Val Acc: 0.8354\n",
      "Epoch 23/50 - Train Loss: 426.7183 - Val Loss: 85.5104 - Train Acc: 0.9092 - Val Acc: 0.8486\n",
      "Epoch 24/50 - Train Loss: 406.0422 - Val Loss: 88.2966 - Train Acc: 0.9120 - Val Acc: 0.8484\n",
      "Epoch 25/50 - Train Loss: 416.5225 - Val Loss: 90.9890 - Train Acc: 0.9129 - Val Acc: 0.8593\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 26/50 - Train Loss: 389.0200 - Val Loss: 99.9316 - Train Acc: 0.9177 - Val Acc: 0.8685\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 27/50 - Train Loss: 377.3310 - Val Loss: 96.1150 - Train Acc: 0.9184 - Val Acc: 0.8564\n",
      "Epoch 28/50 - Train Loss: 361.3507 - Val Loss: 86.1489 - Train Acc: 0.9222 - Val Acc: 0.8711\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 29/50 - Train Loss: 350.3660 - Val Loss: 94.3933 - Train Acc: 0.9252 - Val Acc: 0.8748\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 30/50 - Train Loss: 340.6923 - Val Loss: 83.9262 - Train Acc: 0.9257 - Val Acc: 0.8707\n",
      "Epoch 31/50 - Train Loss: 326.6898 - Val Loss: 84.8392 - Train Acc: 0.9293 - Val Acc: 0.8618\n",
      "Epoch 32/50 - Train Loss: 314.0714 - Val Loss: 90.6453 - Train Acc: 0.9320 - Val Acc: 0.8694\n",
      "Epoch 33/50 - Train Loss: 308.5552 - Val Loss: 100.8614 - Train Acc: 0.9332 - Val Acc: 0.8644\n",
      "Epoch 34/50 - Train Loss: 291.5901 - Val Loss: 84.2219 - Train Acc: 0.9368 - Val Acc: 0.8776\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 35/50 - Train Loss: 281.5487 - Val Loss: 88.5639 - Train Acc: 0.9386 - Val Acc: 0.8767\n",
      "Epoch 36/50 - Train Loss: 272.7864 - Val Loss: 85.7226 - Train Acc: 0.9396 - Val Acc: 0.8816\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 37/50 - Train Loss: 265.7476 - Val Loss: 86.3593 - Train Acc: 0.9410 - Val Acc: 0.8815\n",
      "Epoch 38/50 - Train Loss: 258.7269 - Val Loss: 86.9059 - Train Acc: 0.9436 - Val Acc: 0.8776\n",
      "Epoch 39/50 - Train Loss: 258.3693 - Val Loss: 84.5013 - Train Acc: 0.9429 - Val Acc: 0.8788\n",
      "Epoch 40/50 - Train Loss: 246.2739 - Val Loss: 93.1589 - Train Acc: 0.9458 - Val Acc: 0.8811\n",
      "Epoch 41/50 - Train Loss: 242.2719 - Val Loss: 86.3936 - Train Acc: 0.9464 - Val Acc: 0.8824\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 42/50 - Train Loss: 237.3391 - Val Loss: 91.4199 - Train Acc: 0.9468 - Val Acc: 0.8822\n",
      "Epoch 43/50 - Train Loss: 234.3006 - Val Loss: 94.3214 - Train Acc: 0.9476 - Val Acc: 0.8839\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 44/50 - Train Loss: 228.8047 - Val Loss: 89.6099 - Train Acc: 0.9499 - Val Acc: 0.8924\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "Epoch 45/50 - Train Loss: 224.7593 - Val Loss: 92.1663 - Train Acc: 0.9498 - Val Acc: 0.8874\n",
      "Epoch 46/50 - Train Loss: 222.1692 - Val Loss: 89.2020 - Train Acc: 0.9500 - Val Acc: 0.8891\n",
      "Epoch 47/50 - Train Loss: 222.2139 - Val Loss: 90.3098 - Train Acc: 0.9505 - Val Acc: 0.8876\n",
      "Epoch 48/50 - Train Loss: 223.2861 - Val Loss: 90.3274 - Train Acc: 0.9502 - Val Acc: 0.8889\n",
      "Epoch 49/50 - Train Loss: 222.0688 - Val Loss: 90.6847 - Train Acc: 0.9501 - Val Acc: 0.8889\n",
      "Epoch 50/50 - Train Loss: 221.0628 - Val Loss: 90.6847 - Train Acc: 0.9506 - Val Acc: 0.8889\n",
      "✅ Finished Td=30, Tw=20 — saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td30_Tw20.pth\n",
      "\n",
      "🚀 Running for Td=45, Tw=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/2838713473.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4837, 2.4837, 2.4837, 2.4837, 2.4837, 2.4837, 2.4837, 2.4837, 2.4837,\n",
      "        2.4837, 2.4837, 2.4837], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 363.7928 - Val Loss: 29.1162 - Train Acc: 0.5905 - Val Acc: 0.6647\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 2/50 - Train Loss: 189.8854 - Val Loss: 20.7240 - Train Acc: 0.7958 - Val Acc: 0.7888\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 3/50 - Train Loss: 154.1902 - Val Loss: 24.4546 - Train Acc: 0.8414 - Val Acc: 0.7578\n",
      "Epoch 4/50 - Train Loss: 142.5998 - Val Loss: 18.9775 - Train Acc: 0.8596 - Val Acc: 0.7975\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 5/50 - Train Loss: 126.7055 - Val Loss: 18.1499 - Train Acc: 0.8720 - Val Acc: 0.7946\n",
      "Epoch 6/50 - Train Loss: 113.6025 - Val Loss: 18.1361 - Train Acc: 0.8812 - Val Acc: 0.7878\n",
      "Epoch 7/50 - Train Loss: 112.5039 - Val Loss: 19.7543 - Train Acc: 0.8890 - Val Acc: 0.8266\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 8/50 - Train Loss: 110.4586 - Val Loss: 16.8746 - Train Acc: 0.9012 - Val Acc: 0.8459\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 9/50 - Train Loss: 94.8962 - Val Loss: 16.5790 - Train Acc: 0.9152 - Val Acc: 0.8333\n",
      "Epoch 10/50 - Train Loss: 92.5643 - Val Loss: 15.6600 - Train Acc: 0.9126 - Val Acc: 0.8663\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 11/50 - Train Loss: 87.5848 - Val Loss: 13.7532 - Train Acc: 0.9199 - Val Acc: 0.8624\n",
      "Epoch 12/50 - Train Loss: 91.2533 - Val Loss: 15.0941 - Train Acc: 0.9181 - Val Acc: 0.8672\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 13/50 - Train Loss: 72.3730 - Val Loss: 17.5834 - Train Acc: 0.9350 - Val Acc: 0.8479\n",
      "Epoch 14/50 - Train Loss: 65.5061 - Val Loss: 15.0068 - Train Acc: 0.9401 - Val Acc: 0.8808\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 15/50 - Train Loss: 68.5356 - Val Loss: 14.6759 - Train Acc: 0.9407 - Val Acc: 0.8750\n",
      "Epoch 16/50 - Train Loss: 67.3600 - Val Loss: 16.5391 - Train Acc: 0.9416 - Val Acc: 0.8702\n",
      "Epoch 17/50 - Train Loss: 70.7025 - Val Loss: 16.1182 - Train Acc: 0.9382 - Val Acc: 0.8750\n",
      "Epoch 18/50 - Train Loss: 58.1601 - Val Loss: 18.9385 - Train Acc: 0.9483 - Val Acc: 0.8605\n",
      "Epoch 19/50 - Train Loss: 49.2944 - Val Loss: 17.4286 - Train Acc: 0.9607 - Val Acc: 0.8740\n",
      "Epoch 20/50 - Train Loss: 47.0394 - Val Loss: 21.8269 - Train Acc: 0.9613 - Val Acc: 0.8672\n",
      "Epoch 21/50 - Train Loss: 52.3186 - Val Loss: 19.3245 - Train Acc: 0.9582 - Val Acc: 0.8711\n",
      "Epoch 22/50 - Train Loss: 38.2965 - Val Loss: 17.1540 - Train Acc: 0.9678 - Val Acc: 0.8857\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 23/50 - Train Loss: 38.1293 - Val Loss: 14.2748 - Train Acc: 0.9674 - Val Acc: 0.8944\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 24/50 - Train Loss: 31.4608 - Val Loss: 14.6621 - Train Acc: 0.9746 - Val Acc: 0.9021\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 25/50 - Train Loss: 30.6324 - Val Loss: 17.4540 - Train Acc: 0.9750 - Val Acc: 0.8876\n",
      "Epoch 26/50 - Train Loss: 28.4741 - Val Loss: 15.2560 - Train Acc: 0.9781 - Val Acc: 0.9099\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 27/50 - Train Loss: 29.2894 - Val Loss: 19.5108 - Train Acc: 0.9797 - Val Acc: 0.8905\n",
      "Epoch 28/50 - Train Loss: 27.3751 - Val Loss: 15.2514 - Train Acc: 0.9806 - Val Acc: 0.9118\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 29/50 - Train Loss: 29.0701 - Val Loss: 14.9374 - Train Acc: 0.9798 - Val Acc: 0.9060\n",
      "Epoch 30/50 - Train Loss: 21.9788 - Val Loss: 15.2850 - Train Acc: 0.9841 - Val Acc: 0.9089\n",
      "Epoch 31/50 - Train Loss: 19.7750 - Val Loss: 15.7334 - Train Acc: 0.9853 - Val Acc: 0.9079\n",
      "Epoch 32/50 - Train Loss: 18.9513 - Val Loss: 15.7950 - Train Acc: 0.9869 - Val Acc: 0.9041\n",
      "Epoch 33/50 - Train Loss: 17.4829 - Val Loss: 16.4462 - Train Acc: 0.9886 - Val Acc: 0.9041\n",
      "Epoch 34/50 - Train Loss: 12.9913 - Val Loss: 19.0820 - Train Acc: 0.9915 - Val Acc: 0.9031\n",
      "Epoch 35/50 - Train Loss: 14.1428 - Val Loss: 16.2167 - Train Acc: 0.9904 - Val Acc: 0.9060\n",
      "Epoch 36/50 - Train Loss: 12.2317 - Val Loss: 16.9138 - Train Acc: 0.9915 - Val Acc: 0.9167\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 37/50 - Train Loss: 12.1546 - Val Loss: 19.4630 - Train Acc: 0.9923 - Val Acc: 0.9070\n",
      "Epoch 38/50 - Train Loss: 11.9022 - Val Loss: 17.6193 - Train Acc: 0.9919 - Val Acc: 0.9109\n",
      "Epoch 39/50 - Train Loss: 11.5428 - Val Loss: 17.9755 - Train Acc: 0.9920 - Val Acc: 0.9138\n",
      "Epoch 40/50 - Train Loss: 10.2161 - Val Loss: 18.5716 - Train Acc: 0.9935 - Val Acc: 0.9128\n",
      "Epoch 41/50 - Train Loss: 9.4435 - Val Loss: 17.9575 - Train Acc: 0.9944 - Val Acc: 0.9089\n",
      "Epoch 42/50 - Train Loss: 9.0283 - Val Loss: 18.8989 - Train Acc: 0.9947 - Val Acc: 0.9138\n",
      "Epoch 43/50 - Train Loss: 9.1837 - Val Loss: 18.7263 - Train Acc: 0.9941 - Val Acc: 0.9167\n",
      "Epoch 44/50 - Train Loss: 8.9744 - Val Loss: 18.4980 - Train Acc: 0.9948 - Val Acc: 0.9205\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "Epoch 45/50 - Train Loss: 8.5024 - Val Loss: 18.1655 - Train Acc: 0.9954 - Val Acc: 0.9176\n",
      "Epoch 46/50 - Train Loss: 8.2416 - Val Loss: 18.4190 - Train Acc: 0.9954 - Val Acc: 0.9196\n",
      "Epoch 47/50 - Train Loss: 8.4080 - Val Loss: 18.1242 - Train Acc: 0.9957 - Val Acc: 0.9186\n",
      "Epoch 48/50 - Train Loss: 8.6288 - Val Loss: 18.1820 - Train Acc: 0.9956 - Val Acc: 0.9196\n",
      "Epoch 49/50 - Train Loss: 8.6738 - Val Loss: 18.1904 - Train Acc: 0.9949 - Val Acc: 0.9186\n",
      "Epoch 50/50 - Train Loss: 8.1855 - Val Loss: 18.1904 - Train Acc: 0.9954 - Val Acc: 0.9186\n",
      "✅ Finished Td=45, Tw=10 — saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw10.pth\n",
      "\n",
      "🚀 Running for Td=45, Tw=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/2838713473.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4840, 2.4840, 2.4840, 2.4840, 2.4840, 2.4840, 2.4840, 2.4840, 2.4840,\n",
      "        2.4840, 2.4840, 2.4840], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 498.6688 - Val Loss: 41.9366 - Train Acc: 0.5593 - Val Acc: 0.6618\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 2/50 - Train Loss: 254.9611 - Val Loss: 32.1267 - Train Acc: 0.7740 - Val Acc: 0.7042\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 3/50 - Train Loss: 223.7796 - Val Loss: 28.3622 - Train Acc: 0.8146 - Val Acc: 0.7290\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 4/50 - Train Loss: 195.7496 - Val Loss: 28.4846 - Train Acc: 0.8315 - Val Acc: 0.7341\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 5/50 - Train Loss: 196.4238 - Val Loss: 28.3946 - Train Acc: 0.8415 - Val Acc: 0.7516\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 6/50 - Train Loss: 173.9751 - Val Loss: 27.2804 - Train Acc: 0.8584 - Val Acc: 0.7531\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 7/50 - Train Loss: 179.7349 - Val Loss: 28.9318 - Train Acc: 0.8545 - Val Acc: 0.7524\n",
      "Epoch 8/50 - Train Loss: 176.5763 - Val Loss: 24.1702 - Train Acc: 0.8687 - Val Acc: 0.7955\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 9/50 - Train Loss: 162.4101 - Val Loss: 27.8216 - Train Acc: 0.8797 - Val Acc: 0.7874\n",
      "Epoch 10/50 - Train Loss: 152.8229 - Val Loss: 33.7708 - Train Acc: 0.8846 - Val Acc: 0.7750\n",
      "Epoch 11/50 - Train Loss: 140.2659 - Val Loss: 28.8106 - Train Acc: 0.8916 - Val Acc: 0.7787\n",
      "Epoch 12/50 - Train Loss: 118.2636 - Val Loss: 23.2301 - Train Acc: 0.9036 - Val Acc: 0.8335\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 13/50 - Train Loss: 146.2767 - Val Loss: 33.3621 - Train Acc: 0.8994 - Val Acc: 0.7969\n",
      "Epoch 14/50 - Train Loss: 131.0252 - Val Loss: 21.8161 - Train Acc: 0.9026 - Val Acc: 0.8356\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 15/50 - Train Loss: 121.9485 - Val Loss: 35.7117 - Train Acc: 0.9102 - Val Acc: 0.8437\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 16/50 - Train Loss: 105.4883 - Val Loss: 21.4156 - Train Acc: 0.9274 - Val Acc: 0.8554\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 17/50 - Train Loss: 103.0306 - Val Loss: 19.4288 - Train Acc: 0.9261 - Val Acc: 0.8583\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 18/50 - Train Loss: 92.9934 - Val Loss: 43.9364 - Train Acc: 0.9338 - Val Acc: 0.8415\n",
      "Epoch 19/50 - Train Loss: 93.0085 - Val Loss: 20.4951 - Train Acc: 0.9341 - Val Acc: 0.8671\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 20/50 - Train Loss: 81.7527 - Val Loss: 23.0363 - Train Acc: 0.9407 - Val Acc: 0.8809\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 21/50 - Train Loss: 74.2074 - Val Loss: 18.1582 - Train Acc: 0.9465 - Val Acc: 0.8912\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 22/50 - Train Loss: 72.6743 - Val Loss: 29.4713 - Train Acc: 0.9497 - Val Acc: 0.8444\n",
      "Epoch 23/50 - Train Loss: 69.0388 - Val Loss: 22.1903 - Train Acc: 0.9517 - Val Acc: 0.8875\n",
      "Epoch 24/50 - Train Loss: 66.8848 - Val Loss: 23.5622 - Train Acc: 0.9548 - Val Acc: 0.8955\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 25/50 - Train Loss: 64.1415 - Val Loss: 20.4325 - Train Acc: 0.9562 - Val Acc: 0.8853\n",
      "Epoch 26/50 - Train Loss: 58.0835 - Val Loss: 17.8619 - Train Acc: 0.9595 - Val Acc: 0.9072\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 27/50 - Train Loss: 60.9464 - Val Loss: 16.8295 - Train Acc: 0.9620 - Val Acc: 0.9175\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 28/50 - Train Loss: 50.0302 - Val Loss: 19.5376 - Train Acc: 0.9646 - Val Acc: 0.8999\n",
      "Epoch 29/50 - Train Loss: 46.0702 - Val Loss: 23.6001 - Train Acc: 0.9668 - Val Acc: 0.8985\n",
      "Epoch 30/50 - Train Loss: 44.5319 - Val Loss: 29.7647 - Train Acc: 0.9702 - Val Acc: 0.8934\n",
      "Epoch 31/50 - Train Loss: 41.9545 - Val Loss: 25.1839 - Train Acc: 0.9704 - Val Acc: 0.8904\n",
      "Epoch 32/50 - Train Loss: 36.9148 - Val Loss: 22.6415 - Train Acc: 0.9749 - Val Acc: 0.9102\n",
      "Epoch 33/50 - Train Loss: 41.5022 - Val Loss: 19.8365 - Train Acc: 0.9741 - Val Acc: 0.9145\n",
      "Epoch 34/50 - Train Loss: 34.2910 - Val Loss: 25.1543 - Train Acc: 0.9768 - Val Acc: 0.8955\n",
      "Epoch 35/50 - Train Loss: 32.1805 - Val Loss: 26.3356 - Train Acc: 0.9792 - Val Acc: 0.8992\n",
      "Epoch 36/50 - Train Loss: 29.8108 - Val Loss: 20.0944 - Train Acc: 0.9799 - Val Acc: 0.9138\n",
      "Epoch 37/50 - Train Loss: 28.4099 - Val Loss: 18.2254 - Train Acc: 0.9799 - Val Acc: 0.9167\n",
      "Epoch 38/50 - Train Loss: 27.6309 - Val Loss: 25.3318 - Train Acc: 0.9819 - Val Acc: 0.9138\n",
      "Epoch 39/50 - Train Loss: 25.4240 - Val Loss: 22.2843 - Train Acc: 0.9822 - Val Acc: 0.9196\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 40/50 - Train Loss: 25.2699 - Val Loss: 20.3178 - Train Acc: 0.9814 - Val Acc: 0.9226\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 41/50 - Train Loss: 22.9992 - Val Loss: 26.9127 - Train Acc: 0.9845 - Val Acc: 0.9145\n",
      "Epoch 42/50 - Train Loss: 22.5180 - Val Loss: 24.1973 - Train Acc: 0.9855 - Val Acc: 0.9233\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 43/50 - Train Loss: 22.4953 - Val Loss: 21.6994 - Train Acc: 0.9853 - Val Acc: 0.9240\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "Epoch 44/50 - Train Loss: 22.5173 - Val Loss: 22.5689 - Train Acc: 0.9849 - Val Acc: 0.9240\n",
      "Epoch 45/50 - Train Loss: 20.9909 - Val Loss: 23.5027 - Train Acc: 0.9855 - Val Acc: 0.9226\n",
      "Epoch 46/50 - Train Loss: 19.5847 - Val Loss: 24.8111 - Train Acc: 0.9872 - Val Acc: 0.9196\n",
      "Epoch 47/50 - Train Loss: 19.7654 - Val Loss: 24.0221 - Train Acc: 0.9869 - Val Acc: 0.9204\n",
      "Epoch 48/50 - Train Loss: 20.6323 - Val Loss: 23.2286 - Train Acc: 0.9869 - Val Acc: 0.9211\n",
      "Epoch 49/50 - Train Loss: 20.1757 - Val Loss: 23.3271 - Train Acc: 0.9872 - Val Acc: 0.9211\n",
      "Epoch 50/50 - Train Loss: 20.2558 - Val Loss: 23.3271 - Train Acc: 0.9866 - Val Acc: 0.9211\n",
      "✅ Finished Td=45, Tw=15 — saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw15.pth\n",
      "\n",
      "🚀 Running for Td=45, Tw=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/2838713473.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4841, 2.4841, 2.4841, 2.4841, 2.4841, 2.4841, 2.4841, 2.4841, 2.4841,\n",
      "        2.4841, 2.4841, 2.4841], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 564.5990 - Val Loss: 59.7565 - Train Acc: 0.5752 - Val Acc: 0.5956\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 2/50 - Train Loss: 299.6766 - Val Loss: 36.4886 - Train Acc: 0.7734 - Val Acc: 0.6789\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 3/50 - Train Loss: 273.3092 - Val Loss: 40.5204 - Train Acc: 0.8062 - Val Acc: 0.7205\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 4/50 - Train Loss: 235.0799 - Val Loss: 34.5707 - Train Acc: 0.8347 - Val Acc: 0.7457\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 5/50 - Train Loss: 215.0316 - Val Loss: 27.2007 - Train Acc: 0.8460 - Val Acc: 0.7767\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 6/50 - Train Loss: 207.0406 - Val Loss: 31.7806 - Train Acc: 0.8494 - Val Acc: 0.7615\n",
      "Epoch 7/50 - Train Loss: 188.7195 - Val Loss: 30.0223 - Train Acc: 0.8677 - Val Acc: 0.7767\n",
      "Epoch 8/50 - Train Loss: 178.1047 - Val Loss: 40.1089 - Train Acc: 0.8778 - Val Acc: 0.7849\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 9/50 - Train Loss: 173.1641 - Val Loss: 26.3720 - Train Acc: 0.8817 - Val Acc: 0.8107\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 10/50 - Train Loss: 172.0657 - Val Loss: 28.8762 - Train Acc: 0.8819 - Val Acc: 0.7868\n",
      "Epoch 11/50 - Train Loss: 170.3446 - Val Loss: 30.9854 - Train Acc: 0.8896 - Val Acc: 0.8139\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 12/50 - Train Loss: 174.4330 - Val Loss: 23.6374 - Train Acc: 0.8910 - Val Acc: 0.8353\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 13/50 - Train Loss: 145.7412 - Val Loss: 23.5574 - Train Acc: 0.9004 - Val Acc: 0.8467\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 14/50 - Train Loss: 144.2122 - Val Loss: 22.9611 - Train Acc: 0.9013 - Val Acc: 0.8562\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 15/50 - Train Loss: 142.1016 - Val Loss: 23.9458 - Train Acc: 0.9072 - Val Acc: 0.8416\n",
      "Epoch 16/50 - Train Loss: 138.3177 - Val Loss: 26.2271 - Train Acc: 0.9155 - Val Acc: 0.8366\n",
      "Epoch 17/50 - Train Loss: 128.6690 - Val Loss: 24.9576 - Train Acc: 0.9134 - Val Acc: 0.8517\n",
      "Epoch 18/50 - Train Loss: 122.3813 - Val Loss: 24.1504 - Train Acc: 0.9173 - Val Acc: 0.8347\n",
      "Epoch 19/50 - Train Loss: 115.5202 - Val Loss: 27.6277 - Train Acc: 0.9231 - Val Acc: 0.8379\n",
      "Epoch 20/50 - Train Loss: 110.3822 - Val Loss: 31.5467 - Train Acc: 0.9274 - Val Acc: 0.8233\n",
      "Epoch 21/50 - Train Loss: 106.6156 - Val Loss: 25.9479 - Train Acc: 0.9289 - Val Acc: 0.8461\n",
      "Epoch 22/50 - Train Loss: 101.3973 - Val Loss: 23.0775 - Train Acc: 0.9332 - Val Acc: 0.8486\n",
      "Epoch 23/50 - Train Loss: 94.5125 - Val Loss: 34.6008 - Train Acc: 0.9379 - Val Acc: 0.8360\n",
      "Epoch 24/50 - Train Loss: 94.6633 - Val Loss: 29.8677 - Train Acc: 0.9399 - Val Acc: 0.8650\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 25/50 - Train Loss: 82.5456 - Val Loss: 31.3928 - Train Acc: 0.9462 - Val Acc: 0.8681\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 26/50 - Train Loss: 88.4345 - Val Loss: 32.0190 - Train Acc: 0.9468 - Val Acc: 0.8568\n",
      "Epoch 27/50 - Train Loss: 72.1061 - Val Loss: 25.7745 - Train Acc: 0.9530 - Val Acc: 0.8820\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 28/50 - Train Loss: 74.4099 - Val Loss: 25.3045 - Train Acc: 0.9547 - Val Acc: 0.8839\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 29/50 - Train Loss: 74.7707 - Val Loss: 23.0259 - Train Acc: 0.9565 - Val Acc: 0.8808\n",
      "Epoch 30/50 - Train Loss: 62.0264 - Val Loss: 28.0505 - Train Acc: 0.9602 - Val Acc: 0.8593\n",
      "Epoch 31/50 - Train Loss: 62.2185 - Val Loss: 22.7279 - Train Acc: 0.9625 - Val Acc: 0.8820\n",
      "Epoch 32/50 - Train Loss: 54.8977 - Val Loss: 22.8502 - Train Acc: 0.9677 - Val Acc: 0.8997\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 33/50 - Train Loss: 54.0972 - Val Loss: 26.2647 - Train Acc: 0.9672 - Val Acc: 0.8820\n",
      "Epoch 34/50 - Train Loss: 51.3791 - Val Loss: 26.3326 - Train Acc: 0.9707 - Val Acc: 0.8984\n",
      "Epoch 35/50 - Train Loss: 46.5467 - Val Loss: 17.7502 - Train Acc: 0.9722 - Val Acc: 0.9066\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 36/50 - Train Loss: 47.1487 - Val Loss: 21.0953 - Train Acc: 0.9723 - Val Acc: 0.9123\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "Epoch 37/50 - Train Loss: 41.6655 - Val Loss: 20.9657 - Train Acc: 0.9750 - Val Acc: 0.9110\n",
      "Epoch 38/50 - Train Loss: 40.9255 - Val Loss: 21.5635 - Train Acc: 0.9775 - Val Acc: 0.9047\n",
      "Epoch 39/50 - Train Loss: 36.6545 - Val Loss: 22.7615 - Train Acc: 0.9785 - Val Acc: 0.9091\n",
      "Epoch 40/50 - Train Loss: 36.0429 - Val Loss: 19.8419 - Train Acc: 0.9799 - Val Acc: 0.9123\n",
      "Epoch 41/50 - Train Loss: 34.8829 - Val Loss: 21.6307 - Train Acc: 0.9795 - Val Acc: 0.9091\n",
      "Epoch 42/50 - Train Loss: 34.4577 - Val Loss: 26.2504 - Train Acc: 0.9801 - Val Acc: 0.8984\n",
      "Epoch 43/50 - Train Loss: 32.6406 - Val Loss: 24.9725 - Train Acc: 0.9816 - Val Acc: 0.9016\n",
      "Epoch 44/50 - Train Loss: 31.9252 - Val Loss: 23.3572 - Train Acc: 0.9812 - Val Acc: 0.9104\n",
      "Epoch 45/50 - Train Loss: 29.3498 - Val Loss: 25.5772 - Train Acc: 0.9833 - Val Acc: 0.9009\n",
      "Epoch 46/50 - Train Loss: 30.1917 - Val Loss: 23.3881 - Train Acc: 0.9827 - Val Acc: 0.9110\n",
      "Epoch 47/50 - Train Loss: 30.5763 - Val Loss: 23.8351 - Train Acc: 0.9828 - Val Acc: 0.9073\n",
      "Epoch 48/50 - Train Loss: 28.6883 - Val Loss: 23.9348 - Train Acc: 0.9840 - Val Acc: 0.9066\n",
      "Epoch 49/50 - Train Loss: 28.7940 - Val Loss: 23.9600 - Train Acc: 0.9846 - Val Acc: 0.9060\n",
      "Epoch 50/50 - Train Loss: 29.9609 - Val Loss: 23.9600 - Train Acc: 0.9834 - Val Acc: 0.9060\n",
      "✅ Finished Td=45, Tw=20 — saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td45_Tw20.pth\n",
      "\n",
      "🚀 Running for Td=60, Tw=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/2838713473.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4832, 2.4832, 2.4832, 2.4832, 2.4832, 2.4832, 2.4832, 2.4832, 2.4832,\n",
      "        2.4832, 2.4832, 2.4832], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 290.1162 - Val Loss: 18.8893 - Train Acc: 0.5288 - Val Acc: 0.6463\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 2/50 - Train Loss: 137.9272 - Val Loss: 15.6481 - Train Acc: 0.7832 - Val Acc: 0.7191\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 3/50 - Train Loss: 114.8185 - Val Loss: 15.7561 - Train Acc: 0.8225 - Val Acc: 0.7278\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 4/50 - Train Loss: 94.4197 - Val Loss: 19.4926 - Train Acc: 0.8623 - Val Acc: 0.7045\n",
      "Epoch 5/50 - Train Loss: 80.9739 - Val Loss: 12.1555 - Train Acc: 0.8795 - Val Acc: 0.8268\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 6/50 - Train Loss: 82.2557 - Val Loss: 11.8085 - Train Acc: 0.8829 - Val Acc: 0.8166\n",
      "Epoch 7/50 - Train Loss: 65.9841 - Val Loss: 12.3626 - Train Acc: 0.9044 - Val Acc: 0.8079\n",
      "Epoch 8/50 - Train Loss: 65.1689 - Val Loss: 14.5862 - Train Acc: 0.9130 - Val Acc: 0.8137\n",
      "Epoch 9/50 - Train Loss: 64.8574 - Val Loss: 17.0634 - Train Acc: 0.9135 - Val Acc: 0.7846\n",
      "Epoch 10/50 - Train Loss: 55.3342 - Val Loss: 12.1747 - Train Acc: 0.9208 - Val Acc: 0.8617\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 11/50 - Train Loss: 59.4840 - Val Loss: 16.6489 - Train Acc: 0.9207 - Val Acc: 0.8180\n",
      "Epoch 12/50 - Train Loss: 52.3855 - Val Loss: 12.3770 - Train Acc: 0.9277 - Val Acc: 0.8370\n",
      "Epoch 13/50 - Train Loss: 46.2062 - Val Loss: 11.0121 - Train Acc: 0.9424 - Val Acc: 0.8748\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 14/50 - Train Loss: 53.1429 - Val Loss: 17.4197 - Train Acc: 0.9367 - Val Acc: 0.8253\n",
      "Epoch 15/50 - Train Loss: 35.9284 - Val Loss: 25.0397 - Train Acc: 0.9551 - Val Acc: 0.8166\n",
      "Epoch 16/50 - Train Loss: 39.7333 - Val Loss: 15.0048 - Train Acc: 0.9501 - Val Acc: 0.8850\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 17/50 - Train Loss: 41.1953 - Val Loss: 13.1281 - Train Acc: 0.9531 - Val Acc: 0.9010\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 18/50 - Train Loss: 40.6218 - Val Loss: 10.5241 - Train Acc: 0.9520 - Val Acc: 0.8850\n",
      "Epoch 19/50 - Train Loss: 25.6496 - Val Loss: 12.3774 - Train Acc: 0.9656 - Val Acc: 0.8806\n",
      "Epoch 20/50 - Train Loss: 32.9616 - Val Loss: 14.4223 - Train Acc: 0.9572 - Val Acc: 0.8661\n",
      "Epoch 21/50 - Train Loss: 25.6090 - Val Loss: 21.2364 - Train Acc: 0.9674 - Val Acc: 0.8836\n",
      "Epoch 22/50 - Train Loss: 25.8653 - Val Loss: 14.0747 - Train Acc: 0.9662 - Val Acc: 0.8646\n",
      "Epoch 23/50 - Train Loss: 23.9042 - Val Loss: 14.0011 - Train Acc: 0.9720 - Val Acc: 0.8894\n",
      "Epoch 24/50 - Train Loss: 22.1791 - Val Loss: 17.6969 - Train Acc: 0.9736 - Val Acc: 0.8705\n",
      "Epoch 25/50 - Train Loss: 30.8682 - Val Loss: 16.6968 - Train Acc: 0.9677 - Val Acc: 0.8792\n",
      "Epoch 26/50 - Train Loss: 18.8899 - Val Loss: 19.5470 - Train Acc: 0.9802 - Val Acc: 0.8792\n",
      "Epoch 27/50 - Train Loss: 18.7597 - Val Loss: 18.5645 - Train Acc: 0.9804 - Val Acc: 0.8937\n",
      "Epoch 28/50 - Train Loss: 15.8234 - Val Loss: 23.5907 - Train Acc: 0.9827 - Val Acc: 0.8574\n",
      "Epoch 29/50 - Train Loss: 12.5396 - Val Loss: 17.7478 - Train Acc: 0.9864 - Val Acc: 0.8894\n",
      "Epoch 30/50 - Train Loss: 15.6829 - Val Loss: 12.9126 - Train Acc: 0.9821 - Val Acc: 0.9098\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 31/50 - Train Loss: 12.3789 - Val Loss: 16.6057 - Train Acc: 0.9885 - Val Acc: 0.9112\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 32/50 - Train Loss: 11.7773 - Val Loss: 17.8315 - Train Acc: 0.9875 - Val Acc: 0.9098\n",
      "Epoch 33/50 - Train Loss: 8.6655 - Val Loss: 17.1624 - Train Acc: 0.9925 - Val Acc: 0.9127\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 34/50 - Train Loss: 8.5082 - Val Loss: 18.9216 - Train Acc: 0.9910 - Val Acc: 0.9127\n",
      "Epoch 35/50 - Train Loss: 7.7687 - Val Loss: 20.8743 - Train Acc: 0.9935 - Val Acc: 0.9229\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 36/50 - Train Loss: 7.7600 - Val Loss: 20.7762 - Train Acc: 0.9929 - Val Acc: 0.9170\n",
      "Epoch 37/50 - Train Loss: 6.8392 - Val Loss: 20.9907 - Train Acc: 0.9950 - Val Acc: 0.9214\n",
      "Epoch 38/50 - Train Loss: 6.8885 - Val Loss: 22.8903 - Train Acc: 0.9939 - Val Acc: 0.9199\n",
      "Epoch 39/50 - Train Loss: 6.5936 - Val Loss: 23.8312 - Train Acc: 0.9950 - Val Acc: 0.9214\n",
      "Epoch 40/50 - Train Loss: 5.9559 - Val Loss: 23.8074 - Train Acc: 0.9965 - Val Acc: 0.9185\n",
      "Epoch 41/50 - Train Loss: 5.4662 - Val Loss: 23.2232 - Train Acc: 0.9968 - Val Acc: 0.9185\n",
      "Epoch 42/50 - Train Loss: 5.0226 - Val Loss: 22.2569 - Train Acc: 0.9968 - Val Acc: 0.9199\n",
      "Epoch 43/50 - Train Loss: 5.0818 - Val Loss: 23.9207 - Train Acc: 0.9968 - Val Acc: 0.9229\n",
      "Epoch 44/50 - Train Loss: 4.8491 - Val Loss: 23.9312 - Train Acc: 0.9978 - Val Acc: 0.9185\n",
      "Epoch 45/50 - Train Loss: 4.9633 - Val Loss: 23.4882 - Train Acc: 0.9974 - Val Acc: 0.9243\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 46/50 - Train Loss: 4.7829 - Val Loss: 23.2520 - Train Acc: 0.9975 - Val Acc: 0.9199\n",
      "Epoch 47/50 - Train Loss: 4.8420 - Val Loss: 23.3623 - Train Acc: 0.9975 - Val Acc: 0.9229\n",
      "Epoch 48/50 - Train Loss: 4.7135 - Val Loss: 23.4594 - Train Acc: 0.9971 - Val Acc: 0.9258\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "Epoch 49/50 - Train Loss: 4.6112 - Val Loss: 23.4954 - Train Acc: 0.9979 - Val Acc: 0.9243\n",
      "Epoch 50/50 - Train Loss: 4.6539 - Val Loss: 23.4954 - Train Acc: 0.9972 - Val Acc: 0.9243\n",
      "✅ Finished Td=60, Tw=10 — saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw10.pth\n",
      "\n",
      "🚀 Running for Td=60, Tw=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/2838713473.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4834, 2.4834, 2.4834, 2.4834, 2.4834, 2.4834, 2.4834, 2.4834, 2.4834,\n",
      "        2.4834, 2.4834, 2.4834], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 308.9015 - Val Loss: 29.1030 - Train Acc: 0.5310 - Val Acc: 0.5354\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 2/50 - Train Loss: 162.2606 - Val Loss: 20.2483 - Train Acc: 0.7622 - Val Acc: 0.6810\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 3/50 - Train Loss: 124.5082 - Val Loss: 16.9608 - Train Acc: 0.8138 - Val Acc: 0.7177\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 4/50 - Train Loss: 101.3549 - Val Loss: 20.4571 - Train Acc: 0.8535 - Val Acc: 0.7013\n",
      "Epoch 5/50 - Train Loss: 104.5092 - Val Loss: 17.7434 - Train Acc: 0.8627 - Val Acc: 0.7544\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 6/50 - Train Loss: 91.8768 - Val Loss: 14.9750 - Train Acc: 0.8838 - Val Acc: 0.7722\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 7/50 - Train Loss: 77.1908 - Val Loss: 14.8644 - Train Acc: 0.8986 - Val Acc: 0.7772\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 8/50 - Train Loss: 80.8499 - Val Loss: 15.5422 - Train Acc: 0.9031 - Val Acc: 0.7810\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 9/50 - Train Loss: 71.3108 - Val Loss: 17.0709 - Train Acc: 0.9143 - Val Acc: 0.8051\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 10/50 - Train Loss: 66.9776 - Val Loss: 13.7445 - Train Acc: 0.9188 - Val Acc: 0.8506\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 11/50 - Train Loss: 59.4163 - Val Loss: 13.0816 - Train Acc: 0.9258 - Val Acc: 0.8304\n",
      "Epoch 12/50 - Train Loss: 58.1055 - Val Loss: 12.8110 - Train Acc: 0.9337 - Val Acc: 0.8241\n",
      "Epoch 13/50 - Train Loss: 52.4086 - Val Loss: 11.1605 - Train Acc: 0.9393 - Val Acc: 0.8468\n",
      "Epoch 14/50 - Train Loss: 49.3316 - Val Loss: 9.6025 - Train Acc: 0.9447 - Val Acc: 0.8810\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 15/50 - Train Loss: 41.8167 - Val Loss: 10.8383 - Train Acc: 0.9487 - Val Acc: 0.8772\n",
      "Epoch 16/50 - Train Loss: 46.3085 - Val Loss: 13.9187 - Train Acc: 0.9550 - Val Acc: 0.8443\n",
      "Epoch 17/50 - Train Loss: 51.7234 - Val Loss: 11.8208 - Train Acc: 0.9484 - Val Acc: 0.8696\n",
      "Epoch 18/50 - Train Loss: 49.0827 - Val Loss: 10.9603 - Train Acc: 0.9566 - Val Acc: 0.8696\n",
      "Epoch 19/50 - Train Loss: 35.1852 - Val Loss: 11.6429 - Train Acc: 0.9620 - Val Acc: 0.8835\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 20/50 - Train Loss: 39.5689 - Val Loss: 10.0383 - Train Acc: 0.9617 - Val Acc: 0.8975\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 21/50 - Train Loss: 30.9277 - Val Loss: 10.2174 - Train Acc: 0.9682 - Val Acc: 0.9013\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 22/50 - Train Loss: 27.8141 - Val Loss: 10.2732 - Train Acc: 0.9734 - Val Acc: 0.9038\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 23/50 - Train Loss: 26.7752 - Val Loss: 16.8254 - Train Acc: 0.9756 - Val Acc: 0.8696\n",
      "Epoch 24/50 - Train Loss: 23.1173 - Val Loss: 12.0605 - Train Acc: 0.9763 - Val Acc: 0.9114\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 25/50 - Train Loss: 18.5663 - Val Loss: 13.4244 - Train Acc: 0.9817 - Val Acc: 0.8785\n",
      "Epoch 26/50 - Train Loss: 17.2617 - Val Loss: 12.8539 - Train Acc: 0.9822 - Val Acc: 0.9000\n",
      "Epoch 27/50 - Train Loss: 17.4544 - Val Loss: 14.3556 - Train Acc: 0.9866 - Val Acc: 0.8873\n",
      "Epoch 28/50 - Train Loss: 16.7723 - Val Loss: 10.4312 - Train Acc: 0.9845 - Val Acc: 0.9025\n",
      "Epoch 29/50 - Train Loss: 14.3685 - Val Loss: 12.9701 - Train Acc: 0.9863 - Val Acc: 0.9025\n",
      "Epoch 30/50 - Train Loss: 12.6256 - Val Loss: 12.3795 - Train Acc: 0.9883 - Val Acc: 0.9177\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 31/50 - Train Loss: 11.8978 - Val Loss: 11.6285 - Train Acc: 0.9909 - Val Acc: 0.9253\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 32/50 - Train Loss: 10.2730 - Val Loss: 12.2977 - Train Acc: 0.9922 - Val Acc: 0.9203\n",
      "Epoch 33/50 - Train Loss: 11.1539 - Val Loss: 12.6678 - Train Acc: 0.9920 - Val Acc: 0.9203\n",
      "Epoch 34/50 - Train Loss: 9.7786 - Val Loss: 12.1242 - Train Acc: 0.9925 - Val Acc: 0.9190\n",
      "Epoch 35/50 - Train Loss: 8.0177 - Val Loss: 12.7836 - Train Acc: 0.9940 - Val Acc: 0.9152\n",
      "Epoch 36/50 - Train Loss: 6.6311 - Val Loss: 13.4550 - Train Acc: 0.9952 - Val Acc: 0.9278\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 37/50 - Train Loss: 6.9491 - Val Loss: 15.0078 - Train Acc: 0.9955 - Val Acc: 0.9203\n",
      "Epoch 38/50 - Train Loss: 8.2578 - Val Loss: 12.8880 - Train Acc: 0.9937 - Val Acc: 0.9253\n",
      "Epoch 39/50 - Train Loss: 5.7593 - Val Loss: 13.9759 - Train Acc: 0.9972 - Val Acc: 0.9304\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "Epoch 40/50 - Train Loss: 5.4769 - Val Loss: 15.8305 - Train Acc: 0.9969 - Val Acc: 0.9241\n",
      "Epoch 41/50 - Train Loss: 5.2720 - Val Loss: 14.5480 - Train Acc: 0.9967 - Val Acc: 0.9253\n",
      "Epoch 42/50 - Train Loss: 5.0101 - Val Loss: 15.0083 - Train Acc: 0.9972 - Val Acc: 0.9253\n",
      "Epoch 43/50 - Train Loss: 4.8804 - Val Loss: 16.0758 - Train Acc: 0.9976 - Val Acc: 0.9228\n",
      "Epoch 44/50 - Train Loss: 4.7765 - Val Loss: 15.3014 - Train Acc: 0.9976 - Val Acc: 0.9215\n",
      "Epoch 45/50 - Train Loss: 4.6043 - Val Loss: 16.1544 - Train Acc: 0.9976 - Val Acc: 0.9253\n",
      "Epoch 46/50 - Train Loss: 4.9918 - Val Loss: 16.0338 - Train Acc: 0.9975 - Val Acc: 0.9241\n",
      "Epoch 47/50 - Train Loss: 4.4082 - Val Loss: 16.2927 - Train Acc: 0.9979 - Val Acc: 0.9228\n",
      "Epoch 48/50 - Train Loss: 6.0661 - Val Loss: 16.2280 - Train Acc: 0.9979 - Val Acc: 0.9241\n",
      "Epoch 49/50 - Train Loss: 5.0378 - Val Loss: 16.1361 - Train Acc: 0.9969 - Val Acc: 0.9241\n",
      "Epoch 50/50 - Train Loss: 4.8167 - Val Loss: 16.1361 - Train Acc: 0.9976 - Val Acc: 0.9241\n",
      "✅ Finished Td=60, Tw=15 — saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw15.pth\n",
      "\n",
      "🚀 Running for Td=60, Tw=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/2838713473.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Class Weights Tensor:\n",
      "tensor([2.4835, 2.4835, 2.4835, 2.4835, 2.4835, 2.4835, 2.4835, 2.4835, 2.4835,\n",
      "        2.4835, 2.4835, 2.4835], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ea301b/anaconda3/envs/dl_satang/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 375.2404 - Val Loss: 38.2006 - Train Acc: 0.4834 - Val Acc: 0.5785\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 2/50 - Train Loss: 189.2355 - Val Loss: 21.9936 - Train Acc: 0.7519 - Val Acc: 0.6604\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 3/50 - Train Loss: 133.2652 - Val Loss: 18.9182 - Train Acc: 0.8371 - Val Acc: 0.7717\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 4/50 - Train Loss: 107.9509 - Val Loss: 17.8551 - Train Acc: 0.8649 - Val Acc: 0.7775\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 5/50 - Train Loss: 99.5399 - Val Loss: 17.3192 - Train Acc: 0.8799 - Val Acc: 0.7635\n",
      "Epoch 6/50 - Train Loss: 96.6750 - Val Loss: 15.6313 - Train Acc: 0.8797 - Val Acc: 0.8126\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 7/50 - Train Loss: 102.7517 - Val Loss: 14.3326 - Train Acc: 0.8897 - Val Acc: 0.8091\n",
      "Epoch 8/50 - Train Loss: 88.6910 - Val Loss: 16.0833 - Train Acc: 0.8940 - Val Acc: 0.8068\n",
      "Epoch 9/50 - Train Loss: 82.8163 - Val Loss: 15.3259 - Train Acc: 0.9065 - Val Acc: 0.8454\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 10/50 - Train Loss: 81.3801 - Val Loss: 16.7683 - Train Acc: 0.9066 - Val Acc: 0.8150\n",
      "Epoch 11/50 - Train Loss: 73.3740 - Val Loss: 18.1058 - Train Acc: 0.9144 - Val Acc: 0.8068\n",
      "Epoch 12/50 - Train Loss: 69.2998 - Val Loss: 20.4367 - Train Acc: 0.9189 - Val Acc: 0.8033\n",
      "Epoch 13/50 - Train Loss: 69.2996 - Val Loss: 20.0406 - Train Acc: 0.9254 - Val Acc: 0.8068\n",
      "Epoch 14/50 - Train Loss: 62.3367 - Val Loss: 13.2684 - Train Acc: 0.9286 - Val Acc: 0.8279\n",
      "Epoch 15/50 - Train Loss: 63.1898 - Val Loss: 13.1782 - Train Acc: 0.9317 - Val Acc: 0.8571\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 16/50 - Train Loss: 50.6175 - Val Loss: 12.1491 - Train Acc: 0.9430 - Val Acc: 0.8536\n",
      "Epoch 17/50 - Train Loss: 55.2888 - Val Loss: 13.9933 - Train Acc: 0.9429 - Val Acc: 0.8513\n",
      "Epoch 18/50 - Train Loss: 49.7758 - Val Loss: 16.4574 - Train Acc: 0.9454 - Val Acc: 0.8443\n",
      "Epoch 19/50 - Train Loss: 44.7680 - Val Loss: 16.7261 - Train Acc: 0.9498 - Val Acc: 0.8454\n",
      "Epoch 20/50 - Train Loss: 45.8845 - Val Loss: 16.0645 - Train Acc: 0.9541 - Val Acc: 0.8712\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 21/50 - Train Loss: 41.7848 - Val Loss: 14.0160 - Train Acc: 0.9580 - Val Acc: 0.8689\n",
      "Epoch 22/50 - Train Loss: 43.5161 - Val Loss: 16.8774 - Train Acc: 0.9575 - Val Acc: 0.8923\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 23/50 - Train Loss: 35.2633 - Val Loss: 11.4439 - Train Acc: 0.9646 - Val Acc: 0.8899\n",
      "Epoch 24/50 - Train Loss: 36.7521 - Val Loss: 11.7280 - Train Acc: 0.9628 - Val Acc: 0.8806\n",
      "Epoch 25/50 - Train Loss: 36.6799 - Val Loss: 11.8323 - Train Acc: 0.9646 - Val Acc: 0.8888\n",
      "Epoch 26/50 - Train Loss: 27.0733 - Val Loss: 13.7289 - Train Acc: 0.9729 - Val Acc: 0.8923\n",
      "Epoch 27/50 - Train Loss: 28.9101 - Val Loss: 20.8204 - Train Acc: 0.9735 - Val Acc: 0.8923\n",
      "Epoch 28/50 - Train Loss: 30.4298 - Val Loss: 13.2094 - Train Acc: 0.9763 - Val Acc: 0.9016\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 29/50 - Train Loss: 23.9833 - Val Loss: 16.2237 - Train Acc: 0.9761 - Val Acc: 0.8724\n",
      "Epoch 30/50 - Train Loss: 18.9599 - Val Loss: 14.3590 - Train Acc: 0.9835 - Val Acc: 0.9052\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 31/50 - Train Loss: 17.8070 - Val Loss: 16.9673 - Train Acc: 0.9828 - Val Acc: 0.9063\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 32/50 - Train Loss: 19.1975 - Val Loss: 16.7728 - Train Acc: 0.9818 - Val Acc: 0.9040\n",
      "Epoch 33/50 - Train Loss: 17.1414 - Val Loss: 14.6210 - Train Acc: 0.9858 - Val Acc: 0.9239\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 34/50 - Train Loss: 15.0408 - Val Loss: 17.4227 - Train Acc: 0.9866 - Val Acc: 0.9180\n",
      "Epoch 35/50 - Train Loss: 12.0674 - Val Loss: 14.1018 - Train Acc: 0.9894 - Val Acc: 0.9157\n",
      "Epoch 36/50 - Train Loss: 13.4772 - Val Loss: 18.2033 - Train Acc: 0.9885 - Val Acc: 0.9192\n",
      "Epoch 37/50 - Train Loss: 12.9180 - Val Loss: 18.1024 - Train Acc: 0.9898 - Val Acc: 0.9122\n",
      "Epoch 38/50 - Train Loss: 11.6764 - Val Loss: 16.1491 - Train Acc: 0.9903 - Val Acc: 0.9227\n",
      "Epoch 39/50 - Train Loss: 10.3686 - Val Loss: 15.5920 - Train Acc: 0.9921 - Val Acc: 0.9192\n",
      "Epoch 40/50 - Train Loss: 9.6440 - Val Loss: 17.5593 - Train Acc: 0.9929 - Val Acc: 0.9192\n",
      "Epoch 41/50 - Train Loss: 9.5429 - Val Loss: 17.4851 - Train Acc: 0.9932 - Val Acc: 0.9192\n",
      "Epoch 42/50 - Train Loss: 8.8358 - Val Loss: 17.2478 - Train Acc: 0.9942 - Val Acc: 0.9215\n",
      "Epoch 43/50 - Train Loss: 9.5397 - Val Loss: 19.0582 - Train Acc: 0.9941 - Val Acc: 0.9274\n",
      "💾 Best model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n",
      "Epoch 44/50 - Train Loss: 9.0328 - Val Loss: 18.6204 - Train Acc: 0.9942 - Val Acc: 0.9239\n",
      "Epoch 45/50 - Train Loss: 8.3975 - Val Loss: 19.2584 - Train Acc: 0.9937 - Val Acc: 0.9274\n",
      "Epoch 46/50 - Train Loss: 8.4168 - Val Loss: 18.5617 - Train Acc: 0.9944 - Val Acc: 0.9239\n",
      "Epoch 47/50 - Train Loss: 8.1437 - Val Loss: 18.4882 - Train Acc: 0.9945 - Val Acc: 0.9262\n",
      "Epoch 48/50 - Train Loss: 8.0235 - Val Loss: 18.5190 - Train Acc: 0.9943 - Val Acc: 0.9274\n",
      "Epoch 49/50 - Train Loss: 7.8667 - Val Loss: 18.5132 - Train Acc: 0.9950 - Val Acc: 0.9274\n",
      "Epoch 50/50 - Train Loss: 7.7396 - Val Loss: 18.5132 - Train Acc: 0.9953 - Val Acc: 0.9274\n",
      "✅ Finished Td=60, Tw=20 — saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher/ae_Td60_Tw20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/2838713473.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_lr_finder import LRFinder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# === 🧩 Config ===\n",
    "NUM_EPOCHS = 50\n",
    "LATENT_DIM = 64\n",
    "BEST_LR = 0.01\n",
    "base_dir = \"/home/HardDisk/Satang/thesis_proj\"\n",
    "save_root = \"/home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/teacher\"\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "detection_times = [30, 45, 60]\n",
    "window_sizes = [10, 15, 20]\n",
    "\n",
    "for T_d in detection_times:\n",
    "    for T_w in window_sizes:\n",
    "        print(f\"\\n🚀 Running for Td={T_d}, Tw={T_w}\")\n",
    "        model_name = os.path.join(save_root, f\"ae_Td{T_d}_Tw{T_w}.pth\")\n",
    "        T_len = T_d - T_w + 1\n",
    "        folder_name = f\"X_csv_split_{T_len}\"\n",
    "\n",
    "        input_dir = os.path.join(base_dir, f\"New_{T_d}\", f\"{T_w}\", \"split_tws\", folder_name)\n",
    "        train_path = os.path.join(input_dir, \"train\")\n",
    "        val_path   = os.path.join(input_dir, \"val\")\n",
    "\n",
    "        # === 1. Load Data ===\n",
    "        expected_shape = (T_len, NUM_FEATURES)\n",
    "        X_train_raw, y_train_raw = load_split_from_folder(train_path, expected_shape)\n",
    "        X_val_raw, y_val_raw     = load_split_from_folder(val_path, expected_shape)\n",
    "\n",
    "        # === 2. SMOTE + Encode ===\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_encoded = label_encoder.fit_transform(y_train_raw)\n",
    "        X_train_flat = X_train_raw.reshape(X_train_raw.shape[0], -1)\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X_train_flat, y_train_encoded)\n",
    "        X_train_bal = X_resampled.reshape(-1, expected_shape[0], NUM_FEATURES)\n",
    "        y_train_str = label_encoder.inverse_transform(y_resampled)\n",
    "\n",
    "        # === 3. Datasets + Loaders ===\n",
    "        train_dataset = MultiStreamDataset(X_train_bal, y_train_str, label_encoder, augment=True)\n",
    "        val_dataset   = MultiStreamDataset(X_val_raw, y_val_raw, label_encoder, augment=False)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # === 4. AE Model ===\n",
    "        model = AEWithClassifier(\n",
    "            input_length=expected_shape[0],\n",
    "            feature_dim=NUM_FEATURES,\n",
    "            latent_dim=LATENT_DIM,\n",
    "            num_classes=len(label_encoder.classes_)\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=BEST_LR, weight_decay=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "        class_weights_tensor = compute_class_weights(label_encoder.transform(y_train_str), device)\n",
    "\n",
    "        # === 5. Train AE ===\n",
    "        train_accs, val_accs, train_losses, val_losses = train_model(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            device=device,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            class_weights=class_weights_tensor,\n",
    "            lr=BEST_LR,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            best_model_path=model_name,\n",
    "            alpha=1.0,  # CrossEntropy\n",
    "            beta=1.0    # MSE Reconstruction\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Finished Td={T_d}, Tw={T_w} — saved to {model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1ce127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class StudentCNN(nn.Module):\n",
    "    def __init__(self, input_length, num_classes=12):\n",
    "        super().__init__()\n",
    "        self.streams = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(1, 4, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(4, 8, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool1d(1),\n",
    "                nn.Flatten()\n",
    "            ) for _ in range(8)\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8 * 8, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        self.proj = nn.Linear(8 * 8, 128)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        B, T, C = x.shape\n",
    "        assert C == 8, f\"Expected 8 feature streams, got {C}\"\n",
    "\n",
    "        # Split into 8 streams\n",
    "        streams = [x[:, :, i].unsqueeze(1) for i in range(C)]  # (B, 1, T)\n",
    "        features = [self.streams[i](streams[i]) for i in range(8)]  # list of (B, 8)\n",
    "\n",
    "        x = torch.cat(features, dim=1)  # (B, 64)\n",
    "\n",
    "        if return_features:\n",
    "            feat_proj = self.proj(x)  # (B, 128)\n",
    "            return self.fc(x), None, feat_proj  # dummy recon for consistency\n",
    "\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6dad2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def distillation_loss(student_logits, teacher_logits, student_feat, teacher_feat, true_labels, T=3.0, alpha=0.5, beta=0.3, gamma=0.2):\n",
    "    \"\"\"\n",
    "    alpha: weight for hard loss (CE)\n",
    "    beta: weight for soft loss (KL)\n",
    "    gamma: weight for feature-based distillation (MSE)\n",
    "    T: temperature for soft distillation\n",
    "    \"\"\"\n",
    "    # Hard loss\n",
    "    ce_loss = F.cross_entropy(student_logits, true_labels)\n",
    "\n",
    "    # Soft loss (logits)\n",
    "    soft_teacher = F.softmax(teacher_logits / T, dim=1)\n",
    "    soft_student = F.log_softmax(student_logits / T, dim=1)\n",
    "    kl_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (T * T)\n",
    "\n",
    "    # Feature loss (projection-matched MSE)\n",
    "    feat_loss = F.mse_loss(student_feat, teacher_feat)\n",
    "\n",
    "    return alpha * ce_loss + beta * kl_loss + gamma * feat_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "295b7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_distilled(student, teacher, train_loader, val_loader, device,\n",
    "                    epochs=50, lr=0.0005, class_weights=None,\n",
    "                    T=3.0, alpha=0.5, beta=0.3, gamma=0.2,\n",
    "                    save_path=\"best_student.pth\"):\n",
    "\n",
    "    teacher.eval()\n",
    "    student.to(device)\n",
    "    teacher.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(student.parameters(), lr=lr)\n",
    "    ce_criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    train_losses, train_accuracies, val_losses, val_accuracies = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss, correct = 0.0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # === Forward passes\n",
    "            student_logits, _, student_feat = student(inputs, return_features=True)\n",
    "            with torch.no_grad():\n",
    "                teacher_logits, _, teacher_feat = teacher(inputs, return_features=True)\n",
    "\n",
    "            # === Distillation loss\n",
    "            loss = distillation_loss(\n",
    "                student_logits, teacher_logits,\n",
    "                student_feat, teacher_feat,\n",
    "                labels,\n",
    "                T=T, alpha=alpha, beta=beta, gamma=gamma\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (student_logits.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(total_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # === Validation ===\n",
    "        student.eval()\n",
    "        val_loss, val_correct = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                logits = student(inputs)  # ✅ works as intended\n",
    "                loss = ce_criterion(logits, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (logits.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"[Distill] Epoch {epoch+1:02d}/{epochs} - \"\n",
    "              f\"Loss: {total_loss:.4f} - Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(student.state_dict(), save_path)\n",
    "            print(f\"💾 Best student model saved to: {save_path}\")\n",
    "\n",
    "    student.load_state_dict(torch.load(save_path))\n",
    "    return train_accuracies, val_accuracies, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc2948db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Distilling AE→StudentCNN for Td=30, Tw=10 (T_len=21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/657140011.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 2650.9437 - Train Acc: 0.2726 - Val Acc: 0.4760\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1880.5299 - Train Acc: 0.5487 - Val Acc: 0.5286\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 03/50 - Loss: 1576.0470 - Train Acc: 0.6191 - Val Acc: 0.5451\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 04/50 - Loss: 1403.5020 - Train Acc: 0.6565 - Val Acc: 0.5516\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 05/50 - Loss: 1293.6901 - Train Acc: 0.6787 - Val Acc: 0.6202\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 06/50 - Loss: 1214.7005 - Train Acc: 0.6899 - Val Acc: 0.6057\n",
      "[Distill] Epoch 07/50 - Loss: 1149.5362 - Train Acc: 0.7048 - Val Acc: 0.5967\n",
      "[Distill] Epoch 08/50 - Loss: 1096.1976 - Train Acc: 0.7211 - Val Acc: 0.6308\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 09/50 - Loss: 1047.0234 - Train Acc: 0.7299 - Val Acc: 0.6353\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 10/50 - Loss: 1004.9446 - Train Acc: 0.7395 - Val Acc: 0.6568\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 11/50 - Loss: 966.6630 - Train Acc: 0.7468 - Val Acc: 0.6568\n",
      "[Distill] Epoch 12/50 - Loss: 928.0233 - Train Acc: 0.7592 - Val Acc: 0.6869\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 13/50 - Loss: 892.9640 - Train Acc: 0.7675 - Val Acc: 0.7074\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 14/50 - Loss: 857.1614 - Train Acc: 0.7799 - Val Acc: 0.6864\n",
      "[Distill] Epoch 15/50 - Loss: 822.7866 - Train Acc: 0.7905 - Val Acc: 0.6944\n",
      "[Distill] Epoch 16/50 - Loss: 794.0467 - Train Acc: 0.7950 - Val Acc: 0.7114\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 17/50 - Loss: 764.5130 - Train Acc: 0.8044 - Val Acc: 0.7320\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 18/50 - Loss: 739.9082 - Train Acc: 0.8110 - Val Acc: 0.7460\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 19/50 - Loss: 718.9834 - Train Acc: 0.8137 - Val Acc: 0.7575\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 20/50 - Loss: 697.6964 - Train Acc: 0.8201 - Val Acc: 0.7781\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 21/50 - Loss: 682.6362 - Train Acc: 0.8228 - Val Acc: 0.7966\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 22/50 - Loss: 667.4080 - Train Acc: 0.8295 - Val Acc: 0.7730\n",
      "[Distill] Epoch 23/50 - Loss: 652.8409 - Train Acc: 0.8299 - Val Acc: 0.7730\n",
      "[Distill] Epoch 24/50 - Loss: 642.3521 - Train Acc: 0.8314 - Val Acc: 0.7926\n",
      "[Distill] Epoch 25/50 - Loss: 629.8089 - Train Acc: 0.8366 - Val Acc: 0.7811\n",
      "[Distill] Epoch 26/50 - Loss: 616.1425 - Train Acc: 0.8400 - Val Acc: 0.7956\n",
      "[Distill] Epoch 27/50 - Loss: 609.0605 - Train Acc: 0.8410 - Val Acc: 0.8066\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 28/50 - Loss: 603.2835 - Train Acc: 0.8409 - Val Acc: 0.7921\n",
      "[Distill] Epoch 29/50 - Loss: 596.0154 - Train Acc: 0.8412 - Val Acc: 0.7961\n",
      "[Distill] Epoch 30/50 - Loss: 585.3412 - Train Acc: 0.8466 - Val Acc: 0.7916\n",
      "[Distill] Epoch 31/50 - Loss: 578.3114 - Train Acc: 0.8484 - Val Acc: 0.8076\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 32/50 - Loss: 571.5661 - Train Acc: 0.8486 - Val Acc: 0.8231\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 33/50 - Loss: 562.1256 - Train Acc: 0.8509 - Val Acc: 0.8096\n",
      "[Distill] Epoch 34/50 - Loss: 559.4398 - Train Acc: 0.8513 - Val Acc: 0.8231\n",
      "[Distill] Epoch 35/50 - Loss: 551.4830 - Train Acc: 0.8519 - Val Acc: 0.8357\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 36/50 - Loss: 545.7865 - Train Acc: 0.8542 - Val Acc: 0.8327\n",
      "[Distill] Epoch 37/50 - Loss: 539.3355 - Train Acc: 0.8576 - Val Acc: 0.8362\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 38/50 - Loss: 538.1651 - Train Acc: 0.8560 - Val Acc: 0.8086\n",
      "[Distill] Epoch 39/50 - Loss: 530.1038 - Train Acc: 0.8577 - Val Acc: 0.8292\n",
      "[Distill] Epoch 40/50 - Loss: 524.7653 - Train Acc: 0.8601 - Val Acc: 0.8387\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 41/50 - Loss: 520.4419 - Train Acc: 0.8612 - Val Acc: 0.8216\n",
      "[Distill] Epoch 42/50 - Loss: 516.1427 - Train Acc: 0.8605 - Val Acc: 0.8327\n",
      "[Distill] Epoch 43/50 - Loss: 513.4064 - Train Acc: 0.8612 - Val Acc: 0.8347\n",
      "[Distill] Epoch 44/50 - Loss: 506.2065 - Train Acc: 0.8639 - Val Acc: 0.8252\n",
      "[Distill] Epoch 45/50 - Loss: 506.6646 - Train Acc: 0.8613 - Val Acc: 0.8181\n",
      "[Distill] Epoch 46/50 - Loss: 497.6495 - Train Acc: 0.8670 - Val Acc: 0.8417\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 47/50 - Loss: 497.1927 - Train Acc: 0.8651 - Val Acc: 0.8557\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "[Distill] Epoch 48/50 - Loss: 491.6470 - Train Acc: 0.8658 - Val Acc: 0.8472\n",
      "[Distill] Epoch 49/50 - Loss: 487.1846 - Train Acc: 0.8694 - Val Acc: 0.8497\n",
      "[Distill] Epoch 50/50 - Loss: 483.2980 - Train Acc: 0.8678 - Val Acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/342412524.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Classification Report (StudentCNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       0.99      1.00      0.99        85\n",
      "      Cerber       0.81      0.77      0.79       189\n",
      "    Darkside       0.82      0.81      0.82       323\n",
      "       Excel       1.00      1.00      1.00       147\n",
      "     Firefox       1.00      1.00      1.00       204\n",
      "   GandCrab4       0.68      0.76      0.71       319\n",
      "        Ryuk       0.80      0.77      0.79       196\n",
      "     SDelete       1.00      1.00      1.00        79\n",
      "  Sodinokibi       0.86      0.71      0.78       205\n",
      "  TeslaCrypt       0.83      1.00      0.90        85\n",
      "    WannaCry       1.00      1.00      1.00        79\n",
      "         Zip       1.00      0.99      0.99        85\n",
      "\n",
      "    accuracy                           0.86      1996\n",
      "   macro avg       0.90      0.90      0.90      1996\n",
      "weighted avg       0.86      0.86      0.86      1996\n",
      "\n",
      "✅ Student model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw10.pth\n",
      "\n",
      "🚀 Distilling AE→StudentCNN for Td=30, Tw=15 (T_len=16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/657140011.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 5987.7168 - Train Acc: 0.3071 - Val Acc: 0.4560\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 02/50 - Loss: 4913.7890 - Train Acc: 0.5935 - Val Acc: 0.5247\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 03/50 - Loss: 4483.7815 - Train Acc: 0.6624 - Val Acc: 0.5763\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 04/50 - Loss: 4196.3581 - Train Acc: 0.7086 - Val Acc: 0.6173\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 05/50 - Loss: 3997.1705 - Train Acc: 0.7348 - Val Acc: 0.6386\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 06/50 - Loss: 3851.3862 - Train Acc: 0.7548 - Val Acc: 0.6484\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 07/50 - Loss: 3736.3572 - Train Acc: 0.7722 - Val Acc: 0.6739\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 08/50 - Loss: 3627.6364 - Train Acc: 0.7855 - Val Acc: 0.6822\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 09/50 - Loss: 3537.3314 - Train Acc: 0.7934 - Val Acc: 0.6853\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 10/50 - Loss: 3457.3558 - Train Acc: 0.8041 - Val Acc: 0.7103\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 11/50 - Loss: 3374.3184 - Train Acc: 0.8108 - Val Acc: 0.7107\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 12/50 - Loss: 3297.5512 - Train Acc: 0.8205 - Val Acc: 0.7331\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 13/50 - Loss: 3225.9436 - Train Acc: 0.8259 - Val Acc: 0.7342\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 14/50 - Loss: 3146.4544 - Train Acc: 0.8304 - Val Acc: 0.7384\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 15/50 - Loss: 3069.5328 - Train Acc: 0.8352 - Val Acc: 0.7536\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 16/50 - Loss: 2985.0476 - Train Acc: 0.8398 - Val Acc: 0.7547\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 17/50 - Loss: 2902.5726 - Train Acc: 0.8409 - Val Acc: 0.7612\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 18/50 - Loss: 2813.0907 - Train Acc: 0.8416 - Val Acc: 0.7661\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 19/50 - Loss: 2718.6041 - Train Acc: 0.8484 - Val Acc: 0.7593\n",
      "[Distill] Epoch 20/50 - Loss: 2637.6005 - Train Acc: 0.8478 - Val Acc: 0.7631\n",
      "[Distill] Epoch 21/50 - Loss: 2547.2910 - Train Acc: 0.8523 - Val Acc: 0.7715\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 22/50 - Loss: 2469.1712 - Train Acc: 0.8528 - Val Acc: 0.7787\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 23/50 - Loss: 2397.4196 - Train Acc: 0.8548 - Val Acc: 0.7749\n",
      "[Distill] Epoch 24/50 - Loss: 2323.9472 - Train Acc: 0.8569 - Val Acc: 0.7684\n",
      "[Distill] Epoch 25/50 - Loss: 2257.2415 - Train Acc: 0.8592 - Val Acc: 0.7855\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 26/50 - Loss: 2202.3307 - Train Acc: 0.8632 - Val Acc: 0.7931\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 27/50 - Loss: 2149.5893 - Train Acc: 0.8644 - Val Acc: 0.7851\n",
      "[Distill] Epoch 28/50 - Loss: 2108.3801 - Train Acc: 0.8654 - Val Acc: 0.8003\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 29/50 - Loss: 2070.0223 - Train Acc: 0.8679 - Val Acc: 0.7988\n",
      "[Distill] Epoch 30/50 - Loss: 2029.6671 - Train Acc: 0.8682 - Val Acc: 0.7935\n",
      "[Distill] Epoch 31/50 - Loss: 2000.1506 - Train Acc: 0.8707 - Val Acc: 0.7931\n",
      "[Distill] Epoch 32/50 - Loss: 1977.5913 - Train Acc: 0.8726 - Val Acc: 0.8159\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 33/50 - Loss: 1949.1300 - Train Acc: 0.8763 - Val Acc: 0.8060\n",
      "[Distill] Epoch 34/50 - Loss: 1925.7078 - Train Acc: 0.8769 - Val Acc: 0.8170\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 35/50 - Loss: 1901.9436 - Train Acc: 0.8794 - Val Acc: 0.8132\n",
      "[Distill] Epoch 36/50 - Loss: 1889.9498 - Train Acc: 0.8803 - Val Acc: 0.8235\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 37/50 - Loss: 1871.0991 - Train Acc: 0.8822 - Val Acc: 0.8292\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 38/50 - Loss: 1851.2525 - Train Acc: 0.8823 - Val Acc: 0.8292\n",
      "[Distill] Epoch 39/50 - Loss: 1833.5624 - Train Acc: 0.8866 - Val Acc: 0.8219\n",
      "[Distill] Epoch 40/50 - Loss: 1822.7556 - Train Acc: 0.8848 - Val Acc: 0.8235\n",
      "[Distill] Epoch 41/50 - Loss: 1807.8453 - Train Acc: 0.8851 - Val Acc: 0.8356\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 42/50 - Loss: 1795.7379 - Train Acc: 0.8877 - Val Acc: 0.8318\n",
      "[Distill] Epoch 43/50 - Loss: 1780.3523 - Train Acc: 0.8888 - Val Acc: 0.8322\n",
      "[Distill] Epoch 44/50 - Loss: 1771.9609 - Train Acc: 0.8867 - Val Acc: 0.8200\n",
      "[Distill] Epoch 45/50 - Loss: 1761.1681 - Train Acc: 0.8895 - Val Acc: 0.8288\n",
      "[Distill] Epoch 46/50 - Loss: 1750.1437 - Train Acc: 0.8913 - Val Acc: 0.8360\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 47/50 - Loss: 1735.1682 - Train Acc: 0.8932 - Val Acc: 0.8341\n",
      "[Distill] Epoch 48/50 - Loss: 1732.3498 - Train Acc: 0.8898 - Val Acc: 0.8478\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "[Distill] Epoch 49/50 - Loss: 1722.1764 - Train Acc: 0.8937 - Val Acc: 0.8303\n",
      "[Distill] Epoch 50/50 - Loss: 1711.3028 - Train Acc: 0.8941 - Val Acc: 0.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/342412524.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Classification Report (StudentCNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       0.96      0.96      0.96       112\n",
      "      Cerber       0.86      0.75      0.80       249\n",
      "    Darkside       0.95      0.82      0.88       427\n",
      "       Excel       1.00      0.98      0.99       194\n",
      "     Firefox       0.98      0.92      0.95       271\n",
      "   GandCrab4       0.66      0.77      0.71       420\n",
      "        Ryuk       0.73      0.71      0.72       258\n",
      "     SDelete       1.00      1.00      1.00       103\n",
      "  Sodinokibi       0.79      0.84      0.81       271\n",
      "  TeslaCrypt       0.68      0.91      0.78       114\n",
      "    WannaCry       1.00      1.00      1.00       103\n",
      "         Zip       1.00      0.96      0.98       112\n",
      "\n",
      "    accuracy                           0.85      2634\n",
      "   macro avg       0.88      0.88      0.88      2634\n",
      "weighted avg       0.86      0.85      0.85      2634\n",
      "\n",
      "✅ Student model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw15.pth\n",
      "\n",
      "🚀 Distilling AE→StudentCNN for Td=30, Tw=20 (T_len=11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/657140011.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 7983.1574 - Train Acc: 0.5351 - Val Acc: 0.5843\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 02/50 - Loss: 5845.1908 - Train Acc: 0.7202 - Val Acc: 0.6405\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 03/50 - Loss: 5168.0871 - Train Acc: 0.7621 - Val Acc: 0.6717\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 04/50 - Loss: 4800.0543 - Train Acc: 0.7841 - Val Acc: 0.7151\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 05/50 - Loss: 4518.6366 - Train Acc: 0.8005 - Val Acc: 0.7143\n",
      "[Distill] Epoch 06/50 - Loss: 4273.9018 - Train Acc: 0.8149 - Val Acc: 0.7411\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 07/50 - Loss: 4051.5593 - Train Acc: 0.8251 - Val Acc: 0.7409\n",
      "[Distill] Epoch 08/50 - Loss: 3827.6688 - Train Acc: 0.8347 - Val Acc: 0.7681\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 09/50 - Loss: 3598.5601 - Train Acc: 0.8422 - Val Acc: 0.7746\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 10/50 - Loss: 3388.2615 - Train Acc: 0.8490 - Val Acc: 0.7937\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 11/50 - Loss: 3199.9115 - Train Acc: 0.8539 - Val Acc: 0.8038\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 12/50 - Loss: 3037.0159 - Train Acc: 0.8581 - Val Acc: 0.8082\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 13/50 - Loss: 2911.0549 - Train Acc: 0.8624 - Val Acc: 0.8065\n",
      "[Distill] Epoch 14/50 - Loss: 2809.7748 - Train Acc: 0.8663 - Val Acc: 0.8134\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 15/50 - Loss: 2729.1072 - Train Acc: 0.8725 - Val Acc: 0.8205\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 16/50 - Loss: 2664.4127 - Train Acc: 0.8737 - Val Acc: 0.8187\n",
      "[Distill] Epoch 17/50 - Loss: 2612.3355 - Train Acc: 0.8776 - Val Acc: 0.8239\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 18/50 - Loss: 2564.2665 - Train Acc: 0.8782 - Val Acc: 0.8262\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 19/50 - Loss: 2524.0372 - Train Acc: 0.8816 - Val Acc: 0.8402\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 20/50 - Loss: 2492.4752 - Train Acc: 0.8843 - Val Acc: 0.8354\n",
      "[Distill] Epoch 21/50 - Loss: 2454.6933 - Train Acc: 0.8876 - Val Acc: 0.8446\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 22/50 - Loss: 2427.9387 - Train Acc: 0.8882 - Val Acc: 0.8495\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 23/50 - Loss: 2405.2189 - Train Acc: 0.8892 - Val Acc: 0.8518\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 24/50 - Loss: 2378.7865 - Train Acc: 0.8924 - Val Acc: 0.8455\n",
      "[Distill] Epoch 25/50 - Loss: 2354.0107 - Train Acc: 0.8932 - Val Acc: 0.8554\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 26/50 - Loss: 2333.4029 - Train Acc: 0.8944 - Val Acc: 0.8554\n",
      "[Distill] Epoch 27/50 - Loss: 2313.2009 - Train Acc: 0.8954 - Val Acc: 0.8449\n",
      "[Distill] Epoch 28/50 - Loss: 2292.2417 - Train Acc: 0.8974 - Val Acc: 0.8579\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 29/50 - Loss: 2276.6083 - Train Acc: 0.8977 - Val Acc: 0.8417\n",
      "[Distill] Epoch 30/50 - Loss: 2251.4718 - Train Acc: 0.8994 - Val Acc: 0.8530\n",
      "[Distill] Epoch 31/50 - Loss: 2236.2404 - Train Acc: 0.9007 - Val Acc: 0.8465\n",
      "[Distill] Epoch 32/50 - Loss: 2224.5413 - Train Acc: 0.9010 - Val Acc: 0.8463\n",
      "[Distill] Epoch 33/50 - Loss: 2208.8099 - Train Acc: 0.9018 - Val Acc: 0.8656\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 34/50 - Loss: 2195.5568 - Train Acc: 0.9039 - Val Acc: 0.8723\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 35/50 - Loss: 2177.5722 - Train Acc: 0.9046 - Val Acc: 0.8512\n",
      "[Distill] Epoch 36/50 - Loss: 2169.0074 - Train Acc: 0.9048 - Val Acc: 0.8566\n",
      "[Distill] Epoch 37/50 - Loss: 2155.8536 - Train Acc: 0.9049 - Val Acc: 0.8556\n",
      "[Distill] Epoch 38/50 - Loss: 2140.8494 - Train Acc: 0.9057 - Val Acc: 0.8646\n",
      "[Distill] Epoch 39/50 - Loss: 2129.7064 - Train Acc: 0.9053 - Val Acc: 0.8654\n",
      "[Distill] Epoch 40/50 - Loss: 2121.3218 - Train Acc: 0.9070 - Val Acc: 0.8660\n",
      "[Distill] Epoch 41/50 - Loss: 2109.1410 - Train Acc: 0.9076 - Val Acc: 0.8711\n",
      "[Distill] Epoch 42/50 - Loss: 2091.1559 - Train Acc: 0.9082 - Val Acc: 0.8570\n",
      "[Distill] Epoch 43/50 - Loss: 2082.5481 - Train Acc: 0.9090 - Val Acc: 0.8635\n",
      "[Distill] Epoch 44/50 - Loss: 2075.5757 - Train Acc: 0.9103 - Val Acc: 0.8620\n",
      "[Distill] Epoch 45/50 - Loss: 2060.4723 - Train Acc: 0.9109 - Val Acc: 0.8765\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "[Distill] Epoch 46/50 - Loss: 2049.0685 - Train Acc: 0.9137 - Val Acc: 0.8751\n",
      "[Distill] Epoch 47/50 - Loss: 2040.9932 - Train Acc: 0.9126 - Val Acc: 0.8660\n",
      "[Distill] Epoch 48/50 - Loss: 2027.9340 - Train Acc: 0.9136 - Val Acc: 0.8662\n",
      "[Distill] Epoch 49/50 - Loss: 2024.3831 - Train Acc: 0.9128 - Val Acc: 0.8644\n",
      "[Distill] Epoch 50/50 - Loss: 2016.1760 - Train Acc: 0.9142 - Val Acc: 0.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/342412524.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Classification Report (StudentCNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       0.94      0.88      0.91       221\n",
      "      Cerber       0.97      0.82      0.89       496\n",
      "    Darkside       0.99      0.84      0.91       850\n",
      "       Excel       0.99      1.00      1.00       386\n",
      "     Firefox       0.98      0.95      0.97       539\n",
      "   GandCrab4       0.72      0.81      0.77       836\n",
      "        Ryuk       0.71      0.77      0.74       514\n",
      "     SDelete       0.92      0.99      0.95       204\n",
      "  Sodinokibi       0.84      0.86      0.85       537\n",
      "  TeslaCrypt       0.77      0.99      0.86       224\n",
      "    WannaCry       1.00      1.00      1.00       203\n",
      "         Zip       0.96      0.94      0.95       220\n",
      "\n",
      "    accuracy                           0.88      5230\n",
      "   macro avg       0.90      0.90      0.90      5230\n",
      "weighted avg       0.89      0.88      0.88      5230\n",
      "\n",
      "✅ Student model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td30_Tw20.pth\n",
      "\n",
      "🚀 Distilling AE→StudentCNN for Td=45, Tw=10 (T_len=36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/657140011.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 2672.9910 - Train Acc: 0.1319 - Val Acc: 0.1851\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 02/50 - Loss: 2398.7774 - Train Acc: 0.3973 - Val Acc: 0.4874\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 03/50 - Loss: 2050.8326 - Train Acc: 0.6269 - Val Acc: 0.5562\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 04/50 - Loss: 1904.8695 - Train Acc: 0.6717 - Val Acc: 0.5746\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 05/50 - Loss: 1803.4294 - Train Acc: 0.6963 - Val Acc: 0.5940\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 06/50 - Loss: 1731.3384 - Train Acc: 0.7097 - Val Acc: 0.5988\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 07/50 - Loss: 1675.0197 - Train Acc: 0.7207 - Val Acc: 0.6124\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 08/50 - Loss: 1626.2879 - Train Acc: 0.7351 - Val Acc: 0.6289\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 09/50 - Loss: 1585.6745 - Train Acc: 0.7445 - Val Acc: 0.6347\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 10/50 - Loss: 1551.4915 - Train Acc: 0.7530 - Val Acc: 0.6676\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 11/50 - Loss: 1526.0099 - Train Acc: 0.7629 - Val Acc: 0.6444\n",
      "[Distill] Epoch 12/50 - Loss: 1493.0163 - Train Acc: 0.7714 - Val Acc: 0.6734\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 13/50 - Loss: 1465.3789 - Train Acc: 0.7800 - Val Acc: 0.6744\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 14/50 - Loss: 1437.6685 - Train Acc: 0.7844 - Val Acc: 0.6880\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 15/50 - Loss: 1415.2814 - Train Acc: 0.7967 - Val Acc: 0.7045\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 16/50 - Loss: 1385.1777 - Train Acc: 0.8033 - Val Acc: 0.7171\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 17/50 - Loss: 1364.8421 - Train Acc: 0.8114 - Val Acc: 0.7316\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 18/50 - Loss: 1335.8963 - Train Acc: 0.8228 - Val Acc: 0.7326\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 19/50 - Loss: 1308.2375 - Train Acc: 0.8281 - Val Acc: 0.7403\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 20/50 - Loss: 1284.0511 - Train Acc: 0.8340 - Val Acc: 0.7413\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 21/50 - Loss: 1260.1397 - Train Acc: 0.8389 - Val Acc: 0.7432\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 22/50 - Loss: 1232.5880 - Train Acc: 0.8474 - Val Acc: 0.7529\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 23/50 - Loss: 1197.9793 - Train Acc: 0.8521 - Val Acc: 0.7645\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 24/50 - Loss: 1176.4652 - Train Acc: 0.8546 - Val Acc: 0.7800\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 25/50 - Loss: 1149.9087 - Train Acc: 0.8549 - Val Acc: 0.7868\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 26/50 - Loss: 1121.4074 - Train Acc: 0.8672 - Val Acc: 0.7733\n",
      "[Distill] Epoch 27/50 - Loss: 1095.3466 - Train Acc: 0.8696 - Val Acc: 0.7946\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 28/50 - Loss: 1071.4786 - Train Acc: 0.8751 - Val Acc: 0.8062\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 29/50 - Loss: 1048.3320 - Train Acc: 0.8734 - Val Acc: 0.7849\n",
      "[Distill] Epoch 30/50 - Loss: 1028.9665 - Train Acc: 0.8751 - Val Acc: 0.8110\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 31/50 - Loss: 1010.7761 - Train Acc: 0.8776 - Val Acc: 0.8033\n",
      "[Distill] Epoch 32/50 - Loss: 990.3218 - Train Acc: 0.8814 - Val Acc: 0.8052\n",
      "[Distill] Epoch 33/50 - Loss: 973.3018 - Train Acc: 0.8890 - Val Acc: 0.8072\n",
      "[Distill] Epoch 34/50 - Loss: 955.2422 - Train Acc: 0.8907 - Val Acc: 0.8343\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 35/50 - Loss: 944.2385 - Train Acc: 0.8881 - Val Acc: 0.8120\n",
      "[Distill] Epoch 36/50 - Loss: 930.1231 - Train Acc: 0.8894 - Val Acc: 0.8217\n",
      "[Distill] Epoch 37/50 - Loss: 916.8993 - Train Acc: 0.8941 - Val Acc: 0.8314\n",
      "[Distill] Epoch 38/50 - Loss: 908.2337 - Train Acc: 0.8949 - Val Acc: 0.8333\n",
      "[Distill] Epoch 39/50 - Loss: 894.4675 - Train Acc: 0.8975 - Val Acc: 0.8275\n",
      "[Distill] Epoch 40/50 - Loss: 882.3598 - Train Acc: 0.8976 - Val Acc: 0.8304\n",
      "[Distill] Epoch 41/50 - Loss: 873.4696 - Train Acc: 0.9009 - Val Acc: 0.8430\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 42/50 - Loss: 868.0588 - Train Acc: 0.9004 - Val Acc: 0.8440\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 43/50 - Loss: 855.3974 - Train Acc: 0.9014 - Val Acc: 0.8304\n",
      "[Distill] Epoch 44/50 - Loss: 845.8397 - Train Acc: 0.9066 - Val Acc: 0.8469\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 45/50 - Loss: 836.4186 - Train Acc: 0.9069 - Val Acc: 0.8391\n",
      "[Distill] Epoch 46/50 - Loss: 830.2007 - Train Acc: 0.9048 - Val Acc: 0.8333\n",
      "[Distill] Epoch 47/50 - Loss: 819.6424 - Train Acc: 0.9110 - Val Acc: 0.8498\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "[Distill] Epoch 48/50 - Loss: 814.7695 - Train Acc: 0.9100 - Val Acc: 0.8488\n",
      "[Distill] Epoch 49/50 - Loss: 799.6161 - Train Acc: 0.9141 - Val Acc: 0.8382\n",
      "[Distill] Epoch 50/50 - Loss: 798.6711 - Train Acc: 0.9122 - Val Acc: 0.8459\n",
      "\n",
      "📊 Final Classification Report (StudentCNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      1.00      1.00        39\n",
      "      Cerber       0.84      0.88      0.86       100\n",
      "    Darkside       1.00      0.80      0.89       178\n",
      "       Excel       0.97      1.00      0.99        74\n",
      "     Firefox       0.94      0.92      0.93       108\n",
      "   GandCrab4       0.66      0.75      0.70       175\n",
      "        Ryuk       0.72      0.68      0.70       103\n",
      "     SDelete       1.00      1.00      1.00        36\n",
      "  Sodinokibi       0.83      0.83      0.83       109\n",
      "  TeslaCrypt       0.70      0.93      0.80        40\n",
      "    WannaCry       1.00      1.00      1.00        33\n",
      "         Zip       1.00      1.00      1.00        37\n",
      "\n",
      "    accuracy                           0.85      1032\n",
      "   macro avg       0.89      0.90      0.89      1032\n",
      "weighted avg       0.86      0.85      0.85      1032\n",
      "\n",
      "✅ Student model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw10.pth\n",
      "\n",
      "🚀 Distilling AE→StudentCNN for Td=45, Tw=15 (T_len=31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/342412524.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2409692/657140011.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 2884.4282 - Train Acc: 0.2892 - Val Acc: 0.5069\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 02/50 - Loss: 2323.5615 - Train Acc: 0.6251 - Val Acc: 0.5741\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 03/50 - Loss: 2053.8032 - Train Acc: 0.6855 - Val Acc: 0.5917\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 04/50 - Loss: 1883.4927 - Train Acc: 0.7225 - Val Acc: 0.6224\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 05/50 - Loss: 1767.5742 - Train Acc: 0.7488 - Val Acc: 0.6370\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 06/50 - Loss: 1681.4533 - Train Acc: 0.7605 - Val Acc: 0.6494\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 07/50 - Loss: 1610.9981 - Train Acc: 0.7789 - Val Acc: 0.6618\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 08/50 - Loss: 1551.8486 - Train Acc: 0.7936 - Val Acc: 0.6771\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 09/50 - Loss: 1500.8250 - Train Acc: 0.8043 - Val Acc: 0.6896\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 10/50 - Loss: 1463.5378 - Train Acc: 0.8122 - Val Acc: 0.6969\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 11/50 - Loss: 1425.5432 - Train Acc: 0.8208 - Val Acc: 0.7166\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 12/50 - Loss: 1388.4160 - Train Acc: 0.8326 - Val Acc: 0.7166\n",
      "[Distill] Epoch 13/50 - Loss: 1359.0462 - Train Acc: 0.8372 - Val Acc: 0.7319\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 14/50 - Loss: 1331.7542 - Train Acc: 0.8404 - Val Acc: 0.7348\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 15/50 - Loss: 1302.8625 - Train Acc: 0.8491 - Val Acc: 0.7436\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 16/50 - Loss: 1273.9635 - Train Acc: 0.8546 - Val Acc: 0.7706\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 17/50 - Loss: 1251.0667 - Train Acc: 0.8575 - Val Acc: 0.7845\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 18/50 - Loss: 1225.2313 - Train Acc: 0.8630 - Val Acc: 0.7896\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 19/50 - Loss: 1200.6661 - Train Acc: 0.8682 - Val Acc: 0.7655\n",
      "[Distill] Epoch 20/50 - Loss: 1177.2093 - Train Acc: 0.8720 - Val Acc: 0.7940\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 21/50 - Loss: 1150.2804 - Train Acc: 0.8741 - Val Acc: 0.7984\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 22/50 - Loss: 1128.1242 - Train Acc: 0.8779 - Val Acc: 0.8057\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 23/50 - Loss: 1106.8805 - Train Acc: 0.8818 - Val Acc: 0.8152\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 24/50 - Loss: 1084.4670 - Train Acc: 0.8862 - Val Acc: 0.8130\n",
      "[Distill] Epoch 25/50 - Loss: 1064.8627 - Train Acc: 0.8895 - Val Acc: 0.8115\n",
      "[Distill] Epoch 26/50 - Loss: 1044.0823 - Train Acc: 0.8906 - Val Acc: 0.8188\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 27/50 - Loss: 1027.1675 - Train Acc: 0.8920 - Val Acc: 0.8283\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 28/50 - Loss: 1006.4623 - Train Acc: 0.8963 - Val Acc: 0.8174\n",
      "[Distill] Epoch 29/50 - Loss: 989.6260 - Train Acc: 0.8952 - Val Acc: 0.8335\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 30/50 - Loss: 974.2330 - Train Acc: 0.9003 - Val Acc: 0.8356\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 31/50 - Loss: 957.9753 - Train Acc: 0.8996 - Val Acc: 0.8400\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 32/50 - Loss: 943.3485 - Train Acc: 0.9004 - Val Acc: 0.8356\n",
      "[Distill] Epoch 33/50 - Loss: 931.7100 - Train Acc: 0.8980 - Val Acc: 0.8378\n",
      "[Distill] Epoch 34/50 - Loss: 919.4270 - Train Acc: 0.9009 - Val Acc: 0.8393\n",
      "[Distill] Epoch 35/50 - Loss: 907.0107 - Train Acc: 0.9013 - Val Acc: 0.8422\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 36/50 - Loss: 892.5204 - Train Acc: 0.9057 - Val Acc: 0.8473\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 37/50 - Loss: 880.8535 - Train Acc: 0.9044 - Val Acc: 0.8503\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 38/50 - Loss: 868.6154 - Train Acc: 0.9084 - Val Acc: 0.8554\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 39/50 - Loss: 858.8996 - Train Acc: 0.9097 - Val Acc: 0.8568\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 40/50 - Loss: 845.9784 - Train Acc: 0.9098 - Val Acc: 0.8510\n",
      "[Distill] Epoch 41/50 - Loss: 833.9802 - Train Acc: 0.9141 - Val Acc: 0.8678\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 42/50 - Loss: 823.9819 - Train Acc: 0.9142 - Val Acc: 0.8598\n",
      "[Distill] Epoch 43/50 - Loss: 819.0849 - Train Acc: 0.9139 - Val Acc: 0.8685\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 44/50 - Loss: 806.9616 - Train Acc: 0.9164 - Val Acc: 0.8590\n",
      "[Distill] Epoch 45/50 - Loss: 797.0066 - Train Acc: 0.9160 - Val Acc: 0.8685\n",
      "[Distill] Epoch 46/50 - Loss: 787.3282 - Train Acc: 0.9174 - Val Acc: 0.8685\n",
      "[Distill] Epoch 47/50 - Loss: 780.9463 - Train Acc: 0.9178 - Val Acc: 0.8707\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 48/50 - Loss: 768.5149 - Train Acc: 0.9224 - Val Acc: 0.8714\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "[Distill] Epoch 49/50 - Loss: 763.1073 - Train Acc: 0.9201 - Val Acc: 0.8612\n",
      "[Distill] Epoch 50/50 - Loss: 753.9440 - Train Acc: 0.9223 - Val Acc: 0.8809\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/342412524.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Classification Report (StudentCNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      1.00      1.00        53\n",
      "      Cerber       0.95      0.85      0.90       132\n",
      "    Darkside       0.96      0.86      0.90       232\n",
      "       Excel       1.00      1.00      1.00       100\n",
      "     Firefox       0.98      0.93      0.95       143\n",
      "   GandCrab4       0.76      0.75      0.76       228\n",
      "        Ryuk       0.77      0.74      0.76       137\n",
      "     SDelete       1.00      1.00      1.00        48\n",
      "  Sodinokibi       0.78      0.95      0.86       143\n",
      "  TeslaCrypt       0.69      0.96      0.80        53\n",
      "    WannaCry       1.00      1.00      1.00        48\n",
      "         Zip       1.00      1.00      1.00        52\n",
      "\n",
      "    accuracy                           0.88      1369\n",
      "   macro avg       0.91      0.92      0.91      1369\n",
      "weighted avg       0.89      0.88      0.88      1369\n",
      "\n",
      "✅ Student model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw15.pth\n",
      "\n",
      "🚀 Distilling AE→StudentCNN for Td=45, Tw=20 (T_len=26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/657140011.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 5149.9706 - Train Acc: 0.2040 - Val Acc: 0.4650\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 02/50 - Loss: 4362.0038 - Train Acc: 0.6153 - Val Acc: 0.5886\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 03/50 - Loss: 3991.5939 - Train Acc: 0.6973 - Val Acc: 0.6101\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 04/50 - Loss: 3769.4188 - Train Acc: 0.7291 - Val Acc: 0.6322\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 05/50 - Loss: 3617.9635 - Train Acc: 0.7524 - Val Acc: 0.6486\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 06/50 - Loss: 3505.9774 - Train Acc: 0.7675 - Val Acc: 0.6536\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 07/50 - Loss: 3417.7608 - Train Acc: 0.7802 - Val Acc: 0.6795\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 08/50 - Loss: 3339.0618 - Train Acc: 0.7912 - Val Acc: 0.6896\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 09/50 - Loss: 3278.0486 - Train Acc: 0.8039 - Val Acc: 0.6921\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 10/50 - Loss: 3216.2423 - Train Acc: 0.8125 - Val Acc: 0.7098\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 11/50 - Loss: 3172.0188 - Train Acc: 0.8202 - Val Acc: 0.7319\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 12/50 - Loss: 3120.4302 - Train Acc: 0.8271 - Val Acc: 0.7180\n",
      "[Distill] Epoch 13/50 - Loss: 3076.4740 - Train Acc: 0.8335 - Val Acc: 0.7262\n",
      "[Distill] Epoch 14/50 - Loss: 3030.9651 - Train Acc: 0.8368 - Val Acc: 0.7369\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 15/50 - Loss: 2977.7172 - Train Acc: 0.8445 - Val Acc: 0.7508\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 16/50 - Loss: 2922.4728 - Train Acc: 0.8464 - Val Acc: 0.7495\n",
      "[Distill] Epoch 17/50 - Loss: 2858.9939 - Train Acc: 0.8526 - Val Acc: 0.7672\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 18/50 - Loss: 2795.2181 - Train Acc: 0.8536 - Val Acc: 0.7722\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 19/50 - Loss: 2725.5606 - Train Acc: 0.8588 - Val Acc: 0.7685\n",
      "[Distill] Epoch 20/50 - Loss: 2656.7362 - Train Acc: 0.8580 - Val Acc: 0.7722\n",
      "[Distill] Epoch 21/50 - Loss: 2590.6129 - Train Acc: 0.8614 - Val Acc: 0.7836\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 22/50 - Loss: 2519.7312 - Train Acc: 0.8653 - Val Acc: 0.7748\n",
      "[Distill] Epoch 23/50 - Loss: 2461.3720 - Train Acc: 0.8657 - Val Acc: 0.7817\n",
      "[Distill] Epoch 24/50 - Loss: 2402.9651 - Train Acc: 0.8673 - Val Acc: 0.7817\n",
      "[Distill] Epoch 25/50 - Loss: 2356.4212 - Train Acc: 0.8708 - Val Acc: 0.7691\n",
      "[Distill] Epoch 26/50 - Loss: 2305.8374 - Train Acc: 0.8726 - Val Acc: 0.7981\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 27/50 - Loss: 2266.2387 - Train Acc: 0.8728 - Val Acc: 0.7924\n",
      "[Distill] Epoch 28/50 - Loss: 2227.8145 - Train Acc: 0.8756 - Val Acc: 0.7905\n",
      "[Distill] Epoch 29/50 - Loss: 2191.3576 - Train Acc: 0.8770 - Val Acc: 0.7975\n",
      "[Distill] Epoch 30/50 - Loss: 2162.6034 - Train Acc: 0.8797 - Val Acc: 0.8063\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 31/50 - Loss: 2130.5986 - Train Acc: 0.8795 - Val Acc: 0.7987\n",
      "[Distill] Epoch 32/50 - Loss: 2108.7257 - Train Acc: 0.8803 - Val Acc: 0.8120\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 33/50 - Loss: 2075.9597 - Train Acc: 0.8820 - Val Acc: 0.8057\n",
      "[Distill] Epoch 34/50 - Loss: 2057.1541 - Train Acc: 0.8826 - Val Acc: 0.8013\n",
      "[Distill] Epoch 35/50 - Loss: 2033.6464 - Train Acc: 0.8855 - Val Acc: 0.8114\n",
      "[Distill] Epoch 36/50 - Loss: 2009.5941 - Train Acc: 0.8862 - Val Acc: 0.8132\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 37/50 - Loss: 1992.6000 - Train Acc: 0.8867 - Val Acc: 0.8189\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 38/50 - Loss: 1969.4515 - Train Acc: 0.8887 - Val Acc: 0.8120\n",
      "[Distill] Epoch 39/50 - Loss: 1947.1286 - Train Acc: 0.8888 - Val Acc: 0.8164\n",
      "[Distill] Epoch 40/50 - Loss: 1932.7172 - Train Acc: 0.8889 - Val Acc: 0.8151\n",
      "[Distill] Epoch 41/50 - Loss: 1912.6163 - Train Acc: 0.8915 - Val Acc: 0.8202\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 42/50 - Loss: 1894.1772 - Train Acc: 0.8897 - Val Acc: 0.8151\n",
      "[Distill] Epoch 43/50 - Loss: 1870.5271 - Train Acc: 0.8922 - Val Acc: 0.8215\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 44/50 - Loss: 1858.8071 - Train Acc: 0.8900 - Val Acc: 0.8303\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 45/50 - Loss: 1837.7638 - Train Acc: 0.8940 - Val Acc: 0.8240\n",
      "[Distill] Epoch 46/50 - Loss: 1821.6407 - Train Acc: 0.8936 - Val Acc: 0.8246\n",
      "[Distill] Epoch 47/50 - Loss: 1806.5893 - Train Acc: 0.8930 - Val Acc: 0.8278\n",
      "[Distill] Epoch 48/50 - Loss: 1790.9103 - Train Acc: 0.8953 - Val Acc: 0.8303\n",
      "[Distill] Epoch 49/50 - Loss: 1779.2947 - Train Acc: 0.8918 - Val Acc: 0.8397\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "[Distill] Epoch 50/50 - Loss: 1760.3638 - Train Acc: 0.8980 - Val Acc: 0.8303\n",
      "\n",
      "📊 Final Classification Report (StudentCNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       0.98      0.98      0.98        60\n",
      "      Cerber       0.94      0.84      0.89       152\n",
      "    Darkside       0.97      0.84      0.90       270\n",
      "       Excel       1.00      1.00      1.00       115\n",
      "     Firefox       0.94      0.96      0.95       166\n",
      "   GandCrab4       0.68      0.65      0.67       265\n",
      "        Ryuk       0.68      0.68      0.68       158\n",
      "     SDelete       0.98      1.00      0.99        55\n",
      "  Sodinokibi       0.74      0.80      0.77       167\n",
      "  TeslaCrypt       0.56      1.00      0.72        62\n",
      "    WannaCry       0.98      1.00      0.99        55\n",
      "         Zip       1.00      0.97      0.98        60\n",
      "\n",
      "    accuracy                           0.84      1585\n",
      "   macro avg       0.87      0.89      0.88      1585\n",
      "weighted avg       0.85      0.84      0.84      1585\n",
      "\n",
      "✅ Student model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td45_Tw20.pth\n",
      "\n",
      "🚀 Distilling AE→StudentCNN for Td=60, Tw=10 (T_len=51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/342412524.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2409692/657140011.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 1843.4294 - Train Acc: 0.1262 - Val Acc: 0.2329\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1707.7341 - Train Acc: 0.3134 - Val Acc: 0.3333\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 03/50 - Loss: 1501.0614 - Train Acc: 0.5490 - Val Acc: 0.5167\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 04/50 - Loss: 1377.7670 - Train Acc: 0.6471 - Val Acc: 0.5837\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 05/50 - Loss: 1292.1416 - Train Acc: 0.7041 - Val Acc: 0.6215\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 06/50 - Loss: 1227.2656 - Train Acc: 0.7359 - Val Acc: 0.6143\n",
      "[Distill] Epoch 07/50 - Loss: 1175.4736 - Train Acc: 0.7631 - Val Acc: 0.6856\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 08/50 - Loss: 1131.8637 - Train Acc: 0.7824 - Val Acc: 0.6812\n",
      "[Distill] Epoch 09/50 - Loss: 1098.3925 - Train Acc: 0.8020 - Val Acc: 0.7089\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 10/50 - Loss: 1069.1932 - Train Acc: 0.8112 - Val Acc: 0.7336\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 11/50 - Loss: 1042.9230 - Train Acc: 0.8198 - Val Acc: 0.7001\n",
      "[Distill] Epoch 12/50 - Loss: 1018.0809 - Train Acc: 0.8283 - Val Acc: 0.7234\n",
      "[Distill] Epoch 13/50 - Loss: 999.5537 - Train Acc: 0.8297 - Val Acc: 0.7365\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 14/50 - Loss: 980.6576 - Train Acc: 0.8382 - Val Acc: 0.7584\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 15/50 - Loss: 963.9251 - Train Acc: 0.8413 - Val Acc: 0.7525\n",
      "[Distill] Epoch 16/50 - Loss: 949.9110 - Train Acc: 0.8488 - Val Acc: 0.7758\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 17/50 - Loss: 936.8153 - Train Acc: 0.8518 - Val Acc: 0.7729\n",
      "[Distill] Epoch 18/50 - Loss: 927.0432 - Train Acc: 0.8564 - Val Acc: 0.7715\n",
      "[Distill] Epoch 19/50 - Loss: 915.9655 - Train Acc: 0.8596 - Val Acc: 0.7817\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 20/50 - Loss: 904.1856 - Train Acc: 0.8645 - Val Acc: 0.7700\n",
      "[Distill] Epoch 21/50 - Loss: 897.1420 - Train Acc: 0.8646 - Val Acc: 0.7686\n",
      "[Distill] Epoch 22/50 - Loss: 885.9462 - Train Acc: 0.8664 - Val Acc: 0.7904\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 23/50 - Loss: 876.7804 - Train Acc: 0.8765 - Val Acc: 0.8166\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 24/50 - Loss: 868.5138 - Train Acc: 0.8777 - Val Acc: 0.8253\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 25/50 - Loss: 860.2074 - Train Acc: 0.8792 - Val Acc: 0.8151\n",
      "[Distill] Epoch 26/50 - Loss: 854.7634 - Train Acc: 0.8854 - Val Acc: 0.8064\n",
      "[Distill] Epoch 27/50 - Loss: 846.7493 - Train Acc: 0.8875 - Val Acc: 0.8137\n",
      "[Distill] Epoch 28/50 - Loss: 840.1191 - Train Acc: 0.8904 - Val Acc: 0.8253\n",
      "[Distill] Epoch 29/50 - Loss: 835.1286 - Train Acc: 0.8923 - Val Acc: 0.8413\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 30/50 - Loss: 829.0726 - Train Acc: 0.8939 - Val Acc: 0.8210\n",
      "[Distill] Epoch 31/50 - Loss: 822.1123 - Train Acc: 0.8972 - Val Acc: 0.8486\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 32/50 - Loss: 815.7059 - Train Acc: 0.9003 - Val Acc: 0.8515\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 33/50 - Loss: 812.2904 - Train Acc: 0.9026 - Val Acc: 0.8428\n",
      "[Distill] Epoch 34/50 - Loss: 806.1056 - Train Acc: 0.9015 - Val Acc: 0.8326\n",
      "[Distill] Epoch 35/50 - Loss: 800.4488 - Train Acc: 0.9047 - Val Acc: 0.8443\n",
      "[Distill] Epoch 36/50 - Loss: 795.4344 - Train Acc: 0.9082 - Val Acc: 0.8443\n",
      "[Distill] Epoch 37/50 - Loss: 788.3786 - Train Acc: 0.9068 - Val Acc: 0.8501\n",
      "[Distill] Epoch 38/50 - Loss: 784.4408 - Train Acc: 0.9169 - Val Acc: 0.8544\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 39/50 - Loss: 776.2455 - Train Acc: 0.9130 - Val Acc: 0.8370\n",
      "[Distill] Epoch 40/50 - Loss: 772.9136 - Train Acc: 0.9125 - Val Acc: 0.8632\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 41/50 - Loss: 766.1352 - Train Acc: 0.9175 - Val Acc: 0.8632\n",
      "[Distill] Epoch 42/50 - Loss: 763.0487 - Train Acc: 0.9185 - Val Acc: 0.8646\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 43/50 - Loss: 755.5188 - Train Acc: 0.9220 - Val Acc: 0.8646\n",
      "[Distill] Epoch 44/50 - Loss: 752.2503 - Train Acc: 0.9190 - Val Acc: 0.8617\n",
      "[Distill] Epoch 45/50 - Loss: 746.5261 - Train Acc: 0.9225 - Val Acc: 0.8705\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 46/50 - Loss: 740.5178 - Train Acc: 0.9238 - Val Acc: 0.8617\n",
      "[Distill] Epoch 47/50 - Loss: 733.6368 - Train Acc: 0.9221 - Val Acc: 0.8705\n",
      "[Distill] Epoch 48/50 - Loss: 729.0525 - Train Acc: 0.9271 - Val Acc: 0.8850\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "[Distill] Epoch 49/50 - Loss: 724.9852 - Train Acc: 0.9253 - Val Acc: 0.8690\n",
      "[Distill] Epoch 50/50 - Loss: 717.1729 - Train Acc: 0.9279 - Val Acc: 0.8690\n",
      "\n",
      "📊 Final Classification Report (StudentCNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      1.00      1.00        21\n",
      "      Cerber       0.89      0.87      0.88        68\n",
      "    Darkside       0.98      0.82      0.89       126\n",
      "       Excel       1.00      0.98      0.99        49\n",
      "     Firefox       0.99      0.95      0.97        74\n",
      "   GandCrab4       0.69      0.90      0.78       125\n",
      "        Ryuk       0.85      0.66      0.75        71\n",
      "     SDelete       1.00      1.00      1.00        18\n",
      "  Sodinokibi       0.91      0.93      0.92        74\n",
      "  TeslaCrypt       0.88      0.95      0.91        22\n",
      "    WannaCry       1.00      1.00      1.00        18\n",
      "         Zip       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.89       687\n",
      "   macro avg       0.93      0.92      0.92       687\n",
      "weighted avg       0.90      0.89      0.89       687\n",
      "\n",
      "✅ Student model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw10.pth\n",
      "\n",
      "🚀 Distilling AE→StudentCNN for Td=60, Tw=15 (T_len=46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/342412524.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2409692/657140011.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 1793.8849 - Train Acc: 0.1650 - Val Acc: 0.2519\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1550.8307 - Train Acc: 0.4515 - Val Acc: 0.4797\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 03/50 - Loss: 1279.7166 - Train Acc: 0.6733 - Val Acc: 0.6013\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 04/50 - Loss: 1152.6546 - Train Acc: 0.7365 - Val Acc: 0.6127\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 05/50 - Loss: 1069.8414 - Train Acc: 0.7609 - Val Acc: 0.6380\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 06/50 - Loss: 1009.8623 - Train Acc: 0.7825 - Val Acc: 0.6570\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 07/50 - Loss: 962.3200 - Train Acc: 0.7920 - Val Acc: 0.6620\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 08/50 - Loss: 925.6026 - Train Acc: 0.8045 - Val Acc: 0.6747\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 09/50 - Loss: 889.6927 - Train Acc: 0.8155 - Val Acc: 0.6962\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 10/50 - Loss: 860.1271 - Train Acc: 0.8257 - Val Acc: 0.7063\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 11/50 - Loss: 835.7639 - Train Acc: 0.8352 - Val Acc: 0.7101\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 12/50 - Loss: 812.7903 - Train Acc: 0.8437 - Val Acc: 0.7203\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 13/50 - Loss: 793.4207 - Train Acc: 0.8474 - Val Acc: 0.7342\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 14/50 - Loss: 775.8455 - Train Acc: 0.8573 - Val Acc: 0.7430\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 15/50 - Loss: 759.5553 - Train Acc: 0.8625 - Val Acc: 0.7570\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 16/50 - Loss: 742.6868 - Train Acc: 0.8717 - Val Acc: 0.7557\n",
      "[Distill] Epoch 17/50 - Loss: 730.0029 - Train Acc: 0.8736 - Val Acc: 0.7911\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 18/50 - Loss: 714.3875 - Train Acc: 0.8838 - Val Acc: 0.7734\n",
      "[Distill] Epoch 19/50 - Loss: 702.4125 - Train Acc: 0.8867 - Val Acc: 0.7962\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 20/50 - Loss: 691.5872 - Train Acc: 0.8902 - Val Acc: 0.7949\n",
      "[Distill] Epoch 21/50 - Loss: 678.4029 - Train Acc: 0.8960 - Val Acc: 0.7987\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 22/50 - Loss: 667.4588 - Train Acc: 0.9048 - Val Acc: 0.8190\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 23/50 - Loss: 659.6630 - Train Acc: 0.9060 - Val Acc: 0.8190\n",
      "[Distill] Epoch 24/50 - Loss: 645.8440 - Train Acc: 0.9105 - Val Acc: 0.8253\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 25/50 - Loss: 637.3343 - Train Acc: 0.9107 - Val Acc: 0.8253\n",
      "[Distill] Epoch 26/50 - Loss: 626.5563 - Train Acc: 0.9135 - Val Acc: 0.8456\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 27/50 - Loss: 615.5582 - Train Acc: 0.9195 - Val Acc: 0.8354\n",
      "[Distill] Epoch 28/50 - Loss: 609.5460 - Train Acc: 0.9207 - Val Acc: 0.8342\n",
      "[Distill] Epoch 29/50 - Loss: 600.1783 - Train Acc: 0.9222 - Val Acc: 0.8392\n",
      "[Distill] Epoch 30/50 - Loss: 591.9046 - Train Acc: 0.9263 - Val Acc: 0.8557\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 31/50 - Loss: 583.1668 - Train Acc: 0.9281 - Val Acc: 0.8595\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 32/50 - Loss: 574.4459 - Train Acc: 0.9284 - Val Acc: 0.8759\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 33/50 - Loss: 562.1126 - Train Acc: 0.9328 - Val Acc: 0.8633\n",
      "[Distill] Epoch 34/50 - Loss: 554.7258 - Train Acc: 0.9331 - Val Acc: 0.8658\n",
      "[Distill] Epoch 35/50 - Loss: 547.3936 - Train Acc: 0.9325 - Val Acc: 0.8772\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 36/50 - Loss: 537.0856 - Train Acc: 0.9340 - Val Acc: 0.8696\n",
      "[Distill] Epoch 37/50 - Loss: 530.0245 - Train Acc: 0.9390 - Val Acc: 0.8772\n",
      "[Distill] Epoch 38/50 - Loss: 520.2921 - Train Acc: 0.9407 - Val Acc: 0.8835\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 39/50 - Loss: 513.9163 - Train Acc: 0.9391 - Val Acc: 0.8835\n",
      "[Distill] Epoch 40/50 - Loss: 505.9400 - Train Acc: 0.9405 - Val Acc: 0.8848\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 41/50 - Loss: 495.9433 - Train Acc: 0.9450 - Val Acc: 0.8734\n",
      "[Distill] Epoch 42/50 - Loss: 489.1542 - Train Acc: 0.9410 - Val Acc: 0.8873\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 43/50 - Loss: 483.2220 - Train Acc: 0.9427 - Val Acc: 0.8911\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 44/50 - Loss: 474.7721 - Train Acc: 0.9452 - Val Acc: 0.8722\n",
      "[Distill] Epoch 45/50 - Loss: 467.8884 - Train Acc: 0.9475 - Val Acc: 0.8873\n",
      "[Distill] Epoch 46/50 - Loss: 462.0574 - Train Acc: 0.9480 - Val Acc: 0.8911\n",
      "[Distill] Epoch 47/50 - Loss: 453.6504 - Train Acc: 0.9490 - Val Acc: 0.8987\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "[Distill] Epoch 48/50 - Loss: 450.2408 - Train Acc: 0.9472 - Val Acc: 0.8962\n",
      "[Distill] Epoch 49/50 - Loss: 442.9852 - Train Acc: 0.9495 - Val Acc: 0.8924\n",
      "[Distill] Epoch 50/50 - Loss: 436.3488 - Train Acc: 0.9530 - Val Acc: 0.8949\n",
      "\n",
      "📊 Final Classification Report (StudentCNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      0.96      0.98        27\n",
      "      Cerber       0.97      0.88      0.92        76\n",
      "    Darkside       0.99      0.86      0.92       142\n",
      "       Excel       1.00      1.00      1.00        56\n",
      "     Firefox       0.99      0.94      0.96        85\n",
      "   GandCrab4       0.75      0.89      0.81       138\n",
      "        Ryuk       0.85      0.78      0.82        79\n",
      "     SDelete       0.92      1.00      0.96        24\n",
      "  Sodinokibi       0.91      0.85      0.88        84\n",
      "  TeslaCrypt       0.67      1.00      0.80        28\n",
      "    WannaCry       1.00      1.00      1.00        24\n",
      "         Zip       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           0.90       790\n",
      "   macro avg       0.92      0.93      0.92       790\n",
      "weighted avg       0.91      0.90      0.90       790\n",
      "\n",
      "✅ Student model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw15.pth\n",
      "\n",
      "🚀 Distilling AE→StudentCNN for Td=60, Tw=20 (T_len=41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/342412524.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n",
      "/tmp/ipykernel_2409692/657140011.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distill] Epoch 01/50 - Loss: 2001.8457 - Train Acc: 0.1603 - Val Acc: 0.2494\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 02/50 - Loss: 1716.9503 - Train Acc: 0.4508 - Val Acc: 0.4778\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 03/50 - Loss: 1488.4073 - Train Acc: 0.6379 - Val Acc: 0.5433\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 04/50 - Loss: 1350.2644 - Train Acc: 0.6925 - Val Acc: 0.5890\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 05/50 - Loss: 1255.0166 - Train Acc: 0.7243 - Val Acc: 0.6112\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 06/50 - Loss: 1185.7784 - Train Acc: 0.7460 - Val Acc: 0.6499\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 07/50 - Loss: 1126.6922 - Train Acc: 0.7631 - Val Acc: 0.6546\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 08/50 - Loss: 1083.3705 - Train Acc: 0.7831 - Val Acc: 0.6827\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 09/50 - Loss: 1045.6330 - Train Acc: 0.7888 - Val Acc: 0.6956\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 10/50 - Loss: 1011.1136 - Train Acc: 0.8042 - Val Acc: 0.6967\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 11/50 - Loss: 980.3608 - Train Acc: 0.8134 - Val Acc: 0.7073\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 12/50 - Loss: 954.2006 - Train Acc: 0.8179 - Val Acc: 0.7131\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 13/50 - Loss: 930.1894 - Train Acc: 0.8282 - Val Acc: 0.7190\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 14/50 - Loss: 910.9994 - Train Acc: 0.8378 - Val Acc: 0.7377\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 15/50 - Loss: 893.9973 - Train Acc: 0.8419 - Val Acc: 0.7354\n",
      "[Distill] Epoch 16/50 - Loss: 877.2957 - Train Acc: 0.8498 - Val Acc: 0.7412\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 17/50 - Loss: 862.3185 - Train Acc: 0.8553 - Val Acc: 0.7564\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 18/50 - Loss: 849.9232 - Train Acc: 0.8615 - Val Acc: 0.7471\n",
      "[Distill] Epoch 19/50 - Loss: 835.9006 - Train Acc: 0.8630 - Val Acc: 0.7611\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 20/50 - Loss: 820.9822 - Train Acc: 0.8723 - Val Acc: 0.7635\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 21/50 - Loss: 811.9037 - Train Acc: 0.8745 - Val Acc: 0.7787\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 22/50 - Loss: 800.1853 - Train Acc: 0.8769 - Val Acc: 0.7810\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 23/50 - Loss: 790.9404 - Train Acc: 0.8804 - Val Acc: 0.7717\n",
      "[Distill] Epoch 24/50 - Loss: 779.1043 - Train Acc: 0.8863 - Val Acc: 0.7857\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 25/50 - Loss: 771.9843 - Train Acc: 0.8880 - Val Acc: 0.7904\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 26/50 - Loss: 759.6077 - Train Acc: 0.8876 - Val Acc: 0.7822\n",
      "[Distill] Epoch 27/50 - Loss: 749.7116 - Train Acc: 0.8929 - Val Acc: 0.8009\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 28/50 - Loss: 740.2846 - Train Acc: 0.8997 - Val Acc: 0.7892\n",
      "[Distill] Epoch 29/50 - Loss: 730.5058 - Train Acc: 0.8948 - Val Acc: 0.8126\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 30/50 - Loss: 720.1392 - Train Acc: 0.8972 - Val Acc: 0.7986\n",
      "[Distill] Epoch 31/50 - Loss: 711.2020 - Train Acc: 0.9000 - Val Acc: 0.8162\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 32/50 - Loss: 700.9604 - Train Acc: 0.9021 - Val Acc: 0.8244\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 33/50 - Loss: 688.2845 - Train Acc: 0.9060 - Val Acc: 0.8150\n",
      "[Distill] Epoch 34/50 - Loss: 678.2501 - Train Acc: 0.9076 - Val Acc: 0.8302\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 35/50 - Loss: 670.0840 - Train Acc: 0.9080 - Val Acc: 0.8279\n",
      "[Distill] Epoch 36/50 - Loss: 659.7791 - Train Acc: 0.9120 - Val Acc: 0.7974\n",
      "[Distill] Epoch 37/50 - Loss: 647.2367 - Train Acc: 0.9139 - Val Acc: 0.8232\n",
      "[Distill] Epoch 38/50 - Loss: 639.7656 - Train Acc: 0.9119 - Val Acc: 0.8267\n",
      "[Distill] Epoch 39/50 - Loss: 630.2260 - Train Acc: 0.9128 - Val Acc: 0.8326\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 40/50 - Loss: 619.3509 - Train Acc: 0.9135 - Val Acc: 0.8384\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 41/50 - Loss: 608.5069 - Train Acc: 0.9171 - Val Acc: 0.8571\n",
      "💾 Best student model saved to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n",
      "[Distill] Epoch 42/50 - Loss: 601.8055 - Train Acc: 0.9191 - Val Acc: 0.8443\n",
      "[Distill] Epoch 43/50 - Loss: 589.1362 - Train Acc: 0.9238 - Val Acc: 0.8407\n",
      "[Distill] Epoch 44/50 - Loss: 584.8206 - Train Acc: 0.9201 - Val Acc: 0.8489\n",
      "[Distill] Epoch 45/50 - Loss: 577.3987 - Train Acc: 0.9226 - Val Acc: 0.8501\n",
      "[Distill] Epoch 46/50 - Loss: 569.9462 - Train Acc: 0.9212 - Val Acc: 0.8431\n",
      "[Distill] Epoch 47/50 - Loss: 561.6542 - Train Acc: 0.9262 - Val Acc: 0.8525\n",
      "[Distill] Epoch 48/50 - Loss: 560.0127 - Train Acc: 0.9251 - Val Acc: 0.8419\n",
      "[Distill] Epoch 49/50 - Loss: 550.8188 - Train Acc: 0.9281 - Val Acc: 0.8489\n",
      "[Distill] Epoch 50/50 - Loss: 545.6634 - Train Acc: 0.9274 - Val Acc: 0.8525\n",
      "\n",
      "📊 Final Classification Report (StudentCNN):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    AESCrypt       1.00      1.00      1.00        28\n",
      "      Cerber       0.83      0.93      0.88        84\n",
      "    Darkside       0.98      0.79      0.88       154\n",
      "       Excel       1.00      1.00      1.00        61\n",
      "     Firefox       0.96      0.96      0.96        91\n",
      "   GandCrab4       0.73      0.75      0.74       151\n",
      "        Ryuk       0.66      0.66      0.66        88\n",
      "     SDelete       0.83      1.00      0.91        24\n",
      "  Sodinokibi       0.87      0.87      0.87        91\n",
      "  TeslaCrypt       0.73      0.96      0.83        28\n",
      "    WannaCry       1.00      1.00      1.00        25\n",
      "         Zip       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           0.86       854\n",
      "   macro avg       0.88      0.91      0.89       854\n",
      "weighted avg       0.86      0.86      0.86       854\n",
      "\n",
      "✅ Student model saved: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/student/student_from_ae_Td60_Tw20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/342412524.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "detection_times = [30, 45, 60]\n",
    "window_sizes = [10, 15, 20]\n",
    "\n",
    "base_dir = \"/home/HardDisk/Satang/thesis_proj\"\n",
    "teacher_dir = os.path.join(base_dir, \"Deep_Learning\", \"cross_archi\", \"ae\", \"teacher\")  # AE teacher\n",
    "student_save_dir = os.path.join(base_dir, \"Deep_Learning\", \"cross_archi\", \"ae\", \"student\")\n",
    "os.makedirs(student_save_dir, exist_ok=True)\n",
    "\n",
    "for T_d in detection_times:\n",
    "    for T_w in window_sizes:\n",
    "        T_len = T_d - T_w + 1\n",
    "        expected_shape = (T_len, NUM_FEATURES)\n",
    "\n",
    "        print(f\"\\n🚀 Distilling AE→StudentCNN for Td={T_d}, Tw={T_w} (T_len={T_len})\")\n",
    "\n",
    "        # === Paths ===\n",
    "        folder_name = f\"X_csv_split_{T_len}\"\n",
    "        input_dir = os.path.join(base_dir, f\"New_{T_d}\", f\"{T_w}\", \"split_tws\", folder_name)\n",
    "        train_path = os.path.join(input_dir, \"train\")\n",
    "        val_path   = os.path.join(input_dir, \"val\")\n",
    "        teacher_path = os.path.join(teacher_dir, f\"ae_Td{T_d}_Tw{T_w}.pth\")\n",
    "        student_path = os.path.join(student_save_dir, f\"student_from_ae_Td{T_d}_Tw{T_w}.pth\")\n",
    "\n",
    "        # === 1. Load Data ===\n",
    "        X_train_raw, y_train_raw = load_split_from_folder(train_path, expected_shape)\n",
    "        X_val_raw, y_val_raw     = load_split_from_folder(val_path, expected_shape)\n",
    "\n",
    "        # === 2. Encode & Balance ===\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_encoded = label_encoder.fit_transform(y_train_raw)\n",
    "        X_train_flat = X_train_raw.reshape(X_train_raw.shape[0], -1)\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X_train_flat, y_train_encoded)\n",
    "        X_train_bal = X_resampled.reshape(-1, T_len, NUM_FEATURES)\n",
    "        y_train_str = label_encoder.inverse_transform(y_resampled)\n",
    "\n",
    "        # === 3. Dataset & Dataloader ===\n",
    "        train_dataset = MultiStreamDataset(X_train_bal, y_train_str, label_encoder, augment=True)\n",
    "        val_dataset   = MultiStreamDataset(X_val_raw, y_val_raw, label_encoder, augment=False)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        class_weights = compute_class_weights(label_encoder.transform(y_train_str), device)\n",
    "\n",
    "        # === 4. Load AE Teacher ===\n",
    "        teacher = AEWithClassifier(\n",
    "            input_length=T_len,\n",
    "            feature_dim=NUM_FEATURES,\n",
    "            latent_dim=64,\n",
    "            num_classes=len(label_encoder.classes_),\n",
    "            proj_dim=128\n",
    "        )\n",
    "        teacher.load_state_dict(torch.load(teacher_path, map_location=device))\n",
    "        teacher.to(device)\n",
    "        teacher.eval()\n",
    "        for p in teacher.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # === 5. Init Student CNN & Train ===\n",
    "        student = StudentCNN(\n",
    "            input_length=T_len,\n",
    "            num_classes=len(label_encoder.classes_)\n",
    "        ).to(device)\n",
    "\n",
    "        train_accs, val_accs, train_losses, val_losses = train_distilled(\n",
    "            student=student,\n",
    "            teacher=teacher,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            device=device,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            lr=0.0001,\n",
    "            class_weights=class_weights_tensor,\n",
    "            T=2.5,\n",
    "            alpha=0.7,\n",
    "            beta=0.2,\n",
    "            gamma=0.1,\n",
    "            save_path=student_path\n",
    "        )\n",
    "\n",
    "        # === 6. Final Evaluation ===\n",
    "        student.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = student(inputs)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        print(\"\\n📊 Final Classification Report (StudentCNN):\")\n",
    "        print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
    "        print(f\"✅ Student model saved: {student_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "962da988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_student_baseline(student, train_loader, val_loader, device,\n",
    "                           epochs=50, lr=0.0005, class_weights=None,\n",
    "                           save_path=\"best_student_baseline.pth\"):\n",
    "\n",
    "    student.to(device)\n",
    "    optimizer = optim.Adam(student.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    train_losses, train_accuracies, val_accuracies, val_losses = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        total_loss, correct = 0.0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            logits = student(inputs)  # 🔹 Only logits expected\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (logits.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_acc = correct / len(train_loader.dataset)\n",
    "        train_losses.append(total_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # === Validation ===\n",
    "        student.eval()\n",
    "        val_correct, val_loss = 0, 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                logits = student(inputs)\n",
    "                loss = criterion(logits, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (logits.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / len(val_loader.dataset)\n",
    "        val_accuracies.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"[Baseline] Epoch {epoch+1:02d}/{epochs} - \"\n",
    "              f\"Loss: {total_loss:.4f} - Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(student.state_dict(), save_path)\n",
    "            print(f\"💾 Saved best standalone student model to: {save_path}\")\n",
    "\n",
    "    student.load_state_dict(torch.load(save_path))\n",
    "    return train_accuracies, val_accuracies, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c04a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Training Standalone Student for Td=30, Tw=10 (T_len=21)\n",
      "[Baseline] Epoch 01/50 - Loss: 1405.6159 - Train Acc: 0.1477 - Val Acc: 0.2099\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 1146.1133 - Train Acc: 0.3425 - Val Acc: 0.4163\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 872.6926 - Train Acc: 0.5178 - Val Acc: 0.4749\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 755.2142 - Train Acc: 0.5709 - Val Acc: 0.4975\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 677.6799 - Train Acc: 0.6070 - Val Acc: 0.5341\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 622.6866 - Train Acc: 0.6399 - Val Acc: 0.5476\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 577.1590 - Train Acc: 0.6643 - Val Acc: 0.5731\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 541.4583 - Train Acc: 0.6848 - Val Acc: 0.5947\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 514.1670 - Train Acc: 0.7004 - Val Acc: 0.6022\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 492.9121 - Train Acc: 0.7098 - Val Acc: 0.6117\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 474.2257 - Train Acc: 0.7183 - Val Acc: 0.6288\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 458.1967 - Train Acc: 0.7249 - Val Acc: 0.6413\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 448.0807 - Train Acc: 0.7284 - Val Acc: 0.6358\n",
      "[Baseline] Epoch 14/50 - Loss: 434.3095 - Train Acc: 0.7357 - Val Acc: 0.6378\n",
      "[Baseline] Epoch 15/50 - Loss: 425.7780 - Train Acc: 0.7408 - Val Acc: 0.6628\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 416.1313 - Train Acc: 0.7455 - Val Acc: 0.6503\n",
      "[Baseline] Epoch 17/50 - Loss: 407.8514 - Train Acc: 0.7480 - Val Acc: 0.6573\n",
      "[Baseline] Epoch 18/50 - Loss: 398.3098 - Train Acc: 0.7541 - Val Acc: 0.6583\n",
      "[Baseline] Epoch 19/50 - Loss: 390.2181 - Train Acc: 0.7533 - Val Acc: 0.6718\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 383.9072 - Train Acc: 0.7616 - Val Acc: 0.6799\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 378.0917 - Train Acc: 0.7642 - Val Acc: 0.6708\n",
      "[Baseline] Epoch 22/50 - Loss: 371.7852 - Train Acc: 0.7660 - Val Acc: 0.6759\n",
      "[Baseline] Epoch 23/50 - Loss: 366.3568 - Train Acc: 0.7705 - Val Acc: 0.6869\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 360.9493 - Train Acc: 0.7739 - Val Acc: 0.6708\n",
      "[Baseline] Epoch 25/50 - Loss: 353.8737 - Train Acc: 0.7777 - Val Acc: 0.6844\n",
      "[Baseline] Epoch 26/50 - Loss: 349.2908 - Train Acc: 0.7821 - Val Acc: 0.6969\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 343.3404 - Train Acc: 0.7868 - Val Acc: 0.6964\n",
      "[Baseline] Epoch 28/50 - Loss: 337.8983 - Train Acc: 0.7895 - Val Acc: 0.6999\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 332.7390 - Train Acc: 0.7917 - Val Acc: 0.6914\n",
      "[Baseline] Epoch 30/50 - Loss: 325.9085 - Train Acc: 0.7985 - Val Acc: 0.7249\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 31/50 - Loss: 322.1534 - Train Acc: 0.8006 - Val Acc: 0.7119\n",
      "[Baseline] Epoch 32/50 - Loss: 318.3595 - Train Acc: 0.8043 - Val Acc: 0.7019\n",
      "[Baseline] Epoch 33/50 - Loss: 313.9206 - Train Acc: 0.8066 - Val Acc: 0.7320\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 34/50 - Loss: 309.8453 - Train Acc: 0.8098 - Val Acc: 0.7335\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 35/50 - Loss: 304.7032 - Train Acc: 0.8108 - Val Acc: 0.7305\n",
      "[Baseline] Epoch 36/50 - Loss: 298.5616 - Train Acc: 0.8153 - Val Acc: 0.7430\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 297.7581 - Train Acc: 0.8149 - Val Acc: 0.7495\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 38/50 - Loss: 292.2929 - Train Acc: 0.8185 - Val Acc: 0.7685\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 39/50 - Loss: 288.6854 - Train Acc: 0.8213 - Val Acc: 0.7069\n",
      "[Baseline] Epoch 40/50 - Loss: 284.7402 - Train Acc: 0.8234 - Val Acc: 0.7485\n",
      "[Baseline] Epoch 41/50 - Loss: 283.8079 - Train Acc: 0.8249 - Val Acc: 0.7505\n",
      "[Baseline] Epoch 42/50 - Loss: 278.3629 - Train Acc: 0.8262 - Val Acc: 0.7610\n",
      "[Baseline] Epoch 43/50 - Loss: 277.7452 - Train Acc: 0.8312 - Val Acc: 0.7745\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 44/50 - Loss: 273.7775 - Train Acc: 0.8309 - Val Acc: 0.7781\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 45/50 - Loss: 274.9938 - Train Acc: 0.8306 - Val Acc: 0.7851\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 270.4297 - Train Acc: 0.8336 - Val Acc: 0.7505\n",
      "[Baseline] Epoch 47/50 - Loss: 268.3755 - Train Acc: 0.8338 - Val Acc: 0.7936\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "[Baseline] Epoch 48/50 - Loss: 266.9250 - Train Acc: 0.8324 - Val Acc: 0.7735\n",
      "[Baseline] Epoch 49/50 - Loss: 262.6863 - Train Acc: 0.8361 - Val Acc: 0.7866\n",
      "[Baseline] Epoch 50/50 - Loss: 260.5157 - Train Acc: 0.8390 - Val Acc: 0.7515\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw10.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=30, Tw=15 (T_len=16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/914780513.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 1827.1933 - Train Acc: 0.1558 - Val Acc: 0.2434\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 1354.1988 - Train Acc: 0.4285 - Val Acc: 0.4544\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 1014.7215 - Train Acc: 0.5843 - Val Acc: 0.5114\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 866.1570 - Train Acc: 0.6311 - Val Acc: 0.5528\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 774.4451 - Train Acc: 0.6607 - Val Acc: 0.5816\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 714.4183 - Train Acc: 0.6782 - Val Acc: 0.5945\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 667.0107 - Train Acc: 0.6945 - Val Acc: 0.6097\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 628.4023 - Train Acc: 0.7128 - Val Acc: 0.6185\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 597.2229 - Train Acc: 0.7226 - Val Acc: 0.6371\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 571.9467 - Train Acc: 0.7368 - Val Acc: 0.6500\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 549.6232 - Train Acc: 0.7472 - Val Acc: 0.6655\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 528.7499 - Train Acc: 0.7586 - Val Acc: 0.6769\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 509.4767 - Train Acc: 0.7657 - Val Acc: 0.6891\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 485.6493 - Train Acc: 0.7794 - Val Acc: 0.6974\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 465.1580 - Train Acc: 0.7897 - Val Acc: 0.7145\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 446.7942 - Train Acc: 0.8001 - Val Acc: 0.7232\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 432.3100 - Train Acc: 0.8067 - Val Acc: 0.7396\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 419.0400 - Train Acc: 0.8130 - Val Acc: 0.7434\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 409.7982 - Train Acc: 0.8168 - Val Acc: 0.7380\n",
      "[Baseline] Epoch 20/50 - Loss: 397.2039 - Train Acc: 0.8231 - Val Acc: 0.7555\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 388.8446 - Train Acc: 0.8261 - Val Acc: 0.7483\n",
      "[Baseline] Epoch 22/50 - Loss: 380.1351 - Train Acc: 0.8296 - Val Acc: 0.7730\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 23/50 - Loss: 373.3110 - Train Acc: 0.8314 - Val Acc: 0.7616\n",
      "[Baseline] Epoch 24/50 - Loss: 365.3263 - Train Acc: 0.8373 - Val Acc: 0.7673\n",
      "[Baseline] Epoch 25/50 - Loss: 359.5414 - Train Acc: 0.8392 - Val Acc: 0.7722\n",
      "[Baseline] Epoch 26/50 - Loss: 351.2820 - Train Acc: 0.8413 - Val Acc: 0.7737\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 348.4726 - Train Acc: 0.8425 - Val Acc: 0.7760\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 341.9978 - Train Acc: 0.8467 - Val Acc: 0.7920\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 334.4809 - Train Acc: 0.8491 - Val Acc: 0.7844\n",
      "[Baseline] Epoch 30/50 - Loss: 331.2115 - Train Acc: 0.8511 - Val Acc: 0.7969\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 31/50 - Loss: 326.7278 - Train Acc: 0.8523 - Val Acc: 0.7916\n",
      "[Baseline] Epoch 32/50 - Loss: 321.4565 - Train Acc: 0.8539 - Val Acc: 0.7920\n",
      "[Baseline] Epoch 33/50 - Loss: 317.1139 - Train Acc: 0.8579 - Val Acc: 0.7976\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 34/50 - Loss: 315.0858 - Train Acc: 0.8569 - Val Acc: 0.7901\n",
      "[Baseline] Epoch 35/50 - Loss: 311.8253 - Train Acc: 0.8583 - Val Acc: 0.8052\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 36/50 - Loss: 306.2984 - Train Acc: 0.8611 - Val Acc: 0.8037\n",
      "[Baseline] Epoch 37/50 - Loss: 302.2094 - Train Acc: 0.8624 - Val Acc: 0.8049\n",
      "[Baseline] Epoch 38/50 - Loss: 300.8145 - Train Acc: 0.8635 - Val Acc: 0.8144\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 39/50 - Loss: 296.9555 - Train Acc: 0.8645 - Val Acc: 0.8094\n",
      "[Baseline] Epoch 40/50 - Loss: 291.0234 - Train Acc: 0.8687 - Val Acc: 0.8098\n",
      "[Baseline] Epoch 41/50 - Loss: 290.9907 - Train Acc: 0.8685 - Val Acc: 0.8144\n",
      "[Baseline] Epoch 42/50 - Loss: 287.7052 - Train Acc: 0.8676 - Val Acc: 0.8178\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 43/50 - Loss: 283.1945 - Train Acc: 0.8694 - Val Acc: 0.8185\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 44/50 - Loss: 281.6002 - Train Acc: 0.8702 - Val Acc: 0.8056\n",
      "[Baseline] Epoch 45/50 - Loss: 279.1773 - Train Acc: 0.8718 - Val Acc: 0.8189\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 277.3303 - Train Acc: 0.8718 - Val Acc: 0.8219\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 47/50 - Loss: 273.2389 - Train Acc: 0.8751 - Val Acc: 0.8227\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 48/50 - Loss: 272.0179 - Train Acc: 0.8764 - Val Acc: 0.8212\n",
      "[Baseline] Epoch 49/50 - Loss: 267.7383 - Train Acc: 0.8769 - Val Acc: 0.8288\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "[Baseline] Epoch 50/50 - Loss: 266.4388 - Train Acc: 0.8766 - Val Acc: 0.8273\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw15.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=30, Tw=20 (T_len=11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/914780513.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 2935.8526 - Train Acc: 0.3755 - Val Acc: 0.5201\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 1712.0840 - Train Acc: 0.6523 - Val Acc: 0.5925\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 1385.6784 - Train Acc: 0.7106 - Val Acc: 0.6147\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 1197.6419 - Train Acc: 0.7406 - Val Acc: 0.6436\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 1068.0820 - Train Acc: 0.7626 - Val Acc: 0.6734\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 977.3076 - Train Acc: 0.7828 - Val Acc: 0.6853\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 901.4711 - Train Acc: 0.8018 - Val Acc: 0.7159\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 841.0601 - Train Acc: 0.8148 - Val Acc: 0.7185\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 795.1689 - Train Acc: 0.8258 - Val Acc: 0.7302\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 757.6104 - Train Acc: 0.8343 - Val Acc: 0.7455\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 725.9388 - Train Acc: 0.8404 - Val Acc: 0.7361\n",
      "[Baseline] Epoch 12/50 - Loss: 703.0459 - Train Acc: 0.8472 - Val Acc: 0.7532\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 676.5479 - Train Acc: 0.8525 - Val Acc: 0.7535\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 653.8423 - Train Acc: 0.8570 - Val Acc: 0.7663\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 637.2814 - Train Acc: 0.8601 - Val Acc: 0.7795\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 619.2271 - Train Acc: 0.8628 - Val Acc: 0.7807\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 604.3629 - Train Acc: 0.8672 - Val Acc: 0.7860\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 592.0157 - Train Acc: 0.8695 - Val Acc: 0.7849\n",
      "[Baseline] Epoch 19/50 - Loss: 579.8226 - Train Acc: 0.8700 - Val Acc: 0.7998\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 567.0522 - Train Acc: 0.8721 - Val Acc: 0.7847\n",
      "[Baseline] Epoch 21/50 - Loss: 554.9421 - Train Acc: 0.8761 - Val Acc: 0.7950\n",
      "[Baseline] Epoch 22/50 - Loss: 546.5139 - Train Acc: 0.8771 - Val Acc: 0.7996\n",
      "[Baseline] Epoch 23/50 - Loss: 533.0467 - Train Acc: 0.8788 - Val Acc: 0.8052\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 525.6816 - Train Acc: 0.8817 - Val Acc: 0.8193\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 25/50 - Loss: 517.4465 - Train Acc: 0.8826 - Val Acc: 0.8103\n",
      "[Baseline] Epoch 26/50 - Loss: 507.9525 - Train Acc: 0.8846 - Val Acc: 0.8145\n",
      "[Baseline] Epoch 27/50 - Loss: 505.7433 - Train Acc: 0.8856 - Val Acc: 0.8109\n",
      "[Baseline] Epoch 28/50 - Loss: 498.0139 - Train Acc: 0.8867 - Val Acc: 0.8193\n",
      "[Baseline] Epoch 29/50 - Loss: 488.2511 - Train Acc: 0.8877 - Val Acc: 0.8233\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 30/50 - Loss: 481.9855 - Train Acc: 0.8881 - Val Acc: 0.8243\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 31/50 - Loss: 472.0777 - Train Acc: 0.8913 - Val Acc: 0.8321\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 468.6726 - Train Acc: 0.8935 - Val Acc: 0.8293\n",
      "[Baseline] Epoch 33/50 - Loss: 465.1753 - Train Acc: 0.8935 - Val Acc: 0.8451\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 34/50 - Loss: 461.9271 - Train Acc: 0.8936 - Val Acc: 0.8407\n",
      "[Baseline] Epoch 35/50 - Loss: 454.9059 - Train Acc: 0.8953 - Val Acc: 0.8417\n",
      "[Baseline] Epoch 36/50 - Loss: 447.1834 - Train Acc: 0.8972 - Val Acc: 0.8505\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 443.3139 - Train Acc: 0.8979 - Val Acc: 0.8396\n",
      "[Baseline] Epoch 38/50 - Loss: 439.4591 - Train Acc: 0.8989 - Val Acc: 0.8505\n",
      "[Baseline] Epoch 39/50 - Loss: 436.8512 - Train Acc: 0.9004 - Val Acc: 0.8465\n",
      "[Baseline] Epoch 40/50 - Loss: 431.7442 - Train Acc: 0.8998 - Val Acc: 0.8556\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 41/50 - Loss: 425.3267 - Train Acc: 0.9021 - Val Acc: 0.8426\n",
      "[Baseline] Epoch 42/50 - Loss: 426.0509 - Train Acc: 0.9019 - Val Acc: 0.8512\n",
      "[Baseline] Epoch 43/50 - Loss: 418.9710 - Train Acc: 0.9032 - Val Acc: 0.8524\n",
      "[Baseline] Epoch 44/50 - Loss: 414.5617 - Train Acc: 0.9032 - Val Acc: 0.8593\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "[Baseline] Epoch 45/50 - Loss: 412.7816 - Train Acc: 0.9051 - Val Acc: 0.8562\n",
      "[Baseline] Epoch 46/50 - Loss: 409.7912 - Train Acc: 0.9038 - Val Acc: 0.8539\n",
      "[Baseline] Epoch 47/50 - Loss: 402.7149 - Train Acc: 0.9064 - Val Acc: 0.8554\n",
      "[Baseline] Epoch 48/50 - Loss: 399.7852 - Train Acc: 0.9075 - Val Acc: 0.8488\n",
      "[Baseline] Epoch 49/50 - Loss: 397.1374 - Train Acc: 0.9071 - Val Acc: 0.8562\n",
      "[Baseline] Epoch 50/50 - Loss: 395.1851 - Train Acc: 0.9082 - Val Acc: 0.8656\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td30_Tw20.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=45, Tw=10 (T_len=36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/914780513.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 785.2597 - Train Acc: 0.1132 - Val Acc: 0.2578\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 742.7139 - Train Acc: 0.2233 - Val Acc: 0.3382\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 611.7581 - Train Acc: 0.4009 - Val Acc: 0.4196\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 476.4493 - Train Acc: 0.5495 - Val Acc: 0.5349\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 417.8108 - Train Acc: 0.6103 - Val Acc: 0.5475\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 377.4325 - Train Acc: 0.6547 - Val Acc: 0.5775\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 342.4461 - Train Acc: 0.6817 - Val Acc: 0.5940\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 317.1081 - Train Acc: 0.7009 - Val Acc: 0.6056\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 295.9689 - Train Acc: 0.7183 - Val Acc: 0.6240\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 277.7300 - Train Acc: 0.7342 - Val Acc: 0.6318\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 262.2586 - Train Acc: 0.7505 - Val Acc: 0.6444\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 250.0941 - Train Acc: 0.7623 - Val Acc: 0.6550\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 238.9212 - Train Acc: 0.7692 - Val Acc: 0.6599\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 227.8580 - Train Acc: 0.7754 - Val Acc: 0.6696\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 219.6969 - Train Acc: 0.7855 - Val Acc: 0.6773\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 212.0506 - Train Acc: 0.7864 - Val Acc: 0.6919\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 204.6394 - Train Acc: 0.7953 - Val Acc: 0.6870\n",
      "[Baseline] Epoch 18/50 - Loss: 198.9046 - Train Acc: 0.7976 - Val Acc: 0.6967\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 193.1188 - Train Acc: 0.8040 - Val Acc: 0.6977\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 187.9072 - Train Acc: 0.8074 - Val Acc: 0.6967\n",
      "[Baseline] Epoch 21/50 - Loss: 181.2410 - Train Acc: 0.8136 - Val Acc: 0.7132\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 177.1084 - Train Acc: 0.8164 - Val Acc: 0.7248\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 23/50 - Loss: 171.4615 - Train Acc: 0.8215 - Val Acc: 0.7306\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 165.7787 - Train Acc: 0.8266 - Val Acc: 0.7461\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 25/50 - Loss: 162.9667 - Train Acc: 0.8314 - Val Acc: 0.7510\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 158.9184 - Train Acc: 0.8321 - Val Acc: 0.7364\n",
      "[Baseline] Epoch 27/50 - Loss: 155.0310 - Train Acc: 0.8368 - Val Acc: 0.7490\n",
      "[Baseline] Epoch 28/50 - Loss: 152.3510 - Train Acc: 0.8389 - Val Acc: 0.7481\n",
      "[Baseline] Epoch 29/50 - Loss: 149.7200 - Train Acc: 0.8458 - Val Acc: 0.7674\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 30/50 - Loss: 146.0989 - Train Acc: 0.8450 - Val Acc: 0.7713\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 31/50 - Loss: 142.4853 - Train Acc: 0.8497 - Val Acc: 0.7500\n",
      "[Baseline] Epoch 32/50 - Loss: 140.4834 - Train Acc: 0.8497 - Val Acc: 0.7645\n",
      "[Baseline] Epoch 33/50 - Loss: 138.0157 - Train Acc: 0.8505 - Val Acc: 0.7703\n",
      "[Baseline] Epoch 34/50 - Loss: 134.6835 - Train Acc: 0.8560 - Val Acc: 0.7888\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 35/50 - Loss: 132.2935 - Train Acc: 0.8586 - Val Acc: 0.7820\n",
      "[Baseline] Epoch 36/50 - Loss: 130.5590 - Train Acc: 0.8618 - Val Acc: 0.7800\n",
      "[Baseline] Epoch 37/50 - Loss: 126.1403 - Train Acc: 0.8663 - Val Acc: 0.7917\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 38/50 - Loss: 125.0737 - Train Acc: 0.8655 - Val Acc: 0.7820\n",
      "[Baseline] Epoch 39/50 - Loss: 122.8707 - Train Acc: 0.8745 - Val Acc: 0.7810\n",
      "[Baseline] Epoch 40/50 - Loss: 120.1163 - Train Acc: 0.8716 - Val Acc: 0.7926\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 41/50 - Loss: 119.8350 - Train Acc: 0.8727 - Val Acc: 0.7888\n",
      "[Baseline] Epoch 42/50 - Loss: 116.6435 - Train Acc: 0.8759 - Val Acc: 0.8023\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 43/50 - Loss: 116.0724 - Train Acc: 0.8753 - Val Acc: 0.7897\n",
      "[Baseline] Epoch 44/50 - Loss: 114.9604 - Train Acc: 0.8780 - Val Acc: 0.8081\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 45/50 - Loss: 112.7290 - Train Acc: 0.8798 - Val Acc: 0.7946\n",
      "[Baseline] Epoch 46/50 - Loss: 111.7211 - Train Acc: 0.8824 - Val Acc: 0.8043\n",
      "[Baseline] Epoch 47/50 - Loss: 111.5863 - Train Acc: 0.8850 - Val Acc: 0.8140\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 48/50 - Loss: 107.6206 - Train Acc: 0.8867 - Val Acc: 0.8072\n",
      "[Baseline] Epoch 49/50 - Loss: 107.3059 - Train Acc: 0.8873 - Val Acc: 0.8169\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "[Baseline] Epoch 50/50 - Loss: 105.8650 - Train Acc: 0.8874 - Val Acc: 0.8062\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw10.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=45, Tw=15 (T_len=31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/914780513.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 1016.3155 - Train Acc: 0.1233 - Val Acc: 0.2966\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 840.6059 - Train Acc: 0.3633 - Val Acc: 0.4748\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 591.8036 - Train Acc: 0.5940 - Val Acc: 0.5457\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 502.8606 - Train Acc: 0.6538 - Val Acc: 0.5741\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 440.3985 - Train Acc: 0.6913 - Val Acc: 0.5880\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 399.0516 - Train Acc: 0.7102 - Val Acc: 0.5961\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 367.4381 - Train Acc: 0.7261 - Val Acc: 0.6143\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 344.0918 - Train Acc: 0.7350 - Val Acc: 0.6209\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 322.9447 - Train Acc: 0.7495 - Val Acc: 0.6348\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 304.9945 - Train Acc: 0.7606 - Val Acc: 0.6384\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 289.2579 - Train Acc: 0.7672 - Val Acc: 0.6413\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 275.4117 - Train Acc: 0.7778 - Val Acc: 0.6567\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 264.6974 - Train Acc: 0.7842 - Val Acc: 0.6771\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 254.0509 - Train Acc: 0.7923 - Val Acc: 0.6815\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 244.7326 - Train Acc: 0.8009 - Val Acc: 0.6888\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 234.6218 - Train Acc: 0.8078 - Val Acc: 0.7042\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 228.0136 - Train Acc: 0.8156 - Val Acc: 0.7064\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 220.5971 - Train Acc: 0.8194 - Val Acc: 0.7122\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 212.9625 - Train Acc: 0.8281 - Val Acc: 0.7144\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 207.6128 - Train Acc: 0.8319 - Val Acc: 0.7283\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 200.7723 - Train Acc: 0.8354 - Val Acc: 0.7253\n",
      "[Baseline] Epoch 22/50 - Loss: 195.7760 - Train Acc: 0.8441 - Val Acc: 0.7305\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 23/50 - Loss: 190.3249 - Train Acc: 0.8449 - Val Acc: 0.7400\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 184.9103 - Train Acc: 0.8484 - Val Acc: 0.7451\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 25/50 - Loss: 179.6870 - Train Acc: 0.8536 - Val Acc: 0.7575\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 177.8282 - Train Acc: 0.8541 - Val Acc: 0.7538\n",
      "[Baseline] Epoch 27/50 - Loss: 172.2782 - Train Acc: 0.8616 - Val Acc: 0.7443\n",
      "[Baseline] Epoch 28/50 - Loss: 169.7142 - Train Acc: 0.8624 - Val Acc: 0.7487\n",
      "[Baseline] Epoch 29/50 - Loss: 166.0822 - Train Acc: 0.8658 - Val Acc: 0.7458\n",
      "[Baseline] Epoch 30/50 - Loss: 162.2642 - Train Acc: 0.8701 - Val Acc: 0.7480\n",
      "[Baseline] Epoch 31/50 - Loss: 158.1313 - Train Acc: 0.8704 - Val Acc: 0.7611\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 156.8572 - Train Acc: 0.8744 - Val Acc: 0.7845\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 33/50 - Loss: 154.4430 - Train Acc: 0.8759 - Val Acc: 0.7911\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 34/50 - Loss: 150.7780 - Train Acc: 0.8818 - Val Acc: 0.7896\n",
      "[Baseline] Epoch 35/50 - Loss: 149.3139 - Train Acc: 0.8785 - Val Acc: 0.7787\n",
      "[Baseline] Epoch 36/50 - Loss: 145.9185 - Train Acc: 0.8857 - Val Acc: 0.7772\n",
      "[Baseline] Epoch 37/50 - Loss: 143.9768 - Train Acc: 0.8848 - Val Acc: 0.7962\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 38/50 - Loss: 141.8675 - Train Acc: 0.8845 - Val Acc: 0.7889\n",
      "[Baseline] Epoch 39/50 - Loss: 139.7793 - Train Acc: 0.8876 - Val Acc: 0.8072\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 40/50 - Loss: 136.8905 - Train Acc: 0.8923 - Val Acc: 0.7794\n",
      "[Baseline] Epoch 41/50 - Loss: 135.1072 - Train Acc: 0.8906 - Val Acc: 0.8028\n",
      "[Baseline] Epoch 42/50 - Loss: 132.2375 - Train Acc: 0.8931 - Val Acc: 0.8218\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 43/50 - Loss: 131.4347 - Train Acc: 0.8946 - Val Acc: 0.8210\n",
      "[Baseline] Epoch 44/50 - Loss: 129.9961 - Train Acc: 0.8949 - Val Acc: 0.8006\n",
      "[Baseline] Epoch 45/50 - Loss: 128.5700 - Train Acc: 0.8978 - Val Acc: 0.8137\n",
      "[Baseline] Epoch 46/50 - Loss: 126.2955 - Train Acc: 0.8995 - Val Acc: 0.8115\n",
      "[Baseline] Epoch 47/50 - Loss: 126.1702 - Train Acc: 0.9003 - Val Acc: 0.8203\n",
      "[Baseline] Epoch 48/50 - Loss: 124.0682 - Train Acc: 0.8992 - Val Acc: 0.8181\n",
      "[Baseline] Epoch 49/50 - Loss: 124.6618 - Train Acc: 0.9007 - Val Acc: 0.8240\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "[Baseline] Epoch 50/50 - Loss: 120.1093 - Train Acc: 0.9042 - Val Acc: 0.8459\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw15.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=45, Tw=20 (T_len=26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/914780513.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 1174.0227 - Train Acc: 0.1398 - Val Acc: 0.2107\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 988.8454 - Train Acc: 0.3087 - Val Acc: 0.4057\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 739.3768 - Train Acc: 0.5405 - Val Acc: 0.5331\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 593.3797 - Train Acc: 0.6473 - Val Acc: 0.5760\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 508.2334 - Train Acc: 0.6930 - Val Acc: 0.6120\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 455.2434 - Train Acc: 0.7190 - Val Acc: 0.6309\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 414.9901 - Train Acc: 0.7387 - Val Acc: 0.6562\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 387.1055 - Train Acc: 0.7488 - Val Acc: 0.6795\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 361.2040 - Train Acc: 0.7658 - Val Acc: 0.6858\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 341.0108 - Train Acc: 0.7772 - Val Acc: 0.6915\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 327.2062 - Train Acc: 0.7839 - Val Acc: 0.7123\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 310.3312 - Train Acc: 0.7967 - Val Acc: 0.7104\n",
      "[Baseline] Epoch 13/50 - Loss: 298.9343 - Train Acc: 0.8045 - Val Acc: 0.7091\n",
      "[Baseline] Epoch 14/50 - Loss: 287.5914 - Train Acc: 0.8075 - Val Acc: 0.7211\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 275.9120 - Train Acc: 0.8183 - Val Acc: 0.7394\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 266.8518 - Train Acc: 0.8243 - Val Acc: 0.7426\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 258.7570 - Train Acc: 0.8274 - Val Acc: 0.7514\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 250.6747 - Train Acc: 0.8324 - Val Acc: 0.7457\n",
      "[Baseline] Epoch 19/50 - Loss: 243.4600 - Train Acc: 0.8354 - Val Acc: 0.7539\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 236.9066 - Train Acc: 0.8410 - Val Acc: 0.7565\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 229.2691 - Train Acc: 0.8440 - Val Acc: 0.7615\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 225.6457 - Train Acc: 0.8496 - Val Acc: 0.7615\n",
      "[Baseline] Epoch 23/50 - Loss: 219.8399 - Train Acc: 0.8499 - Val Acc: 0.7767\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 215.1159 - Train Acc: 0.8546 - Val Acc: 0.7741\n",
      "[Baseline] Epoch 25/50 - Loss: 209.2403 - Train Acc: 0.8578 - Val Acc: 0.7830\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 205.4000 - Train Acc: 0.8594 - Val Acc: 0.7886\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 200.1136 - Train Acc: 0.8632 - Val Acc: 0.7943\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 197.5524 - Train Acc: 0.8653 - Val Acc: 0.7855\n",
      "[Baseline] Epoch 29/50 - Loss: 193.7803 - Train Acc: 0.8675 - Val Acc: 0.7855\n",
      "[Baseline] Epoch 30/50 - Loss: 190.5060 - Train Acc: 0.8714 - Val Acc: 0.7918\n",
      "[Baseline] Epoch 31/50 - Loss: 187.2647 - Train Acc: 0.8703 - Val Acc: 0.7956\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 185.3307 - Train Acc: 0.8716 - Val Acc: 0.7994\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 33/50 - Loss: 182.6889 - Train Acc: 0.8734 - Val Acc: 0.8013\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 34/50 - Loss: 178.3410 - Train Acc: 0.8770 - Val Acc: 0.8076\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 35/50 - Loss: 174.6344 - Train Acc: 0.8774 - Val Acc: 0.8019\n",
      "[Baseline] Epoch 36/50 - Loss: 172.3536 - Train Acc: 0.8809 - Val Acc: 0.8095\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 170.2792 - Train Acc: 0.8817 - Val Acc: 0.8044\n",
      "[Baseline] Epoch 38/50 - Loss: 168.0163 - Train Acc: 0.8843 - Val Acc: 0.8095\n",
      "[Baseline] Epoch 39/50 - Loss: 165.9648 - Train Acc: 0.8842 - Val Acc: 0.8183\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 40/50 - Loss: 164.2652 - Train Acc: 0.8836 - Val Acc: 0.8126\n",
      "[Baseline] Epoch 41/50 - Loss: 163.0939 - Train Acc: 0.8845 - Val Acc: 0.8164\n",
      "[Baseline] Epoch 42/50 - Loss: 159.1585 - Train Acc: 0.8909 - Val Acc: 0.8101\n",
      "[Baseline] Epoch 43/50 - Loss: 158.1501 - Train Acc: 0.8914 - Val Acc: 0.8170\n",
      "[Baseline] Epoch 44/50 - Loss: 155.4292 - Train Acc: 0.8927 - Val Acc: 0.8095\n",
      "[Baseline] Epoch 45/50 - Loss: 155.0286 - Train Acc: 0.8924 - Val Acc: 0.8284\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 46/50 - Loss: 153.7611 - Train Acc: 0.8939 - Val Acc: 0.8271\n",
      "[Baseline] Epoch 47/50 - Loss: 151.3382 - Train Acc: 0.8962 - Val Acc: 0.8265\n",
      "[Baseline] Epoch 48/50 - Loss: 150.6241 - Train Acc: 0.8967 - Val Acc: 0.8252\n",
      "[Baseline] Epoch 49/50 - Loss: 148.5233 - Train Acc: 0.8969 - Val Acc: 0.8322\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "[Baseline] Epoch 50/50 - Loss: 146.1195 - Train Acc: 0.8978 - Val Acc: 0.8385\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td45_Tw20.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=60, Tw=10 (T_len=51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/914780513.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 571.0764 - Train Acc: 0.0908 - Val Acc: 0.1921\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 552.4245 - Train Acc: 0.1322 - Val Acc: 0.2416\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 531.9931 - Train Acc: 0.2033 - Val Acc: 0.2329\n",
      "[Baseline] Epoch 04/50 - Loss: 472.0607 - Train Acc: 0.3464 - Val Acc: 0.4236\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 356.0477 - Train Acc: 0.5847 - Val Acc: 0.5138\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 294.7076 - Train Acc: 0.6775 - Val Acc: 0.5502\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 258.8948 - Train Acc: 0.7067 - Val Acc: 0.5721\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 232.2111 - Train Acc: 0.7272 - Val Acc: 0.5968\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 214.2587 - Train Acc: 0.7429 - Val Acc: 0.6157\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 199.8289 - Train Acc: 0.7513 - Val Acc: 0.6405\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 187.1815 - Train Acc: 0.7590 - Val Acc: 0.6288\n",
      "[Baseline] Epoch 12/50 - Loss: 177.5372 - Train Acc: 0.7714 - Val Acc: 0.6565\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 13/50 - Loss: 169.1702 - Train Acc: 0.7832 - Val Acc: 0.6696\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 161.6115 - Train Acc: 0.7940 - Val Acc: 0.6798\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 155.7225 - Train Acc: 0.8005 - Val Acc: 0.6856\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 149.4640 - Train Acc: 0.8061 - Val Acc: 0.6798\n",
      "[Baseline] Epoch 17/50 - Loss: 143.5495 - Train Acc: 0.8076 - Val Acc: 0.6885\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 139.3764 - Train Acc: 0.8129 - Val Acc: 0.7045\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 135.5223 - Train Acc: 0.8187 - Val Acc: 0.6987\n",
      "[Baseline] Epoch 20/50 - Loss: 130.2526 - Train Acc: 0.8264 - Val Acc: 0.7118\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 126.3919 - Train Acc: 0.8286 - Val Acc: 0.7074\n",
      "[Baseline] Epoch 22/50 - Loss: 122.8043 - Train Acc: 0.8311 - Val Acc: 0.7074\n",
      "[Baseline] Epoch 23/50 - Loss: 119.6575 - Train Acc: 0.8326 - Val Acc: 0.7322\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 115.9977 - Train Acc: 0.8346 - Val Acc: 0.7162\n",
      "[Baseline] Epoch 25/50 - Loss: 113.8629 - Train Acc: 0.8400 - Val Acc: 0.7365\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 110.5649 - Train Acc: 0.8404 - Val Acc: 0.7525\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 107.3254 - Train Acc: 0.8461 - Val Acc: 0.7569\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 104.9934 - Train Acc: 0.8503 - Val Acc: 0.7540\n",
      "[Baseline] Epoch 29/50 - Loss: 102.0476 - Train Acc: 0.8509 - Val Acc: 0.7482\n",
      "[Baseline] Epoch 30/50 - Loss: 99.5015 - Train Acc: 0.8552 - Val Acc: 0.7569\n",
      "[Baseline] Epoch 31/50 - Loss: 98.4917 - Train Acc: 0.8524 - Val Acc: 0.7525\n",
      "[Baseline] Epoch 32/50 - Loss: 95.9600 - Train Acc: 0.8570 - Val Acc: 0.7642\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 33/50 - Loss: 94.3089 - Train Acc: 0.8613 - Val Acc: 0.7642\n",
      "[Baseline] Epoch 34/50 - Loss: 92.7038 - Train Acc: 0.8639 - Val Acc: 0.7744\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 35/50 - Loss: 89.9966 - Train Acc: 0.8669 - Val Acc: 0.7831\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 36/50 - Loss: 88.1834 - Train Acc: 0.8703 - Val Acc: 0.7875\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 86.8317 - Train Acc: 0.8719 - Val Acc: 0.7744\n",
      "[Baseline] Epoch 38/50 - Loss: 84.5559 - Train Acc: 0.8747 - Val Acc: 0.7686\n",
      "[Baseline] Epoch 39/50 - Loss: 83.7277 - Train Acc: 0.8762 - Val Acc: 0.7875\n",
      "[Baseline] Epoch 40/50 - Loss: 81.9853 - Train Acc: 0.8755 - Val Acc: 0.7875\n",
      "[Baseline] Epoch 41/50 - Loss: 81.2454 - Train Acc: 0.8797 - Val Acc: 0.8020\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 42/50 - Loss: 79.7987 - Train Acc: 0.8827 - Val Acc: 0.8035\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 43/50 - Loss: 78.9884 - Train Acc: 0.8833 - Val Acc: 0.8093\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 44/50 - Loss: 77.6836 - Train Acc: 0.8893 - Val Acc: 0.8122\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 45/50 - Loss: 75.8431 - Train Acc: 0.8845 - Val Acc: 0.8020\n",
      "[Baseline] Epoch 46/50 - Loss: 74.4265 - Train Acc: 0.8895 - Val Acc: 0.7875\n",
      "[Baseline] Epoch 47/50 - Loss: 73.8523 - Train Acc: 0.8913 - Val Acc: 0.8137\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 48/50 - Loss: 72.4118 - Train Acc: 0.8939 - Val Acc: 0.8006\n",
      "[Baseline] Epoch 49/50 - Loss: 71.8752 - Train Acc: 0.8933 - Val Acc: 0.8239\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "[Baseline] Epoch 50/50 - Loss: 70.9121 - Train Acc: 0.8933 - Val Acc: 0.7918\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw10.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=60, Tw=15 (T_len=46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/914780513.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 626.1540 - Train Acc: 0.0949 - Val Acc: 0.2165\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 611.2647 - Train Acc: 0.1352 - Val Acc: 0.2671\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 581.4301 - Train Acc: 0.2445 - Val Acc: 0.4405\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 438.2678 - Train Acc: 0.5033 - Val Acc: 0.5089\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 343.6388 - Train Acc: 0.6115 - Val Acc: 0.5392\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 303.5162 - Train Acc: 0.6525 - Val Acc: 0.5873\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 272.2775 - Train Acc: 0.6878 - Val Acc: 0.6063\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 251.0408 - Train Acc: 0.7064 - Val Acc: 0.6101\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 231.5526 - Train Acc: 0.7306 - Val Acc: 0.6405\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 10/50 - Loss: 216.6389 - Train Acc: 0.7426 - Val Acc: 0.6570\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 203.9372 - Train Acc: 0.7553 - Val Acc: 0.6494\n",
      "[Baseline] Epoch 12/50 - Loss: 193.2377 - Train Acc: 0.7664 - Val Acc: 0.6532\n",
      "[Baseline] Epoch 13/50 - Loss: 184.9014 - Train Acc: 0.7738 - Val Acc: 0.6620\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 177.2380 - Train Acc: 0.7796 - Val Acc: 0.6709\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 169.5834 - Train Acc: 0.7880 - Val Acc: 0.6734\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 163.7732 - Train Acc: 0.7891 - Val Acc: 0.6671\n",
      "[Baseline] Epoch 17/50 - Loss: 157.9193 - Train Acc: 0.7926 - Val Acc: 0.6759\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 152.7786 - Train Acc: 0.7974 - Val Acc: 0.6772\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 148.5586 - Train Acc: 0.8056 - Val Acc: 0.6911\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 20/50 - Loss: 144.7497 - Train Acc: 0.8071 - Val Acc: 0.6975\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 21/50 - Loss: 141.0014 - Train Acc: 0.8120 - Val Acc: 0.7038\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 136.0842 - Train Acc: 0.8211 - Val Acc: 0.6886\n",
      "[Baseline] Epoch 23/50 - Loss: 132.7084 - Train Acc: 0.8243 - Val Acc: 0.7051\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 130.0582 - Train Acc: 0.8254 - Val Acc: 0.7025\n",
      "[Baseline] Epoch 25/50 - Loss: 127.4613 - Train Acc: 0.8294 - Val Acc: 0.7127\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 124.7530 - Train Acc: 0.8348 - Val Acc: 0.7038\n",
      "[Baseline] Epoch 27/50 - Loss: 121.9632 - Train Acc: 0.8346 - Val Acc: 0.7215\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 119.4265 - Train Acc: 0.8355 - Val Acc: 0.7177\n",
      "[Baseline] Epoch 29/50 - Loss: 117.1849 - Train Acc: 0.8402 - Val Acc: 0.7304\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 30/50 - Loss: 115.1870 - Train Acc: 0.8472 - Val Acc: 0.7380\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 31/50 - Loss: 112.3442 - Train Acc: 0.8484 - Val Acc: 0.7430\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 108.9294 - Train Acc: 0.8571 - Val Acc: 0.7380\n",
      "[Baseline] Epoch 33/50 - Loss: 108.0722 - Train Acc: 0.8580 - Val Acc: 0.7494\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 34/50 - Loss: 105.6501 - Train Acc: 0.8603 - Val Acc: 0.7468\n",
      "[Baseline] Epoch 35/50 - Loss: 103.1321 - Train Acc: 0.8610 - Val Acc: 0.7557\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 36/50 - Loss: 102.1494 - Train Acc: 0.8690 - Val Acc: 0.7570\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 37/50 - Loss: 99.8414 - Train Acc: 0.8678 - Val Acc: 0.7747\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 38/50 - Loss: 98.2580 - Train Acc: 0.8698 - Val Acc: 0.7646\n",
      "[Baseline] Epoch 39/50 - Loss: 96.0857 - Train Acc: 0.8762 - Val Acc: 0.7608\n",
      "[Baseline] Epoch 40/50 - Loss: 96.2989 - Train Acc: 0.8723 - Val Acc: 0.7620\n",
      "[Baseline] Epoch 41/50 - Loss: 93.7116 - Train Acc: 0.8763 - Val Acc: 0.7759\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 42/50 - Loss: 91.7404 - Train Acc: 0.8850 - Val Acc: 0.7823\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 43/50 - Loss: 90.0682 - Train Acc: 0.8812 - Val Acc: 0.7823\n",
      "[Baseline] Epoch 44/50 - Loss: 89.0649 - Train Acc: 0.8868 - Val Acc: 0.8025\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 45/50 - Loss: 88.0467 - Train Acc: 0.8858 - Val Acc: 0.7835\n",
      "[Baseline] Epoch 46/50 - Loss: 87.5070 - Train Acc: 0.8861 - Val Acc: 0.7899\n",
      "[Baseline] Epoch 47/50 - Loss: 86.2438 - Train Acc: 0.8885 - Val Acc: 0.8051\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "[Baseline] Epoch 48/50 - Loss: 84.4317 - Train Acc: 0.8935 - Val Acc: 0.7962\n",
      "[Baseline] Epoch 49/50 - Loss: 83.7061 - Train Acc: 0.8930 - Val Acc: 0.7975\n",
      "[Baseline] Epoch 50/50 - Loss: 81.6889 - Train Acc: 0.8957 - Val Acc: 0.8051\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw15.pth\n",
      "\n",
      "🚀 Training Standalone Student for Td=60, Tw=20 (T_len=41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/914780513.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 01/50 - Loss: 683.4314 - Train Acc: 0.1103 - Val Acc: 0.2237\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 02/50 - Loss: 655.4610 - Train Acc: 0.1894 - Val Acc: 0.3665\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 03/50 - Loss: 571.1371 - Train Acc: 0.3454 - Val Acc: 0.4344\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 04/50 - Loss: 420.4691 - Train Acc: 0.5527 - Val Acc: 0.4977\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 05/50 - Loss: 352.2167 - Train Acc: 0.6357 - Val Acc: 0.5656\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 06/50 - Loss: 307.2643 - Train Acc: 0.6793 - Val Acc: 0.5785\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 07/50 - Loss: 274.4951 - Train Acc: 0.7057 - Val Acc: 0.6066\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 08/50 - Loss: 252.3978 - Train Acc: 0.7222 - Val Acc: 0.6511\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 09/50 - Loss: 235.7434 - Train Acc: 0.7344 - Val Acc: 0.6393\n",
      "[Baseline] Epoch 10/50 - Loss: 219.2206 - Train Acc: 0.7525 - Val Acc: 0.6522\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 11/50 - Loss: 208.7311 - Train Acc: 0.7637 - Val Acc: 0.6674\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 12/50 - Loss: 198.9098 - Train Acc: 0.7666 - Val Acc: 0.6616\n",
      "[Baseline] Epoch 13/50 - Loss: 191.4410 - Train Acc: 0.7730 - Val Acc: 0.6874\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 14/50 - Loss: 183.0935 - Train Acc: 0.7837 - Val Acc: 0.6944\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 15/50 - Loss: 176.4486 - Train Acc: 0.7896 - Val Acc: 0.7002\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 16/50 - Loss: 169.7292 - Train Acc: 0.7959 - Val Acc: 0.7096\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 17/50 - Loss: 164.9582 - Train Acc: 0.8025 - Val Acc: 0.7108\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 18/50 - Loss: 160.5919 - Train Acc: 0.8056 - Val Acc: 0.7178\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 19/50 - Loss: 156.2622 - Train Acc: 0.8056 - Val Acc: 0.7143\n",
      "[Baseline] Epoch 20/50 - Loss: 151.1723 - Train Acc: 0.8138 - Val Acc: 0.6979\n",
      "[Baseline] Epoch 21/50 - Loss: 147.6683 - Train Acc: 0.8161 - Val Acc: 0.7260\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 22/50 - Loss: 142.1849 - Train Acc: 0.8259 - Val Acc: 0.7295\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 23/50 - Loss: 138.6675 - Train Acc: 0.8284 - Val Acc: 0.7389\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 24/50 - Loss: 135.4833 - Train Acc: 0.8336 - Val Acc: 0.7389\n",
      "[Baseline] Epoch 25/50 - Loss: 131.7633 - Train Acc: 0.8397 - Val Acc: 0.7506\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 26/50 - Loss: 128.2615 - Train Acc: 0.8436 - Val Acc: 0.7693\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 27/50 - Loss: 124.9488 - Train Acc: 0.8455 - Val Acc: 0.7775\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 28/50 - Loss: 122.1575 - Train Acc: 0.8502 - Val Acc: 0.7787\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 29/50 - Loss: 119.7689 - Train Acc: 0.8511 - Val Acc: 0.7763\n",
      "[Baseline] Epoch 30/50 - Loss: 116.1360 - Train Acc: 0.8574 - Val Acc: 0.7705\n",
      "[Baseline] Epoch 31/50 - Loss: 114.0905 - Train Acc: 0.8593 - Val Acc: 0.7822\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 32/50 - Loss: 110.5057 - Train Acc: 0.8643 - Val Acc: 0.7787\n",
      "[Baseline] Epoch 33/50 - Loss: 108.8071 - Train Acc: 0.8699 - Val Acc: 0.8009\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 34/50 - Loss: 106.8012 - Train Acc: 0.8703 - Val Acc: 0.7728\n",
      "[Baseline] Epoch 35/50 - Loss: 103.5954 - Train Acc: 0.8764 - Val Acc: 0.8021\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 36/50 - Loss: 102.4120 - Train Acc: 0.8757 - Val Acc: 0.7998\n",
      "[Baseline] Epoch 37/50 - Loss: 99.4582 - Train Acc: 0.8800 - Val Acc: 0.7998\n",
      "[Baseline] Epoch 38/50 - Loss: 97.6929 - Train Acc: 0.8822 - Val Acc: 0.8033\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 39/50 - Loss: 96.7525 - Train Acc: 0.8831 - Val Acc: 0.8162\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 40/50 - Loss: 93.8224 - Train Acc: 0.8893 - Val Acc: 0.7951\n",
      "[Baseline] Epoch 41/50 - Loss: 92.9802 - Train Acc: 0.8881 - Val Acc: 0.8162\n",
      "[Baseline] Epoch 42/50 - Loss: 90.4510 - Train Acc: 0.8923 - Val Acc: 0.8091\n",
      "[Baseline] Epoch 43/50 - Loss: 89.8061 - Train Acc: 0.8937 - Val Acc: 0.8232\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 44/50 - Loss: 87.4117 - Train Acc: 0.8971 - Val Acc: 0.8208\n",
      "[Baseline] Epoch 45/50 - Loss: 86.3925 - Train Acc: 0.8929 - Val Acc: 0.7963\n",
      "[Baseline] Epoch 46/50 - Loss: 84.7477 - Train Acc: 0.9002 - Val Acc: 0.8279\n",
      "💾 Saved best standalone student model to: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n",
      "[Baseline] Epoch 47/50 - Loss: 83.7011 - Train Acc: 0.9018 - Val Acc: 0.8173\n",
      "[Baseline] Epoch 48/50 - Loss: 82.9716 - Train Acc: 0.8986 - Val Acc: 0.8208\n",
      "[Baseline] Epoch 49/50 - Loss: 80.7144 - Train Acc: 0.9045 - Val Acc: 0.8279\n",
      "[Baseline] Epoch 50/50 - Loss: 80.9621 - Train Acc: 0.9032 - Val Acc: 0.8232\n",
      "✅ Saved standalone student model: /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student/student_baseline_Td60_Tw20.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/914780513.py:60: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  student.load_state_dict(torch.load(save_path))\n"
     ]
    }
   ],
   "source": [
    "baseline_save_dir = \"/home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/baseline_student\"\n",
    "os.makedirs(baseline_save_dir, exist_ok=True)\n",
    "\n",
    "for T_d in detection_times:\n",
    "    for T_w in window_sizes:\n",
    "        T_len = T_d - T_w + 1\n",
    "        expected_shape = (T_len, NUM_FEATURES)\n",
    "\n",
    "        print(f\"\\n🚀 Training Standalone Student for Td={T_d}, Tw={T_w} (T_len={T_len})\")\n",
    "\n",
    "        # === Paths\n",
    "        folder_name = f\"X_csv_split_{T_len}\"\n",
    "        input_dir = os.path.join(base_dir, f\"New_{T_d}\", f\"{T_w}\", \"split_tws\", folder_name)\n",
    "        train_path = os.path.join(input_dir, \"train\")\n",
    "        val_path   = os.path.join(input_dir, \"val\")\n",
    "        student_model_path = os.path.join(baseline_save_dir, f\"student_baseline_Td{T_d}_Tw{T_w}.pth\")\n",
    "\n",
    "        # === 1. Load Data\n",
    "        X_train_raw, y_train_raw = load_split_from_folder(train_path, expected_shape)\n",
    "        X_val_raw, y_val_raw     = load_split_from_folder(val_path, expected_shape)\n",
    "\n",
    "        # === 2. Encode & Balance\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_encoded = label_encoder.fit_transform(y_train_raw)\n",
    "\n",
    "        X_train_flat = X_train_raw.reshape(X_train_raw.shape[0], -1)\n",
    "        X_resampled, y_resampled = SMOTE().fit_resample(X_train_flat, y_train_encoded)\n",
    "        X_train_bal = X_resampled.reshape(-1, T_len, NUM_FEATURES)\n",
    "        y_train_str = label_encoder.inverse_transform(y_resampled)\n",
    "\n",
    "        # === 3. Dataset & Loader\n",
    "        train_dataset = MultiStreamDataset(X_train_bal, y_train_str, label_encoder, augment=True)\n",
    "        val_dataset   = MultiStreamDataset(X_val_raw, y_val_raw, label_encoder, augment=False)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # === 4. Compute Class Weights\n",
    "        class_weights_tensor = compute_class_weights(label_encoder.transform(y_train_str), device)\n",
    "\n",
    "        # === 5. Initialize Standalone Student\n",
    "        student_baseline = StudentCNN(\n",
    "            input_length=T_len,\n",
    "            num_classes=len(label_encoder.classes_)\n",
    "        ).to(device)\n",
    "\n",
    "        # === 6. Train (No KD)\n",
    "        train_accs_b, val_accs_b, train_losses_b, val_losses_b = train_student_baseline(\n",
    "            student=student_baseline,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            device=device,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            lr=0.00005,\n",
    "            class_weights=class_weights_tensor,\n",
    "            save_path=student_model_path\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Saved standalone student model: {student_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c8f20a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
      "/tmp/ipykernel_2409692/4053020706.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All evaluation results saved to /home/HardDisk/Satang/thesis_proj/Deep_Learning/cross_archi/ae/results/model_eval_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# === CONFIG ===\n",
    "detection_times = [30, 45, 60]\n",
    "window_sizes = [10, 15, 20]\n",
    "NUM_FEATURES = 8\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_dir = \"/home/HardDisk/Satang/thesis_proj/\"\n",
    "base_teacher_dir = os.path.join(base_dir, \"Deep_Learning\", \"cross_archi\", \"ae\", \"teacher\")\n",
    "student_kd_dir = os.path.join(base_dir, \"Deep_Learning\",\"cross_archi\",\"ae\", \"student\")\n",
    "student_baseline_dir = os.path.join(base_dir, \"Deep_Learning\",\"cross_archi\",\"ae\", \"baseline_student\")\n",
    "csv_output_path = os.path.join(base_dir, \"Deep_Learning\",\"cross_archi\",\"ae\", \"results\", \"model_eval_summary.csv\")\n",
    "os.makedirs(os.path.dirname(csv_output_path), exist_ok=True)\n",
    "\n",
    "# # === YOUR MODULE IMPORTS ===\n",
    "# from your_module import load_split_from_folder, MultiStreamDataset, RansomwareTransformer, StudentCNN\n",
    "\n",
    "results = []\n",
    "\n",
    "def evaluate_and_log(model, model_path, test_loader, label_encoder, T_d, T_w, model_type, results_list):\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            # Handle models that return a tuple (logits, recon)\n",
    "            if isinstance(model, AEWithClassifier):\n",
    "                logits, _ = model(inputs)\n",
    "            else:\n",
    "                logits = model(inputs)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    report = classification_report(all_labels, all_preds, target_names=label_encoder.classes_, output_dict=True)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    results_list.append({\n",
    "        \"Td\": T_d,\n",
    "        \"Tw\": T_w,\n",
    "        \"T_len\": T_d - T_w + 1,\n",
    "        \"Model\": model_type,\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"Precision_macro\": round(report[\"macro avg\"][\"precision\"], 4),\n",
    "        \"Recall_macro\": round(report[\"macro avg\"][\"recall\"], 4),\n",
    "        \"F1_macro\": round(report[\"macro avg\"][\"f1-score\"], 4),\n",
    "        \"F1_weighted\": round(report[\"weighted avg\"][\"f1-score\"], 4),\n",
    "    })\n",
    "\n",
    "# === MAIN EVALUATION LOOP ===\n",
    "for T_d in detection_times:\n",
    "    for T_w in window_sizes:\n",
    "        T_len = T_d - T_w + 1\n",
    "        expected_shape = (T_len, NUM_FEATURES)\n",
    "        folder_name = f\"X_csv_split_{T_len}\"\n",
    "        test_path = os.path.join(base_dir, f\"New_{T_d}\", f\"{T_w}\", \"split_tws\", folder_name, \"test\")\n",
    "\n",
    "        # === Load test set ===\n",
    "        X_test_raw, y_test_raw = load_split_from_folder(test_path, expected_shape)\n",
    "        label_encoder = LabelEncoder()\n",
    "        label_encoder.fit(y_test_raw)\n",
    "\n",
    "        test_dataset = MultiStreamDataset(X_test_raw, y_test_raw, label_encoder, augment=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # === Teacher ===\n",
    "        teacher_path = os.path.join(base_teacher_dir, f\"ae_Td{T_d}_Tw{T_w}.pth\")\n",
    "        teacher = AEWithClassifier(\n",
    "        input_length=T_len,                # ✅ must match original\n",
    "        feature_dim=NUM_FEATURES,\n",
    "        latent_dim=64,\n",
    "        num_classes=len(label_encoder.classes_),\n",
    "        proj_dim=128\n",
    "    )\n",
    "        evaluate_and_log(teacher, teacher_path, test_loader, label_encoder, T_d, T_w, \"Teacher\", results)\n",
    "\n",
    "        # === Student with KD ===\n",
    "        student_kd_path = os.path.join(student_kd_dir, f\"student_from_ae_Td{T_d}_Tw{T_w}.pth\")\n",
    "        student_kd = StudentCNN(input_length=T_len, num_classes=len(label_encoder.classes_))\n",
    "        evaluate_and_log(student_kd, student_kd_path, test_loader, label_encoder, T_d, T_w, \"Student_KD\", results)\n",
    "\n",
    "        # === Student Baseline ===\n",
    "        student_b_path = os.path.join(student_baseline_dir, f\"student_baseline_Td{T_d}_Tw{T_w}.pth\")\n",
    "        student_b = StudentCNN(input_length=T_len, num_classes=len(label_encoder.classes_))\n",
    "        evaluate_and_log(student_b, student_b_path, test_loader, label_encoder, T_d, T_w, \"Student_Baseline\", results)\n",
    "\n",
    "# === Save to CSV ===\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(csv_output_path, index=False)\n",
    "print(f\"\\n✅ All evaluation results saved to {csv_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c36b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_satang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
